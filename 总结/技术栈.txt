----------------------------------------------容器虚拟化技术Docker------------------------------------------------------- 
	一、容器虚拟化技术Docker
		定义：解决了运行环境和配置问题软件容器，方便做持续集成并有助于整体发布的容器虚拟化技术。
		特点:一次构建、随处运行，DevOps，内核虚拟化，依赖与宿主机内核（不同于传统的虚拟机技术）
		基本组成：镜像、容器、仓库
		docker安装：
		docker启动：centos 6+ 命令：service docker start
					centos 7+ 命令：systemctl start docker 
		docker关闭重启：centos 7+ 命令：systemctl restart docker  systemctl stop docker systemctl enable docker //开机自启
	二、常用命令：
		帮助命令：docker version/docker info/docker --help
		镜像命令：docker images 
				  docker search XXX镜像名，可选参数：
				  docker pull XXX镜像名
				  docker rmi -f XXX镜像名ID
				  移除所有镜像：docker rmi -f $(docker images -qa)
		容器命令：docker run [OPTIONS] IMAGE [COMMAND] [ARG...]
				   OPTIONS说明（常用）：有些是一个减号，有些是两个减号
					--name="容器新名字": 为容器指定一个名称；
					-d: 后台运行容器，并返回容器ID，也即启动守护式容器；
					-i：以交互模式运行容器，通常与 -t 同时使用；
					-t：为容器重新分配一个伪输入终端，通常与 -i 同时使用；
					-P: 随机端口映射；
					-p: 指定端口映射，有以下四种格式
						  ip:hostPort:containerPort
						  ip::containerPort
						  hostPort:containerPort
						  containerPort 
				当前所有正在运行的容器：docker ps [OPTIONS] 
										OPTIONS说明（常用）：
										-a :列出当前所有正在运行的容器+历史上运行过的
										-l :显示最近创建的容器。
										-n：显示最近n个创建的容器。
										-q :静默模式，只显示容器编号。
										--no-trunc :不截断输出。
				退出容器：容器停止退出exit
						  容器不停止退出ctrl+P+Q
				启动/停止/重启/强制停止容器：docker start/stop/restart/kill 容器ID或者容器名
				删除已停止的容器：docker rm -f 容器ID 
				删除所有容器：docker rm -f $(docker ps -a -q) 或docker ps -a -q | xargs docker rm
				启动守护式容器：docker run -d 容器名
				查看容器日志：docker logs -f -t --tail n 容器ID
				查看容器内运行的进程：docker top 容器ID
				查看容器内部细节：docker inspect 容器ID
				进入正在运行的容器并以命令行交互：docker exec -it 容器ID bashShell
												  重新进入docker attach 容器ID
				从容器内拷贝文件到主机上：docker cp 容器ID:容器内路径 目的主机路径
	三、Docker镜像
		镜像加速原理：bootfs(加载kernel) / rootfs(不同的操作系统发行版)			
		分层的联合文件系统：最大的一个好处就是 - 共享资源
		Docker镜像commit操作补充：docker commit -m=“提交的描述信息” -a=“作者” 容器ID 要创建的目标镜像名:[标签名]
	四、Docker容器数据卷
		作用：容器间继承+共享数据、容器的持久化
		卷的设计目的就是数据的持久化，完全独立于容器的生存周期，因此Docker不会在容器删除时删除其挂载的数据卷
		特点：
			1：数据卷可在容器之间共享或重用数据
			2：卷中的更改可以直接生效
			3：数据卷中的更改不会包含在镜像的更新中
			4：数据卷的生命周期一直持续到没有容器使用它为止
		直接命令添加：
			docker run -it -v /宿主机绝对路径目录:/容器内目录[:ro] [--privileged=true] 镜像名
		查看数据卷是否挂载成功
			docker inspect 容器ID
		容器和宿主机之间数据共享				  
		容器停止退出后，宿主机修改后数据是否同步-同步				  
		DockerFile添加-生成镜像：
			使用方式：在Dockerfile中使用VOLUME指令来给镜像添加一个或多个数据卷，格式：VOLUME["/dataVolumeContainer1","/dataVolumeContainer2","/dataVolumeContainer3"]
			构建：docker build -f Dockerfile路径 -t 新的镜像名
		数据卷容器(容器间继承+传递共享数据)：
			语法：--volumes-from，例如：docker run -it --name doc2 --volumes-from doc01 zzyy/centos
	五、DockerFile解析
		定义：Dockerfile是用来构建Docker镜像的构建文件，是由一系列命令和参数构成的脚本。
		构建三步骤：编写Dockerfile文件、docker build、docker run
		关系：
			Dockerfile面向开发，Docker镜像成为交付标准，Docker容器则涉及部署与运维，三者缺一不可，合力充当Docker体系的基石
		保留字:
	六、Docker发布
		aliyun镜像的使用：
		登录阿里云Docker Registry：$ sudo docker login --username=ali域逸诚 registry.cn-hangzhou.aliyuncs.com
		从Registry中拉取镜像：$ sudo docker pull registry.cn-hangzhou.aliyuncs.com/ali_yuyicheng/redis_test:[镜像版本号]				  
		将镜像推送到Registry：				  
						$ sudo docker login --username=ali域逸诚 registry.cn-hangzhou.aliyuncs.com
						$ sudo docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/ali_yuyicheng/redis_test:[镜像版本号]
						$ sudo docker push registry.cn-hangzhou.aliyuncs.com/ali_yuyicheng/redis_test:[镜像版本号]  
					
----------------------------------------------文档数据结构MongoDB技术篇-------------------------------------------------------					  
	一、npm（Node Package Manager 包管理器）工具的使用
		- 通过npm可以对node中的包进行上传、下载、搜索等操作
			- npm会在安装完node以后，自动安装
			- npm的常用指令
				npm -v 查看npm的版本
				npm version 查看所有模块的版本
				npm init 初始化项目-创建package.json
				npm i/install 包名 安装指定的包
				npm i/install 包名 --save 安装指定的包并添加依赖
				npm i/install 包名 -g 全局安装（一般都是一些工具）
				npm i/install 安装当前项目所依赖的包
				npm s/search 包名 搜索包	
				npm r/remove 包名 删除一个包
	二、MongoDB	
		定义：为快速开发WEB应用而设计的数据库，面向文档，类似JSON数据(BSON),注意：MongoDB数据库使用的是JavaScript进行操作的，在MongoDB含有一个对ES标准实现的引擎，
			在MongoDB中所有ES中的语法中都可以使用
		启动：
			- 打开cmd命令行窗口
				- 输入 mongod 启动mongodb服务器
				- 32位注意：
					启动服务器时，需要输入如下内容
						mongod --storageEngine=mmapv1
						mongod --dbpath 数据库路径 --port 端口
				
			- 再打开一个cmd窗口
				- 输入 mongo 连接mongodb ，出现 >				  
						  
		- 基本概念
			数据库（database）- 类比SQL数据库、集合（collection）- 类比SQL表、文档（document）- 类比SQL表记录
			- 在MongoDB中，数据库和集合都不需要手动创建，当我们创建文档时，如果文档所在的集合或数据库不存在会自动创建数据库和集合		
			
		- 基本指令
			show dbs/databases 
				- 显示当前的所有数据库
			use 数据库名
				- 进入到指定的数据库中
			db
				- db表示的是当前所处的数据库
			show collections
				- 显示数据库中所有的集合
				
		- 数据库的CRUD（增删改查）的操作
			  
			- 向数据库中插入文档
			- db.collection.insert()
				- insert()可以向集合中插入一个或多个文档
			- db.collection.insertOne()
				- 向集合中插入一个文档
			- db.collection.insertMany()
				- 向集合中插入多个文档
			如：db.stus.insert([
					{name:"沙和尚",age:38,gender:"男"},
					{name:"白骨精",age:16,gender:"女"},
					{name:"蜘蛛精",age:14,gender:"女"}
				]);
				db.stus.find({}); //查询所有文档
					
			- 查询数据库中的文档
				- db.collection.find()
					- 可以根据指定条件从集合中查询所有符合条件的文档
					- 返回的是一个数组
				- db.collection.findOne()
					- 查询第一个符合条件的文档
					- 返回的是一个对象
				- db.collection.find().count()
					- 查询符合条件的文档的数量
				查询条件：
					-$gt $eq $lt $lte limit() $or
					如：db.emp.find({sal:{$lt:2000 , $gt:1000}}).limit(5);
						db.emp.find({$or:[{sal:{$lt:1000}} , {sal:{$gt:2500}}]});
				分页：
				skip()用于跳过指定数量的数据，MongoDB会自动调整skip和limit的位置
				如：db.numbers.find().skip(10).limit(10); -第11条到20条数据	
				如：db.stus.find({age:16 , name:"白骨精"});
					
			- 修改数据库中的文档
				- db.collection.update()
					- 可以修改、替换集合中的一个或多个文档（默认修改一个）
					注意：  - update()默认情况下会使用新对象来替换旧的对象
							- 如果需要修改指定的属性，而不是替换需要使用“修改操作符”来完成修改
								$set 可以用来修改文档中的指定属性
								$unset 可以用来删除文档的指定属性
								内嵌文档中：
								$push 用于向数组中添加一个新的元素
								$addToSet 向数组中添加一个新元素 ，如果数组中已经存在了该元素，则不会添加
								$inc 增加到	，如:db.emp.updateMany({sal:{$lte:1000}} , {$inc:{sal:400}});						
							- update()默认只会修改一个
				- db.collection.updateOne()
					- 修改集合中的一个文档
				- db.collection.updateMany()
					- 修改集合中的多个文档
				- db.collection.replaceOne()
					- 替换集合中的一个文档
				如：db.stus.update(
					{"_id" : ObjectId("59c219689410bc1dbecc0709")},
					{$set:{
						gender:"男",
						address:"流沙河"
					}}    
				)
				又如：db.stus.update(
						{"name" : "猪八戒"},
						
						{
							$set:{
							address:"呵呵呵"
							}
						}  ,
						{
							multi:true
						}    
					)
					
			- 删除集合中的文档
				- db.collection.remove()
					- 删除集合中的一个或多个文档（默认删除多个），可以第二个参数传递一个true，则只会删除一个
				- db.collection.deleteOne()
					- 删除集合中的一个文档
				- db.collection.deleteMany()
					- 删除集合中的多个文档
				- 清空一个集合
					db.collection.remove({})
				- 删除一个集合
					db.collection.drop()
				- 删除一个数据库
					db.dropDatabase()	
				注意：一般数据库数据中添加一个字段，来表示数据是否被删除
					如：db.stus.insert([
						{
							name:"zbj",
							isDel:0
							},
							{
							name:"shs",
							isDel:0
							},
						{
						name:"ts",
							isDel:0
						}

					]);
					db.stus.updateOne({name:"ts"},{$set:{isDel:1}});	
					db.stus.find({isDel:0});
		文档关系：一对一（one to one），内嵌文档的形式
				  如：db.wifeAndHusband.insert([
						{
							name:"黄蓉",
							husband:{
								name:"郭靖"
							}
						},{
							name:"潘金莲",
							husband:{
								name:"武大郎"
							}
						}

					]);
				  一对多（one to many）/多对一(many to one)，也可以用内嵌文档的形式
				  多对多(many to many) 用两个集合表示
		排序与投影：
				查询文档时，默认情况是按照_id的值进行排列（升序）
				sort()可以用来指定文档的排序的规则,sort()需要传递一个对象来指定排序规则 1表示升序 -1表示降序
				limit skip sort 可以以任意的顺序进行调用
				如：db.emp.find({}).sort({sal:1,empno:-1});
				在查询时，可以在第二个参数的位置来设置查询结果的投影，0不显示；1：显示
				如：db.emp.find({},{ename:1 , _id:0 , sal:1});
		分组查询：
			分组分片查询，aggregate的使用
			//源数据
			db.items.insert( [
			  {
			   "quantity" : 2,
			   "price" : 5.0,
			   "pnumber" : "p003",
			  }...,{
			   "quantity" : 5,
			   "price" : 10.0,
			   "pnumber" : "p002"
			  }
			])    
			//$group语法:{ $group: { _id: <expression>, <field1>: { <accumulator1> : <expression1> }, ... } }
			/*
			 *_id 分组的key,expression分组的字段，如果_id为null 相当于SQL:select count(*) from table
			 *field1 分组后展示的字段
			 *accumulator1 分组管道函数，如：$sum\$avg\$min\$max\$push\$addToSet\$first\$last
			 *expression1  分组显示数据相关
			 */	
			//查询总数,相当于SQL:select count(1) as count from items
			db.items.count();
			db.items.aggregate([{$group:{_id:null,count:{$sum:1}}}])
			//统计数量，相当于SQL:select sum(quantity) as total  from  items
			db.items.aggregate([{$group:{_id:null,total:{$sum:"$quantity"}}}]);
			//按产品类型来进行分组，然后在统计卖出的数量是多少，相当于SQL：select sum(quantity) as total from  items  group by pnumber
			db.items.aggregate([{$group:{_id:"$pnumber",total:{$sum:"$quantity"}}}])
			//通过相同的产品类型来进行分组，然后查询相同产品类型卖出最多的订单详情，相当于SQL:select max(quantity) as quantity from  items  group by pnumber
			db.items.aggregate([{$group:{_id:"$pnumber",max:{$max:"$quantity"}}}])
			db.items.aggregate([{$group:{_id:"$pnumber",min:{$min:"$quantity"}}}])
			//通过相同的产品类型来进行分组，统计各个产品数量，然后获取最大的数量，相当于SQL:select max(t.total) from (select sum(quantity) as total from  items  group by pnumber) t
			db.items.aggregate([{$group:{_id:"$pnumber",total:{$sum:"$quantity"}}}])
			db.items.aggregate([{$group:{_id:"$pnumber",total:{$sum:"$quantity"}}},{$group:{_id:null,max:{$max:"$total"}}}])
			//通过相同的产品类型来进行分组，然后查询每个订单详情相同产品类型卖出的平均价格，相当于SQL:select avg(price) as price from  items  group by pnumber
			db.items.aggregate([{$group:{_id:"$pnumber",price:{$avg:"$price"}}}])
			//通过相同的产品类型来进行分组，然后查询每个相同产品卖出的数量放在数组里面,，注意值数组中的值不要超过16M
			db.items.aggregate([{$group:{_id:"$pnumber",quantitys:{$push:"$quantity"}}}])
			db.items.aggregate([{$group:{_id:"$pnumber",quantitys:{$push:{quantity:"$quantity",price:"$price"}}}}])
			//表达式的值添加到一个数组中（无重复值），这个值不要超过16M
			db.items.aggregate([{$group:{_id:"$pnumber",quantitys:{$addToSet:"$quantity"}}}])
			//$first：返回每组第一个文档，如果有排序，按照排序，如果没有按照默认的存储的顺序的第一个文档。
			//$last：返回每组最后一个文档，如果有排序，按照排序，如果没有按照默认的存储的顺序的最后个文档。
			db.items.aggregate([{$group:{_id:"$pnumber",quantityFrist:{$first:"$quantity"}}}])
			//$project显示或不显示字段，相当于SQL:select
			db.items.aggregate([{$group:{_id:null,count:{$sum:1}}},{$project:{"_id":0,"count":1}}])
			//通过滤订单中，想知道卖出的数量大于8的产品有哪些产品，相当于SQL:select sum(quantity) as total from  items  group by pnumber having total>8   
			db.items.aggregate([{$group:{_id:"$pnumber",total:{$sum:"$quantity"}}},{$match:{total:{$gt:8}}}])
			//$match如果是放在$group之前就是当做where来使用，我们只统计pnumber =p001 产品卖出了多少个  select sum(quantity) as total from  items where pnumber='p001'
			db.items.aggregate([{$match:{"pnumber":"p001"}},{$group:{_id:null,total:{$sum:"$quantity"}}}])
			//$skip、$limit使用顺序不同，结果也不同，注意：$limit、$skip、$sort、$match可以使用在阶段管道，如果使用在$group之前可以过滤掉一些数据，提高性能
			db.items.aggregate([{ $skip: 2 },{ $limit: 4 },{ $sort: { quantity : -1 }}])
			db.items.aggregate([{ $limit: 4 },{ $skip: 2 }])
			//将文档中的某一个数组类型字段拆分成多条，每条包含数组中的一个值
			db.items.aggregate([{$group:{_id:"$pnumber",quantitys:{$push:"$quantity"}}}])
			db.items.aggregate([{$group:{_id:"$pnumber",quantitys:{$push:"$quantity"}}},{$unwind:"$quantitys"}])
			//$out必须为pipeline最后一个阶段管道，因为是将最后计算结果写入到指定的collection中
			db.items.aggregate([{$group:{_id:"$pnumber",quantitys:{$push:"$quantity"}}},{$unwind:"$quantitys"},{$project:{"_id":0,"quantitys":1}},{$out:"result"}])
			db.result.find()
		模糊查询：$options - 可选参数				  
			如：db.students.find({"user_name": {$regex: /尚/, $options:'i'}}); 
				db.students.find({"user_name": {$regex:/尚.*/i}}); 
				db.students.find({user_name:{$in:[/^孙尚香/i,/^胡歌/]}});
				db.students.find({user_name:{$regex:/^孙尚香/i,$nin:['孙尚香II']}});
				db.students.find({user_name:{$regex:/香/,$options:"si"}});
	
----------------------------------------------Spring boot 技术篇---------------------------------------------------------	
	一、基本概念：
			特点：开箱即用，自动配置
			配置文件：YAML 的基本使用-支持文档块
			配置文件值的注入：
				方式一：@ConfigurationProperties
					格式：
				javaBean 
					@Component
					@ConfigurationProperties(prefix = "person")
					//@Validated
					public class Person {
						//@Value("${person.last-name}")
						private String lastName;
						//@Value("#{11*2}")
						private Integer age;
						private Boolean boss;
						private Date birth;

						private Map<String,Object> maps;
						private List<Object> lists;
						private Dog dog;
						...
					}
				配置文件：
					person:
						lastName: hello
						age: 18
						boss: false
						birth: 2017/12/12
						maps: {k1: v1,k2: 12}
						lists:
						  - lisi
						  - zhaoliu
						dog:
						  name: 小狗
						  age: 12
						  
				方式二：@Value
				区别：
					|            	| @ConfigurationProperties | @Value 	 |
					| 功能         	| 批量注入配置文件中的属性 | 一个个指定  |
					| 松散绑定（松散语法）| 支持               | 不支持    	 |
					| SpEL       	| 不支持                      | 支持     |
					| JSR303数据校验| 支持                       | 不支持    |
					| 复杂类型封装  | 支持                       | 不支持    |
			配置文件加载：@PropertySource
				格式：
					@PropertySource(value = {"classpath:person.properties"})
					@Component
					@ConfigurationProperties(prefix = "person")
					public class Person {
						//@Value("#{11*2}")
						private Integer age;
						//@Value("true")
						private Boolean boss;

					```
					}
			配置文件读取：@ImportResource
				格式：
					java文件
						@ImportResource(locations = {"classpath:beans.xml"})
					xml文件
					<?xml version="1.0" encoding="UTF-8"?>
					<beans xmlns="http://www.springframework.org/schema/beans"
						   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
						   xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd">


						<bean id="helloService" class="com.atguigu.springboot.service.HelloService"></bean>
					</beans>	
			配置文件添加：	
				推荐使用全注解的方式
				1、配置类@Configuration------>Spring配置文件
				2、使用@Bean给容器中添加组件

				```java
				@Configuration
				public class MyAppConfig {

					//将方法的返回值添加到容器中；容器中这个组件默认的id就是方法名
					@Bean
					public HelloService helloService(){
						System.out.println("配置类@Bean给容器中添加组件了...");
						return new HelloService();
					}
				}
			配置文件占位符:
				如：*.properties 配置文件中
					person.last-name=张三${random.uuid}
					person.dog.name=${person.hello:hello}_dog
					
			配置文件Profile:		
				激活指定profile的方式：
				1、配置文件中指定  spring.profiles.active=dev	
				2、命令行方式 java -jar **-0.0.1-SNAPSHOT.jar --spring.profiles.active=dev；
				3、虚拟机参数 -Dspring.profiles.active=dev
			配置文件加载位置：
				springboot 启动会扫描以下位置的application.properties或者application.yml文件作为Spring boot的默认配置文件
				–file:./config/
				–file:./
				–classpath:/config/
				–classpath:/
				优先级由高到底，高优先级的配置会覆盖低优先级的配置；
				SpringBoot会从这四个位置全部加载主配置文件；互补配置；
				-指定加载位置：java -jar **-0.0.1-SNAPSHOT.jar --spring.config.location=G:/application.properties
			外部配置加载顺序：
				SpringBoot也可以从以下位置加载配置； 优先级从高到低；高优先级的配置覆盖低优先级的配置，所有的配置会形成互补配置
				1.命令行参数
					java -jar **-02-0.0.1-SNAPSHOT.jar --server.port=8087  --server.context-path=/abc
				多个配置用空格分开； --配置项=值
				2.来自java:comp/env的JNDI属性
				3.Java系统属性（System.getProperties()）
				4.操作系统环境变量
				5.RandomValuePropertySource配置的random.*属性值
				6.由jar包外向jar包内进行寻找，优先加载带profile
					jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件
					jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件
				10.@Configuration注解类上的@PropertySource
				11.通过SpringApplication.setDefaultProperties指定的默认属性
			自动配置原理：
				xxxxAutoConfigurartion：自动配置类；
				xxxxProperties:封装配置文件中相关属性；
			检测自动配置类是否生效：debug=true
	二、日志框架：
			默认：springBoot底层也是使用slf4j+logback的方式进行日志记录
			| 日志门面  （日志的抽象层）               | 日志实现                                     
			| ---------------------------------------- | ---------------------------------------- |
			| JCL（Jakarta  Commons Logging）          | Log4j  JUL（java.util.logging）  Log4j2  Logback	
			| SLF4j（Simple  Logging Facade for Java） jboss-logging|	
			系统统一日志（slf4j）输出：
				1、将系统中其他日志框架先排除出去
				2、用中间包来替换原有的日志框架
				3、我们导入slf4j其他的实现
	
			日志级别：
				由低到高   trace<debug<info<warn<error
			springBoot修改默认日志配置：
				1、指定级别：logging.level.XX包名=trace
				2、logging.path=  #不指定路径在当前项目下生成springboot.log日志
				   logging.path=/spring/log #在当前磁盘的根路径下创建spring文件夹和里面的log文件夹；使用 spring.log 作为默认文件
				3、logging.file=G:/springboot.log
				输出格式：
				4、logging.pattern.console=%d{yyyy-MM-dd} [%thread] %-5level %logger{50} - %msg%n #控制台
				5、logging.pattern.file=%d{yyyy-MM-dd} [%thread] %-5level %logger{50} - %msg%n #指定文件中
			指定具体的日志实现配置：类路径下放上每个日志框架自己的配置文件即可
				如：logback.xml：直接就被日志框架识别了；
					logback-spring.xml：日志框架就不直接加载日志的配置项，由SpringBoot解析日志配置，可以使用SpringBoot的高级Profile功能
					
					xml文件：
					<appender name="stdout" class="ch.qos.logback.core.ConsoleAppender">
							<!--
							日志输出格式：
								%d表示日期时间，
								%thread表示线程名，
								%-5level：级别从左显示5个字符宽度
								%logger{50} 表示logger名字最长50个字符，否则按照句点分割。 
								%msg：日志消息，
								%n是换行符
							-->
							<layout class="ch.qos.logback.classic.PatternLayout">
								<springProfile name="dev">
									<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} ----> [%thread] ---> %-5level %logger{50} - %msg%n</pattern>
								</springProfile>
								<springProfile name="!dev">
									<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} $$$$$$ [%thread] $$$$$$ %-5level %logger{50} - %msg%n</pattern>
								</springProfile>
							</layout>
						</appender>	
	二、Web模块：				
			静态资源映射：
				1、（以Jar包的方式引入静态资源）/webjars/**，都去 classpath:/META-INF/resources/webjars/找资源；如：localhost:8080/webjars/jquery/3.3.1/jquery.js
					引入如：
						<dependency>
							<groupId>org.webjars</groupId>
							<artifactId>jquery</artifactId>
							<version>3.3.1</version>
						</dependency>
				2、	/**，访问任何资源
					静态资源的文件夹：
					"classpath:/META-INF/resources/", 
					"classpath:/resources/",
					"classpath:/static/", 
					"classpath:/public/" 
					"/"：当前项目的根路径	
				3、	欢迎页：静态资源文件夹下的所有index.html页面；被"/**"映射；
				4、 所有的 **/favicon.ico  都是在静态资源文件下找	
			模板引擎：JSP、Velocity、Freemarker、Thymeleaf，SpringBoot推荐的Thymeleaf
				Thymeleaf使用：
					1、引入：POM.xml
						<dependency>
							<groupId>org.springframework.boot</groupId>
							<artifactId>spring-boot-starter-thymeleaf</artifactId>
							2.1.6
						</dependency>
				<properties>
						<thymeleaf.version>3.0.9.RELEASE</thymeleaf.version>
						<!-- 布局功能的支持程序  thymeleaf3主程序  layout2以上版本 -->
						<!-- thymeleaf2   layout1-->
						<thymeleaf-layout-dialect.version>2.2.2</thymeleaf-layout-dialect.version>
				  </properties>
					2、使用：把HTML页面放在classpath:/templates/，thymeleaf就能自动渲染；
						页面引入：<html lang="en" xmlns:th="http://www.thymeleaf.org">
						页面使用标签：
							语法规则：
								包含：th:insert th:replace th:include
								遍历：th:each
								条件判断：th:if th:unless th:switch th:case
								申明变量：th:object th:with
								属性修改：th:attr th:attrprepend th:attrapend
								属性值修改: th:value th:src th:href
								标签体内容：th:text（转义） th:utext（不转义）
								申明片段：th:fragment 
								移除：th:remove
							表达式：
								${...}：获取变量值，符合OGNL（Object Graphic Navigation Language(对象图导航语言)）标准；
									1）、获取对象的属性、调用方法
									2）、使用内置的基本对象：
										#ctx : the context object.
										#vars: the context variables.
										#locale : the context locale.
										#request : (only in Web Contexts) the HttpServletRequest object.
										#response : (only in Web Contexts) the HttpServletResponse object.
										#session : (only in Web Contexts) the HttpSession object.
										#servletContext : (only in Web Contexts) the ServletContext object.
									3）、内置的一些工具对象：
									#execInfo : information about the template being processed.
									#messages : methods for obtaining externalized messages inside variables expressions, in the same way as they would be obtained using #{…} syntax.
									#uris : methods for escaping parts of URLs/URIs
									#conversions : methods for executing the configured conversion service (if any).
									#dates : methods for java.util.Date objects: formatting, component extraction, etc.
									#calendars : analogous to #dates , but for java.util.Calendar objects.
									#numbers : methods for formatting numeric objects.
									#strings : methods for String objects: contains, startsWith, prepending/appending, etc.
									#objects : methods for objects in general.
									#bools : methods for boolean evaluation.
									#arrays : methods for arrays.
									#lists : methods for lists.
									#sets : methods for sets.
									#maps : methods for maps.
									#aggregates : methods for creating aggregates on arrays or collections.
									#ids : methods for dealing with id attributes that might be repeated (for example, as a result of an iteration).
										Selection Variable Expressions: *{...}：选择表达式：和${}在功能上是一样；补充：配合 th:object="${session.user}：	
									    <div th:object="${session.user}">
										<p>Name: <span th:text="*{firstName}">Sebastian</span>.</p>
										<p>Surname: <span th:text="*{lastName}">Pepper</span>.</p>
										<p>Nationality: <span th:text="*{nationality}">Saturn</span>.</p>
										</div>
										Message Expressions: #{...}：获取国际化内容
										Link URL Expressions: @{...}：定义URL；@{/order/process(execId=${execId},execType='FAST')}		
										Fragment Expressions: ~{...}：片段引用表达式;<div th:insert="~{commons :: main}">...</div>				
									Literals（字面量）
										  Text literals: 'one text' , 'Another one!' ,…
										  Number literals: 0 , 34 , 3.0 , 12.3 ,…
										  Boolean literals: true , false
										  Null literal: null
										  Literal tokens: one , sometext , main ,…
									Text operations:（文本操作）
										String concatenation: +
										Literal substitutions: |The name is ${name}|
									Arithmetic operations:（数学运算）
										Binary operators: + , - , * , / , %
										Minus sign (unary operator): -
									Boolean operations:（布尔运算）
										Binary operators: and , or
										Boolean negation (unary operator): ! , not
									Comparisons and equality:（比较运算）
										Comparators: > , < , >= , <= ( gt , lt , ge , le )
										Equality operators: == , != ( eq , ne )
									Conditional operators:条件运算（三元运算符）
										If-then: (if) ? (then)
										If-then-else: (if) ? (then) : (else)
										Default: (value) ?: (defaultvalue)
									Special tokens:
										No-Operation: _ 
				禁用Thymeleaf缓存：spring.thymeleaf.cache=false 
			SpringMVC自动配置：
					SpringBoot对SpringMVC的默认配置，WebMvcAutoConfiguration
					做的主要几件事：
							1、自动配置了ViewResolver（视图解析器）
							2、支持静态资源文件夹路径,webjars
							3、支持静态首页访问
							4、支持favicon.ico系统图标
							5、自动注册了Converte转换器Formatter格式化器
			扩展SpringMVC：
					Bean.XML 参考：
						 <mvc:view-controller path="/hello" view-name="success"/>
							<mvc:interceptors>
								<mvc:interceptor>
									<mvc:mapping path="/hello"/>
									<bean></bean>
								</mvc:interceptor>
							</mvc:interceptors>
					编写一个配置类（@Configuration），是WebMvcConfigurerAdapter类型；不能标注@EnableWebMvc（会全面接管），既保留了所有的自动配置，也能用自定义扩展的配置；
					如：@Configuration
						//@EnableWebMvc
						public class MyMvcConfig extends WebMvcConfigurerAdapter {
							@Override
							public void addViewControllers(ViewControllerRegistry registry) {
							   // super.addViewControllers(registry);
								registry.addViewController("/atguigu").setViewName("success");
							}
						}
			全面接管SpringMVC：需要在自定义的配置类中添加@EnableWebMvc即可		
					原理：底层有@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)
						WebMvcConfigurationSupport只是保留SpringMVC最基本的功能
			国际化：
				使用步骤：	1）、编写国际化配置文件
							2）、使用ResourceBundleMessageSource管理国际化资源文件
							3）、在页面使用fmt:message取出国际化内容
				结论：根据浏览器语言设置的信息切换了国际化
				原理：国际化Locale（区域信息对象）；LocaleResolver（获取区域信息对象）；	
						@Bean
						@ConditionalOnMissingBean
						@ConditionalOnProperty(prefix = "spring.mvc", name = "locale")
						public LocaleResolver localeResolver() {
							if (this.mvcProperties
									.getLocaleResolver() == WebMvcProperties.LocaleResolver.FIXED) {
								return new FixedLocaleResolver(this.mvcProperties.getLocale());
							}
							//默认的就是根据请求头带来的区域信息获取Locale进行国际化
							AcceptHeaderLocaleResolver localeResolver = new AcceptHeaderLocaleResolver();
							localeResolver.setDefaultLocale(this.mvcProperties.getLocale());
							return localeResolver;
						}
				点击链接切换国际化: 自定义个类实现LocaleResolver重写resolveLocale方法（对请求参数进行处理）返回区域对象，并注入容器里
						参考：
						public class MyLocaleResolver implements LocaleResolver {
							@Override
							public Locale resolveLocale(HttpServletRequest request) {
								String l = request.getParameter("l");
								Locale locale = Locale.getDefault();
								if(!StringUtils.isEmpty(l)){
									String[] split = l.split("_");
									locale = new Locale(split[0],split[1]);
								}
								return locale;
							}

							@Override
							public void setLocale(HttpServletRequest request, HttpServletResponse response, Locale locale) {

							}
						}
						 @Bean
							public LocaleResolver localeResolver(){
								return new MyLocaleResolver();
							}
						}
			Rest风格:
					URI：/资源名称/资源标识（主表Id），以HTTP请求方式（GET、POST、PUT、DELETE）区分对资源CRUD操作；
					注意要点：如果添加/修改页面（二合一版），页面创建一个input项，name="_method";值就是我们指定的请求方式，原理：SpringMVC中配置HiddenHttpMethodFilter;（SpringBoot自动配置好的）
			模板抽取：
					1、抽取公共片段
					<div th:fragment="copy">
						&copy; 2011 The Good Thymes Virtual Grocery
					</div>
					2、引入公共片段
					<div th:insert="~{footer :: copy}"></div> // ~{templatename::selector}：模板名::选择器;~{templatename::fragmentname}:模板名::片段名									
					3、默认效果：
					如果使用th:insert等属性进行引入，可以不用写~{}：行内写法可以加上：[[~{}]];[(~{})]；
					三种引入公共片段的th属性：
					th:insert：将公共片段整个插入到声明引入的元素中
					th:replace：将声明引入的元素替换为公共片段
					th:include：将被引入的片段的内容包含进这个标签中
					如：
						<footer th:fragment="copy">
							&copy; 2011 The Good Thymes Virtual Grocery
						</footer>
						引入方式
						<div th:insert="footer :: copy"></div>
						<div th:replace="footer :: copy"></div>
						<div th:include="footer :: copy"></div>
						效果
						<div>
							<footer>
							&copy; 2011 The Good Thymes Virtual Grocery
							</footer>
						</div>
						
						<footer>
							&copy; 2011 The Good Thymes Virtual Grocery
						</footer>
						
						<div>
							&copy; 2011 The Good Thymes Virtual Grocery
						</div>
			错误处理：
				效果：1、浏览器：返回一个默认的错误页面；2、其他客户端，默认响应一个json数据
				原理：ErrorMvcAutoConfiguration；错误处理的自动配置类
					一但系统出现4xx或者5xx之类的错误；
					1、ErrorPageCustomizer就会生效（定制错误的响应规则）；就会来到/error请求；
					2、就会来到BasicErrorController处理（针对浏览器与其他客户端分别处理）；
					3、浏览器：调用DefaultErrorViewResolver类，交给它处理（有模板引擎，按模板引擎处理；没有默认处理error/状态码.html）
					4、其他客户端：调用getErrorAttributes方法，返回封装的Json数据；
				定制处理处理：
					基本规则：1、有模板引擎：模板引擎文件夹里面的error文件夹下找状态码.HTML（支持精准匹配与模糊匹配如：5xx.html）
								包含信息：
									timestamp：时间戳
					​				status：状态码
					​				error：错误提示
					​				exception：异常对象
					​				message：异常消息
					​				errors：JSR303数据校验的错误
							  2、没有模板引擎：静态资源文件夹
							  3、默认：来到SpringBoot默认的错误提示页面
				定制错误的JSON返回数据（思路）：
					自定义异常处理&返回定制json数据	
					转发到/error进行自适应响应效果处理
					将定制数据携带出去
			配置嵌入式Servlet容器：
				结论：SpringBoot默认使用Tomcat作为嵌入式的Servlet容器
				定制：
					1、ServerProperties方式，在配置文件中配置
					//通用的Servlet容器设置，server.xxx
					  如：server.port=8081 server.context-path=/crud
					//Tomcat的设置，server.tomcat.xxx
					  如：server.tomcat.uri-encoding=UTF-8
					2、EmbeddedServletContainerCustomizer方式，在java代码中配置
					  如：
						@Bean  //一定要将这个定制器加入到容器中
						public EmbeddedServletContainerCustomizer embeddedServletContainerCustomizer(){
							return new EmbeddedServletContainerCustomizer() {
								//定制嵌入式的Servlet容器相关的规则
								@Override
								public void customize(ConfigurableEmbeddedServletContainer container) {
									container.setPort(8083);
								}
							};
						}
				注册Servlet三大组件：Servlet、Filter、Listener 替代在web.xml中的配置	
				自动的注册前端控制器：DispatcherServletAutoConfiguration	
				修改配置：server.servletPath修改默认拦截的请求路径		
				修改为其他的servlet容器：
					支持Tomcat Undertow Jetty
					如：
						<!-- 引入web模块 -->
						<dependency>
						   <groupId>org.springframework.boot</groupId>
						   <artifactId>spring-boot-starter-web</artifactId>
						   <exclusions>
							  <exclusion>
								 <artifactId>spring-boot-starter-tomcat</artifactId>
								 <groupId>org.springframework.boot</groupId>
							  </exclusion>
						   </exclusions>
						</dependency>
						<!--引入其他的Servlet容器-->
						<dependency>
						   <artifactId>spring-boot-starter-undertow</artifactId>
						   <groupId>org.springframework.boot</groupId>
						</dependency>
				各自区别：
					Tomcat 是Apache下的一款重量级的基于HTTP协议的服务器
					Undertow 基于NIO（非阻塞式输入输出，相对于BIO（Blocking I/O，阻塞IO））实现的高并发轻量级的服务器 支持JSP
					Jetty 基于NIO（非阻塞式输入输出，相对于BIO（Blocking I/O，阻塞IO））实现的高并发轻量级的服务器 支持长链接
					Netty是一款基于NIO（Nonblocking I/O，非阻塞IO）开发的网络通信框架，客户端服务器框架
				嵌入式Servlet容器自动配置原理：EmbeddedServletContainerAutoConfiguration
					步骤：
					1）、SpringBoot根据导入的依赖情况，给容器中添加相应的EmbeddedServletContainerFactory
					2）、容器中某个组件要创建对象就会惊动后置处理器；EmbeddedServletContainerCustomizerBeanPostProcessor；只要是嵌入式的Servlet容器工厂，后置处理器就工作；
					3）、后置处理器，从容器中获取所有的EmbeddedServletContainerCustomizer，调用定制器的定制方法
				启动原理（步骤）：
					springBoot应用启动运行run方法->refreshContext(context);SpringBoot创建并刷新IOC容器(如果是web应用创建AnnotationConfigEmbeddedWebApplicationContext，否则：AnnotationConfigApplicationContext)
					->refresh(context)刷新IOC容器->onRefresh()->webIoc容器会创建嵌入式的Servlet容器；createEmbeddedServletContainer()
					->获取嵌入式的Servlet容器工厂EmbeddedServletContainerFactory->后置处理器EmbeddedServletContainerCustomizerBeanPostProcessor工作->
					->定制器来先定制Servlet容器的相关配置->嵌入式的Servlet容器创建对象并启动Servlet容器
				结论：IOC容器启动创建嵌入式的Servlet容器并启动
			外置的Servlet容器：
				嵌入式Servlet容器将应用打成可执行的jar，优点：简单、便携；缺点：默认不支持JSP、优化定制比较复杂；
				外置的Servlet容器一般指外面安装Tomcat---应用war包的方式打包；
				使用步骤：
					1）、必须创建一个war项目；（利用idea创建好目录结构）
					2）、将嵌入式的Tomcat指定为provided；
					<dependency>
					   <groupId>org.springframework.boot</groupId>
					   <artifactId>spring-boot-starter-tomcat</artifactId>
					   <scope>provided</scope>
					</dependency>
					3）、必须编写一个SpringBootServletInitializer的子类，并调用configure方法
					public class ServletInitializer extends SpringBootServletInitializer {
					   @Override
					   protected SpringApplicationBuilder configure(SpringApplicationBuilder application) {
						   //传入SpringBoot应用的主程序
						  return application.sources(SpringBoot04WebJspApplication.class);
					   }

					}
					4）、启动服务器就可以使用；
				原理：
					jar包：执行SpringBoot主类的main方法，启动ioc容器，创建嵌入式的Servlet容器；
					war包：启动服务器，服务器启动SpringBoot应用【SpringBootServletInitializer】，启动ioc容器；
	三、springboot与docker：
			详情参考docker技术；
			Docker是一个开源的应用容器引擎；是一个轻量级容器技术；
				
	四、springboot与数据访问：
			链接JDBC:
				1、导入依赖：
					<dependency>
						<groupId>org.springframework.boot</groupId>
						<artifactId>spring-boot-starter-jdbc</artifactId>
					</dependency>
					<dependency>
						<groupId>mysql</groupId>
						<artifactId>mysql-connector-java</artifactId>
						<scope>runtime</scope>
					</dependency>
				2、添加配置参数：
					spring:
					  datasource:
						username: root
						password: 123456
						url: jdbc:mysql://192.168.15.22:3306/jdbc
						driver-class-name: com.mysql.jdbc.Driver
						schema:
						- classpath:department.sql #指定位置
				3、申明使用
			相关结论：
				默认是用org.apache.tomcat.jdbc.pool.DataSource作为数据源，数据源的相关配置都在DataSourceProperties里面
				DataSourceInitializer：ApplicationListener 可以运行建表与运行数据插入（runSchemaScripts();运行建表语句；runDataScripts();运行插入数据的sql语句；）
				默认只需要将文件重命名为：schema-*.sql、data-*.sql 默认规则：schema.sql，schema-all.sql；
					可以使用   
					schema:
						- classpath:department.sql #指定位置
				自动配置了JdbcTemplate操作数据库；
			整合：Druid数据源，参考：https://blog.csdn.net/weixin_41404773/article/details/82592719
				1、导入依赖：
					<dependency>
						<groupId>org.springframework.boot</groupId>
						<artifactId>spring-boot-starter-jdbc</artifactId>
					</dependency>
					<!--引入druid-->
					<!-- https://mvnrepository.com/artifact/com.alibaba/druid -->
					<dependency>
						<groupId>com.alibaba</groupId>
						<artifactId>druid</artifactId>
						<version>1.1.8</version>
					</dependency>
				2、添加配置参数：在aplication.yml或aplication.properties
					spring:
					  datasource:
						username: root
						password: 123456
						url: jdbc:mysql://localhost:3306/testwkn
						driver-class-name: com.mysql.jdbc.Driver
						type: com.alibaba.druid.pool.DruidDataSource
					 
						initialSize: 5
						minIdle: 5
						maxActive: 20
						maxWait: 60000
						timeBetweenEvictionRunsMillis: 60000
						minEvictableIdleTimeMillis: 300000
						validationQuery: SELECT 1 FROM DUAL
						testWhileIdle: true
						testOnBorrow: false
						testOnReturn: false
						poolPreparedStatements: true
					#   配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
						filters: stat,wall,log4j
						maxPoolPreparedStatementPerConnectionSize: 20
						useGlobalDataSourceStat: true
						connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500
					#    schema:
					#      - classpath:department.sql

				3、	读取配置
					@Configuration
					public class DruidConfig {
					 
						@ConfigurationProperties(prefix = "spring.datasource")
						@Bean
						public DataSource druid(){
						   return  new DruidDataSource();
						}
					 
						//配置Druid的监控
						//1、配置一个管理后台的Servlet
						@Bean
						public ServletRegistrationBean statViewServlet(){
							ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), "/druid/*");
							Map<String,String> initParams = new HashMap<>();
					 
							initParams.put("loginUsername","admin");
							initParams.put("loginPassword","123456");
							initParams.put("allow","");//默认就是允许所有访问
							initParams.put("deny","192.168.15.21");
					 
							bean.setInitParameters(initParams);
							return bean;
						}
					 
					 
						//2、配置一个web监控的filter
						@Bean
						public FilterRegistrationBean webStatFilter(){
							FilterRegistrationBean bean = new FilterRegistrationBean();
							bean.setFilter(new WebStatFilter());
					 
							Map<String,String> initParams = new HashMap<>();
							initParams.put("exclusions","*.js,*.css,/druid/*");
					 
							bean.setInitParameters(initParams);
					 
							bean.setUrlPatterns(Arrays.asList("/*"));
					 
							return  bean;
						}
					}
			整合Mybatis:
				1、导入依赖：
					<dependency>
						<groupId>org.mybatis.spring.boot</groupId>
						<artifactId>mybatis-spring-boot-starter</artifactId>
						<version>1.3.1</version>
					</dependency>
				2、申明使用：
					1、注解版-写好提供的接口，程序的入口添加@MapperScan
					2、配置文件版
						mybatis:
						  config-location: classpath:mybatis/mybatis-config.xml 指定全局配置文件的位置
						  mapper-locations: classpath:mybatis/mapper/*.xml  指定sql映射文件的位置
			整合Jpa（Java Persistence API，通过注解或者XML描述【对象-关系表】之间的映射关系，并将实体对象持久化到数据库中）:
				Jpa特点：ORM映射元数据：JPA支持XML和注解两种元数据的形式，元数据描述对象和表之间的映射关系，框架据此将实体对象持久化到数据库表中；如：@Entity、@Table、@Column、@Transient等注解
						 JPA 提供API：用来操作实体对象，执行CRUD操作，框架在后台替我们完成所有的事情，开发者从繁琐的JDBC和SQL代码中解脱出来；如：entityManager.merge(T t)；
						 JPQL查询语言：通过面向对象而非面向数据库的查询语言查询数据，避免程序的SQL语句紧密耦合；如：from Student s where s.name = ?
						 JPA仅仅是一种规范，也就是说JPA仅仅定义了一些接口，而接口是需要实现才能工作的。Hibernate就是实现了JPA接口的ORM框架。
				spirng data jpa：
					是spring提供的一套简化JPA开发的框架，按照约定好的【方法命名规则】写dao层接口，就可以在不写接口实现的情况下，实现对数据库的访问和操作。同时提供了很多除了CRUD之外的功能，如分页、排序、复杂查询等等。		 
					Spring Data JPA 可以理解为 JPA 规范的再次封装抽象，底层还是使用了 Hibernate 的 JPA 技术实现。
					接口约定命名规则：如：findByNameAndPwd xxAndxx
					使用：
						1、导入依赖：
							<dependency>
								<groupId>org.springframework.boot/groupId>
								<artifactId>spring-boot-starter-data-jpa</artifactId>
							</dependency>
						2、添加配置：
							spring:  
								jpa:
									hibernate:
								# 更新或者创建数据表结构
										ddl-auto: update
								#控制台显示SQL
									show-sql: true
									database: mysql
						3、使用：
							编写一个实体类（bean）和数据表进行映射，并且配置好映射关系；
							编写一个Dao接口来操作实体类对应的数据表（Repository）；
							如：
								//使用JPA注解配置映射关系
								@Entity //告诉JPA这是一个实体类（和数据表映射的类）
								@Table(name = "tbl_user") //@Table来指定和哪个数据表对应;如果省略默认表名就是user；
								public class User {

									@Id //这是一个主键
									@GeneratedValue(strategy = GenerationType.IDENTITY)//自增主键
									private Integer id;

									@Column(name = "last_name",length = 50) //这是和数据表对应的一个列
									private String lastName;
									@Column //省略默认列名就是属性名
									private String email;
									...
								}
								
								public interface UserRepository extends JpaRepository<User,Integer> {
								}
			Springboot启动配置：
				构造过程（initialize(sources)）
					ApplicationContextInitializer，应用程序初始化器，做一些初始化的工作，	
					ApplicationListener，应用程序事件(ApplicationEvent)监听器，
					默认情况下，initialize方法从spring.factories文件中找出对应的key为ApplicationContextInitializer的类与ApplicationListener的类；
				SpringApplication执行
					SpringApplication构造完成之后调用run方法，启动SpringApplication，run方法执行的时候会做以下几件事
					构造Spring容器、刷新Spring容器、从Spring容器中找出ApplicationRunner和CommandLineRunner接口的实现类并排序后依次执行！
					
	五、Springboot与缓存：
			JSR107标准：
				Java Caching定义了5个核心接口，分别是CachingProvider, CacheManager, Cache, Entry和Expiry
					CachingProvider定义了创建、配置、获取、管理和控制多个CacheManager。
					CacheManager定义了创建、配置、获取、管理和控制多个唯一命名的Cache。
					Cache是一个类似Map的数据结构并临时存储以Key为索引的值。
					Entry是一个存储在Cache中的key-value对。Expiry 每一个存储在Cache中的条目有一个定义的有效期。
			使用：
				<dependency>
					<groupId>javax.cache</groupId>
					<artifactId>cache-api</artifactId>
				</dependency>
			Spring缓存抽象：
				简介：Spring从3.1开始定义了org.springframework.cache.Cache和org.springframework.cache.CacheManager接口来统一不同的缓存技术；
					并支持使用JCache（JSR-107）注解简化开发；
				特点：
					Cache接口为缓存的组件规范定义，包含缓存的各种操作集合；
					Cache接口下Spring提供了各种xxxCache的实现；如RedisCache，EhCacheCache , ConcurrentMapCache等；
					每次调用需要缓存功能的方法时，Spring会检查检查指定参数的指定的目标方法是否已经被调用过；如果有就直接从缓存中获取方法调用后的结果，如果没有就调用方法并缓存结果后返回给用户。下次调用直接从缓存中获取。
					使用Spring缓存抽象时我们需要关注以下两点； 
						确定方法需要被缓存以及他们的缓存策略
						从缓存中读取之前缓存存储的数据
				注解：
					@Cacheable - 主要针对方法配置，能够根据方法的请求参数对其结果进行缓存
					@CacheEvict - 清空缓存（删除）
					@CachePut - 保证方法被调用，又希望结果被缓存（更新）
					@EnableCaching	- 开启基于注解的缓存
					keyGenerator - 缓存数据时key生成策略
					serialize - 缓存数据时value序列化策略
				主要参数：
					cacheNames - 缓存的名称 如：@Cacheable(cacheNames={"emp"})
					value - 缓存的名称 如：@Cacheable(value=”cache0”) 或者 @Cacheable(value={”cache1”,”cache2”}
					key - 缓存的key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则缺省按照方法的所有参数进行组合，如：@Cacheable(value=”cache0”,key=”#userName”)
					condition - 缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才进行缓存/清除缓存，在调用方法之前之后都能判断，如：@Cacheable(value=”cache0”,condition=”#userName.length()>2”)
					allEntries -是否清空所有缓存内容，缺省为 false，如果指定为 true，则方法调用后将立即清空所有缓存，如：@CachEvict(value=”cache0”,allEntries=true)
					beforeInvocation - 是否在方法执行前就清空，缺省为 false，如果指定为 true，则在方法还没有执行的时候就清空缓存，缺省情况下，如果方法执行抛出异常，则不会清空缓存，如：@CachEvict(value=”cache01”，beforeInvocation=true)
					unless - 用于否决缓存的，条件为true不会缓存，fasle才缓存（与condition恰恰相反），如：@Cacheable(value=”cache01”,unless=”#result == null”)
				Cache SpEL available metadata：
					#root.methodName  #当前被调用的方法名
					#root.method.name #当前被调用的方法
					#root.target	  #当前被调用的目标对象
					#root.targetClass #当前被调用的目标对象类
					#root.args[0]     #当前被调用的方法的参数列表
					#root.caches[0].name #当前方法调用使用的缓存列表（如@Cacheable(value={"cache1", "cache2"})），则有两个cache
					#iban、 #a0、#p0 #方法参数的名字.可以直接#参数名，也可以使用#p0或#a0的形式，0代表参数的索引；
					#result           #方法执行后的返回值
				使用：
					•1、引入spring-boot-starter-cache模块
					•2、开启缓存：@EnableCaching
					•3、使用缓存注解
				
			Spring-data-redis：参考：https://blog.csdn.net/qq_26545305/article/details/80559902
				使用:
					1、引入依赖（2.0以后的版本）：
					<dependency>
						<groupId>org.springframework.boot</groupId>
						<artifactId>spring-boot-starter-data-redis</artifactId>
					</dependency>
					2、application.yml配置文件配置redis的相关信息
					spring:
					  redis:
						host: 192.168.224.225
						port: 6379
						password:
					3、配置redis整入spring的缓存框架
						@Configuration
						@EnableCaching  //继承CachingConfigurerSupport并重写方法，配合该注解实现spring缓存框架的使用
						public class RedisConfig extends CachingConfigurerSupport {
							/**载入配置文件配置的连接工厂**/
							@Autowired
							RedisConnectionFactory redisConnectionFactory;
							/*不提示警告信息*/
							@SuppressWarnings("rawtypes")
							@Autowired
							RedisTemplate redisTemplate;
						 
							@Bean
							RedisTemplate<String,Object> objectRedisTemplate(){
								RedisTemplate<String,Object> redisTemplate=new RedisTemplate<>();
								redisTemplate.setConnectionFactory(redisConnectionFactory);
								return redisTemplate;
							}
						 
							@Bean 
							@Override
							public CacheManager cacheManager(){
								RedisCacheManager redisCacheManager=new RedisCacheManager(redisTemplate);
								//设置缓存过期时间
						       // redisCacheManager.setDefaultExpiration(60);//秒
								return redisCacheManager;
							}
						 
							/**
							 * 重写缓存key生成策略，可根据自身业务需要进行自己的配置生成条件
							 * @return
							 */
							@Bean 
							@Override
							public KeyGenerator keyGenerator() {
								return new KeyGenerator() {
									@Override
									public Object generate(Object target, Method method, Object... params) {
										StringBuilder sb = new StringBuilder();
										sb.append(target.getClass().getName());
										sb.append(method.getName());
										for (Object obj : params) {
											sb.append(obj.toString());
										}
										return sb.toString();
									}
								};
							}
						 
						}
					
				操作: spring data redis中用来操作redis的一是采用注解的方式，常用两个注解@Cacheable、@CacheEvit，二是采用RedisTemplate的方式；
					  对应于redis的5中结构，RedisTemplate中定义了对应5种数据结构的操作
					  redisTemplate.opsForValue();//操作字符串
					  redisTemplate.opsForHash();//操作hash
					  redisTemplate.opsForList();//操作list
					  redisTemplate.opsForSet();//操作set
					  redisTemplate.opsForZSet();//操作有序Zset
			
			Ace-Cache：参考：https://gitee.com/geek_qi/ace-cache
				基于spring boot上的注解缓存，自带轻量级缓存管理页面。@Cache比spring cache更轻量的缓存，支持单个缓存设置过期时间，可以根据前缀移除缓存。采用fastjson序列化与反序列化，以json串存于缓存之中。
				使用：
					1、添加依赖：
						<dependency>
							<groupId>com.github.wxiaoqi</groupId>
							<artifactId>ace-cache</artifactId>
							<version>0.0.2</version>
						</dependency>
					2、配置文件中添加配置：
						redis:
							pool:
								 maxActive: 300
								 maxIdle: 100
								 maxWait: 1000
							host: 127.0.0.1
							port: 6379
							password:
							timeout: 2000
							# 服务或应用名
							sysName: ace
							enable: true
							database: 0
					3、程序入口开启：缓存开启@EnableAceCache
					具体使用：在Service上进行@Cache注解或@CacheClear注解；
						配置缓存：@Cache
								注解参数	类型	说明
								key	字符串	缓存表达式，动态运算出key
								expires	整形	缓存时长，单位：分钟
								desc	描述	缓存说明
								parser	Class<? extends ICacheResultParser>	缓存返回结果自定义处理类
								generator	Class<? extends IKeyGenerator>	缓存键值自定义生成类
						清除缓存：@CacheClear
								注解参数	类型	说明
									pre	字符串	清除某些前缀key缓存
									key	字符串	清除某个key缓存
									keys	字符串数组	清除某些前缀key缓存
									generator	Class<? extends IKeyGenerator>	缓存键值自定义生成类
					轻量管理端：访问地址：http://IP:PORT/cache					
						
	六、Springboot与消息：（异步通信、系统解耦、流量削峰填谷）
				消息的使用：利用消息中间件来提升系统异步通信、扩展解耦能力；
				基本概念：
					消息代理：（message broker）
					目的地：（destination）
					消息队列2种形式目的地
						1. 队列（queue） ：点对点消息通信（point-to-point）
						2. 主题（topic） ：发布（publish） /订阅（subscribe）消息通信
					点对点：
						消息发送者发送消息，消息代理将其放入一个队列中，消息接收者从队列中获取消息内容，消息读取后被移出队列，消息只有唯一的发送者和接受者，但并不是说只能有一个接收者
					发布订阅式：
						发送者（发布者）发送消息到主题，多个接收者（订阅者）监听（订阅）这个主题，那么就会在消息到达时同时收到消息
					JMS（Java Message Service） JAVA消息服务：基于JVM消息代理的规范。 ActiveMQ、 HornetMQ是JMS实现
					AMQP（Advanced Message Queuing Protocol）：高级消息队列协议，也是一个消息代理的规范，兼容JMS；RabbitMQ是AMQP的实现
				JMS与AMQP区别：
					AMQP网络线级协议，跨语言跨平台，支持5种消息模型；（1）direct exchange（2）、fanout exchange（3）、topic change（4）、headers exchange（5）、system exchange
				Springboot的支持：
					– spring-jms提供了对JMS的支持
					– spring-rabbit提供了对AMQP的支持
					– 需要ConnectionFactory的实现来连接消息代理
					– 提供JmsTemplate、 RabbitTemplate来发送消息
					– @JmsListener（JMS）、 @RabbitListener（AMQP）注解在方法上监听消息代理发布的消息
					– @EnableJms、 @EnableRabbit开启支持
					– JmsAutoConfiguration
					– RabbitAutoConfiguration
				RabbitMQ：
					简介：是一个由erlang开发的AMQP(Advanved Message Queue Protocol)的开源实现。
					核心概念：
						Message：消息，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组
								 成，这些属性包括routing-key（路由键）、 priority（相对于其他消息的优先权）、 delivery-mode（指出
								 该消息可能需要持久性存储）等。
						Publisher：消息的生产者，也是一个向交换器发布消息的客户端应用程序。
						Exchange：交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。
						Exchange有4种类型： direct(默认)，fanout, topic, 和headers，不同类型的Exchange转发消息的策略有所区别。							
						Queue：消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。
							   消息一直在队列里面，等待消费者连接到这个队列将其取走。
						Binding：绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连
								 接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。Exchange 和Queue的绑定可以是多对多的关系。
						Connection：网络连接，比如一个TCP连接。
						Channel：信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内的虚
								 拟连接， AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这
								 些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所
								 以引入了信道的概念，以复用一条 TCP 连接。
						Consumer：消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。 
						Virtual Host：虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。
									  每个 vhost 本质上就是一个 mini 版的 RabbitMQ 服务器，拥有									  
									  自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 / 。
						Broker：表示消息队列服务器实体   
					运行机制：
						一句话概括：生产者将消息发送到Exchange（交换机），Exchange根据路由规则（routing-key）将消息Binding绑定到不同的消息队列，消费者
									从消息队列里取出消息
						Exchange的类型：Exchange分发消息时根据类型的不同分发策略有区别，目前共四种类型：
										direct、 fanout、 topic、 headers 。 headers 匹配 AMQP 消息的 header而不是路由键，
										headers 交换器和 direct 交换器完全一致，但性能差很多，目前几乎用不到了，
										所以直接看另外三种类型：
									1、Direct Exchange：完全匹配、单播模式（消息中的routing-key与消息队列中的binding key完全一致）
									2、Fanout（扇出） Exchange：广播模式（与消息中的routing-key无关的，交换器将消息转发到所有的消息队列里）
									3、Topic Exchange：模式匹配分发消息，将路由键与绑定键的字符用.隔开，支持识别通配符：符号“#”和符号 “*” 。
													   #匹配0个或多个单词，*匹配一个单词。
				与Springboot的整合：
					1、添加依赖：
						 <dependency>
							<groupId>org.springframework.boot</groupId>
							<artifactId>spring-boot-starter-amqp</artifactId>
						</dependency>
					2、配置文件中添加配置：
							#RabbitMQ相关的配置信息
							spring.rabbitmq.host=127.0.0.1
							spring.rabbitmq.port=5672
							spring.rabbitmq.username=guest
							spring.rabbitmq.password=guest
					3、申明使用：
						AmqpTemplate - 发送消息
						@RabbitListener(queues="") - 监听消息
						
		七、Springboot与检索ElasticSearch：
				简介：ElasticSearch是一个分布式搜索服务，提供Restful API，底层基于Apache Lucene，采用多shard（分片）的方式保证数据安全，并且提供自动resharding的功能，
					  github等大型的站点也是采用了ElasticSearch作为其搜索服务。
				特点：1、分布式实时文件存储，并将每一个字段都编入索引
					  2、实时分析的分布式搜索引擎
					  3、可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据（1PB=1024TB）
				与Mysql对比：
					关系数据库     ⇒ 数据库         ⇒ 表          ⇒ 行              ⇒ 列(Columns)
					Elasticsearch  ⇒ 索引(Index)    ⇒ 类型(type)  ⇒ 文档(Docments)  ⇒ 属性/字段(Fields)
				注意与MongoDB的区别：数据库         ⇒ 集合        ⇒ 文档            ⇒ 属性
				交互：与Elasticsearch的交互，可以使用Java API，也可以直接使用HTTP的Restful API方式
				核心：提供了强大的索引功能；
				与Springboot的整合：
					1、添加依赖：
						 <dependency>
							<groupId>org.springframework.boot</groupId>
							<artifactId>spring-boot-starter-data-elasticsearch</artifactId>
							<version>2.0.2.RELEASE</version>
						</dependency>
					2、配置文件中添加配置：	
						#elasticsearch集群名称，默认的是elasticsearch
						spring.data.elasticsearch.cluster-name=
						#节点的地址 注意api模式下端口号是9300，千万不要写成9200
						spring.data.elasticsearch.cluster-nodes=192.168.11.24:9300
						#是否开启本地存储
						spring.data.elasticsearch.repositories.enable=true
					3、申明使用：
						参考：https://blog.csdn.net/linzhiqiang0316/article/details/80343401	
						ElasticsearchRepository、 ElasticsearchTemplate、 JestClient
						
		八、Springboot与任务：
				异步：与第三方系统交互的时候，往往采用异步任务。在Spring 3.x之后，就已经内置了@Async来完美解决这个问题。使用@EnableAysnc、 @Aysnc即可；
				定时：Spring为我们提供了异步执行任务调度的方式，提供TaskExecutor、TaskScheduler接口。@EnableScheduling（开启）、@Scheduled（定时）
					  如：@Scheduled(fixedRate = 1000)//fixedRate函数每隔1S执行一次，也可以使用@Scheduled(cron="...")
						  public void method1(){}
						  @EnableScheduling
						  public class DemoApplication {}
					  cron表达式：
						秒（0-59） 分（0-59） 小时（0-23） 日期或天（1-31） 月份（1-12） 星期（0-7或SUN-SAT 0,7是SUN）
						特殊字符的含义：,（枚举）-（区间）*（任意）/（步长）？（日/星期冲突匹配）L（最后）W（工作日）C（和calendar联系后计算过的值）#（星期，4#2，第2个星期四）
						举例："0 0 12 * * ?" 每天中午12点触发
		
		九、Springboot与邮件任务：				
				参考：https://www.cnblogs.com/zhangyinhua/p/9277684.html
				自动装配类JavaMailSender.send();//发送邮件
		十、Springboot与安全：
				简介： Security是针对Spring项目的安全框架，也是Spring Boot底层安全模块默认的技术选型。
					   它可以实现强大的web安全控制。对于安全控制，仅需引入spring-boot-starter-security模块，进行少量的配置，即可实现强大的安全管理。
				使用：参考：https://www.cnblogs.com/ealenxie/p/9293768.html
				    重要的类：
					   WebSecurityConfigurerAdapter：自定义Security策略
					   AuthenticationManagerBuilder：自定义认证策略
					   @EnableWebSecurity：开启WebSecurity模式
					核心概念：
					   “认证”（Authentication）和“授权”（Authorization或者访问控制）两大目标
					web/http与安全：
						1. 登陆/注销
						– HttpSecurity配置登陆、注销功能
						2. Thymeleaf提供的SpringSecurity标签支持，需要引入thymeleaf-extras-springsecurity4						
						– sec:authentication=“” 获得当前用户的用户名
						– sec:authorize=“hasRole(‘ADMIN’)” 当前用户必须拥有ADMIN权限时才会显示标签内容
						3. remember me
						– 表单添加remember-me的checkbox
						– 配置启用remember-me功能
						4. CSRF（Cross-site request forgery）跨站请求伪造
						– HttpSecurity启用csrf功能，会为表单添加_csrf的值，提交携带来预防CSRF；
					
					
					与shiro的区别：
						Shiro是Apache 的Java的一个安全框架。
						Shiro的特点 易于理解的 Java Security API；
									简单的身份认证（登录），支持多种数据源；
									对角色的简单的签权（访问控制），支持细粒度的签权；
									支持一级缓存，以提升应用程序的性能；
									内置的基于POJO企业会话管理，适用于Web以及Web的环境；
									非常简单的加密 API；
									异构客户端会话访问；
									不跟任何的框架或者容器捆绑，可以独立运行；
									Authentication：身份认证/登录；
									Authorization：授权，即权限验证，验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限；
									Session Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中；会话可以是普通JavaSE环境的，也可以是如Web环境的；
									Cryptography：加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储；
									Web Support：Web支持，可以非常容易的集成到Web环境；
									Caching：缓存，比如用户登录后，其用户信息、拥有的角色/权限不必每次去查，这样可以提高效率；
									Concurrency：shiro支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去；
									Testing：提供测试支持；
									Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问；
									Remember Me：记住我，即一次登录后，下次再来的话不用登录了
						
						Shiro四大核心功能：Authentication,Authorization,Cryptography,Session Management
						Shiro三个核心组件：Subject, SecurityManager 和 Realms.
							Subject：主体，代表了当前“用户”，这个用户不一定是一个具体的人，与当前应用交互的任何东西都是Subject，如网络爬虫，机器人等；
									 即一个抽象概念；所有Subject都绑定到SecurityManager，与Subject的所有交互都会委托给SecurityManager；可以把Subject认为是一个门面；SecurityManager才是实际的执行者；
							SecurityManager：安全管理器；即所有与安全有关的操作都会与SecurityManager交互；且它管理着所有Subject；
											 可以看出它是Shiro的核心，它负责与后边介绍的其他组件进行交互，如果学习过SpringMVC，你可以把它看成DispatcherServlet前端控制器；
							Realms：域，Shiro从从Realm获取安全数据（如用户、角色、权限），就是说SecurityManager要验证用户身份，那么它需要从Realm获取相应的用户进行比较以确定用户身份是否合法；
									也需要从Realm得到用户相应的角色/权限进行验证用户是否能进行操作；可以把Realm看成DataSource，即安全数据源。
						
						Security：基于Spring的企业应用系统提供声明式的安全访问控制解决方案的安全框架。
							      在Spring应用上下文中配置的Bean，充分利用了Spring IoC，DI（IoC：Inversion of Control控制反转,DI:Dependency Injection依赖注入）和AOP（面向切面编程）功能，
								  为应用系统提供声明式的安全访问控制功能，减少了为企业系统安全控制编写大量重复代码的工作。
								  Web/Http 安全：通过建立 filter 和相关的 service bean 来实现框架的认证机制。
								  AuthenticationManager：处理来自于框架其他部分的认证请求。
								  AccessDecisionManager：为 Web 或方法的安全提供访问决策。
								  AuthenticationProvider：AuthenticationManager 是通过它来认证用户的。
								  UserDetailsService：跟 AuthenticationProvider 关系密切，用来获取用户信息的。
						
							授权含义：OAuth2.0（三方授权登录）授权协议
								
													OAuth2.0 内部回调先获取token，再用token（令牌，权限范围
													和有效期）授权登录，获取用户信息
								客户端（豆瓣）  ----------------------------------------------------->   授权层、服务提供商（QQ认证服务器）
												<----------------------------------------------------
												     向客户端开放用户储存的信息，提供信息
								OpenID ：身份认证，即如何通过 URI 来认证用户身份。如果使用OpenID，你的网站地址（URI）就是你的用户名，而你的密码安全的存储在一个 OpenID 服务网站上。
								         主要原理：
										 主要原理是
											1. 首先得拥有一个合法的OpenID帐号，也就是说需要在一个验证服务器申请了一个帐号。
											2. 你有了这个帐号之后，就可以在任何一个其他支持OpenID验证的网站，并且用你上面申请的OpenID进行登录
											3. 因为这个网站并不知道你的身份是否正确，所以它会请求你的验证服务器对你的身份进行验证。
											4. 验证服务器告诉网站说，你是合法用户
											5. 网站接受你的身份，让你进入。
 
								区别：OAuth关注的是authorization；而OpenID侧重的是authentication
							
		十一、Springboot与分布式：				
				常见的分布式：zookeeper+dubbo组合，springCloud全栈技术以及spring Cloud Alibaba分布式解决方案
				架构演变：
					单一应用架构（all in one）：流量1~10，用于简化增删改查工作量的数据访问框架(ORM)是关键
					垂直应用架构：流量10~1000，将应用拆成互不相干的几个应用，以提升效率。此时，出现用于加速前端页面开发的Web框架(MVC)是关键
					分布式服务架构：流量1000~10000 ，当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心。此时，
									用于提高业务复用及整合的分布式服务框架(RPC)是关键
					流动计算架构：流量10000+，当服务越来越多，容量的评估，此时需增加一个调度中心基于访问压力实时管理集群容量，
								  提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)是关键
				
				zookeeper：（服务的注册中心）ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务。它是
						   一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等
						   压力较小，zk 将全量数据存储在内存，高性能，而且支持集群。
				dubbo：（服务的治理）Dubbo是Alibaba开源的分布式服务框架，特点分层架构解耦，从服务的模型分为服务的提供者与消费者。- DubboX当当网
				使用参考：https://blog.csdn.net/zhengzhaoyang122/article/details/81877595	   
								
				SpringCloud：是一个分布式的整体解决方案。Spring Cloud为开发者提供了在分布式系统（配置管理，服务发现，熔断，路由，微代理，控制总线，
							 一次性token，全局琐，leader选举，分布式session，集群状态）中快速构建的工具，使用Spring Cloud的开发者可以快速的启动服务
							 或构建应用、同时能够快速和云平台资源进行对接。（详情参考SpringCloud技术栈）
		
		十二、Springboot与热部署：	
				1、禁用模板引擎的cache，使用ctrl+F9重新编译页面
				2、官方提供的Spring Loaded
				    方式一：添加依赖
					<dependency>
						<groupId>org.springframework</groupId>
						<artifactId>springloaded</artifactId>
						<version>1.2.8.RELEASE</version>
					</dependency>
					方式二：maven仓库下载，下载地址：http://mvnrepository.com/artifact/org.springframework/springloaded
				    运行（VM arguments）时参数；-javaagent:C:/springloaded-1.2.5.RELEASE.jar –noverify
				3、devtools
				   添加依赖：
				   <dependency>
						<groupId>org.springframework.boot</groupId>
						<artifactId>spring-boot-devtools</artifactId>
						<optional>true</optional>
					</dependency>
					配置设置：
					#热部署生效
					spring.devtools.restart.enabled: true
					#设置重启的目录
					#spring.devtools.restart.additional-paths: src/main/java
					#classpath目录下的WEB-INF文件夹内容修改不重启
					spring.devtools.restart.exclude: WEB-INF/**
					IDEA配置，修改了Java类后，IDEA默认是不自动编译的。自动编译：（1）File-Settings-Compiler-Build Project automatically
																				（2）ctrl + shift + alt + /,选择Registry,勾上 Compiler autoMake allow when app running
				4、JRebel热部署插件
				    安装：
						点击File -> Settings -> Plugins,如下图：搜索JRebel安装，重启IDEA工具即可
		十三、Springboot与监控：		
				使用：
					添加依赖
					<dependency>
						<groupId>org.springframework.boot</groupId>
						<artifactId>spring-boot-starter-actuator</artifactId>
					</dependency>
				监控端点分类：
					应用配置类：/autoconfig /configprops /beans /env /mappings /info
					
					度量指标类：/metrics /health /dump /trace /auditevents
					
					操作控制类：/shutdown（关闭应用，默认关闭的） 可以在application.properties中配置开启：endpoints.shutdown.enabled=true
				
				通过http方式访问监控端点
				定制端点信息：endpoints+端点名+属性名进行设置，如：
					修改端点id（endpoints.beans.id=mybeans）
					– 开启远程应用关闭功能（endpoints.shutdown.enabled=true）
					– 关闭端点（endpoints.beans.enabled=false）
					– 开启所需端点
					• endpoints.enabled=false
					• endpoints.beans.enabled=true
					– 定制端点访问根路径
					• management.context-path=/manage
					• management.port=20001
					– 关闭http端点
					• management.port=-1		
					
----------------------------------------------SpringCloud技术栈篇---------------------------------------------------------						  
	基础概念：
	    微服务：强调的是服务的大小，它关注的是某一个点，是具体解决某一个问题/提供落地对应服务的一个服务应用
		-最早提出：马丁福勒
				微服务化的核心是将传统的一站式应用，根据业务拆分成一个一个的服务，彻底
		地去耦合,每一个微服务提供单个业务功能的服务，一个服务做一件事，
		从技术角度看就是一种小而独立的处理过程，类似进程概念，能够自行单独启动
		或销毁，拥有自己独立的数据库。
		微服务架构：架构模式，微服务之间互相协调、互相配合，每个服务运行在其独立的进程中，
			服务与服务间采用轻量级的通信机制互相协作（通常是基于HTTP协议的RESTful API），包括一些环境，有机构成的整体。
		优点缺点：
		-优点：内聚小，松耦合，拥有独立的进程，开发简单；
			   易于与第三方集成，如：与持续自动化构建部署（Jenkins, Hudson）
			   微服务只是业务逻辑的代码，不会和HTML,CSS 或其他界面组件混合（前后端分离思想）。
		-缺点：开发人员要处理分布式系统的复杂性
			   多服务运维难度，随着服务的增加，运维的压力也在增大
			   系统部署依赖
			   服务间通信成本、数据一致性、系统集成测试、性能监控……
		微服务技术栈：
			微服务条目			落地技术											备注			               
			
			服务开发			Springboot、Spring、SpringMVC
			服务配置与管理		Netflix公司的Archaius、阿里Diamond等
			服务注册与发现		Eureka、Consul、Zookeeper、AliBabaNacos等
			服务调用			Rest、RPC、gRPC
			服务熔断器			Hystrix、Envoy等
			负载均衡			Ribbon、Feign Nginx等
			服务接口调用(客户端调用服务的简化工具)
								Feign等
			消息队列			Kafka、RabbitMQ、ActiveMQ等
			服务配置中心管理  	SpringCloudConfig、Chef等
			服务路由（API网关） Zuul、Spring Cloud Gateway等
			服务监控			Zabbix、Nagios、Metrics、Spectator等
			全链路追踪			Zipkin，Brave、Dapper、Sleuth等
			服务部署			Docker、OpenStack、Kubernetes等
			数据流操作开发包	SpringCloud Stream（封装与Redis,Rabbit、Kafka等发送接收消息）
			事件消息总线    	Spring Cloud Bus
			......
    SpringCloud入门介绍：
		含义：SpringCloud=分布式微服务架构下的一站式解决方案，是各个微服务架构落地技术的集合体，俗称微服务全家桶
		与springboot之间关系：SpringBoot可以离开SpringCloud独立使用开发项目，
							  但是SpringCloud离不开SpringBoot，属于依赖的关系.
							  SpringBoot专注于快速、方便的开发单个微服务个体，SpringCloud关注全局的服务治理框架。
		与Dubbo的比较： 最大区别：SpringCloud抛弃了Dubbo的RPC通信，采用的是基于HTTP的REST方式。
						REST相比RPC更为灵活，服务提供方和调用方的依赖只依靠一纸契约，这在强调快速演化的微服务环境下，显得更加合适。
						品牌机与组装机的区别
						Spring Cloud的功能比DUBBO更加强大，涵盖面更广，而且作为Spring的拳头项目，它也能够与Spring Framework、Spring Boot、Spring Data、Spring Batch等其他Spring项目完美融合，这些对于微服务而言是至关重要的。
						使用Dubbo构建的微服务架构就像组装电脑，各环节我们的选择自由度很高；
						而Spring Cloud就像品牌机，在Spring Source的整合下，做了大量的兼容性测试，保证了机器拥有更高的稳定性。
						社区支持与更新力度
						最为重要的是，DUBBO停止了5年左右的更新，虽然2017.7重启了(刘军)。对于技术发展的新需求，需要由开发者自行拓展升级（比如当当网弄出了DubboX），这对于很多想要采用微服务架构的中小软件组织，显然是不太合适的，中小公司没有这么强大的技术能力去修改Dubbo源码+周边的一整套解决方案，并不是每一个公司都有阿里的大牛+真实的线上生产环境测试过。
	简单服务调用：
			-RestTemplate + API 使用方式： 
			 RestTemplate提供了多种便捷访问远程Http服务的方法，是一种简单便捷的访问restful服务模板类，是Spring提供的用于访问Rest服务的客户端模板工具集 
			使用步骤：
			1，注入Bean：
			如：@Configuration
				public class ConfigBean
				{
				 @Bean
				public RestTemplate getRestTemplate()
					{
				return new RestTemplate();
					}
				}
			2，声明使用：
			@Autowired
			private RestTemplate restTemplate;
			
			方法中：
			restTemplate.postForObject(REST_URL_PREFIX+"/dept/add", dept, Boolean.class); - 参数：REST请求地址、请求参数、HTTP响应转换被转换成的对象类型

	服务注册与发现：
			-Eureka(C/S)：
				简介：Netflix公司的子模块，是一个基于REST的服务，用于定位服务，以实现云端中间层服务发现和故障转移。Netflix在设计Eureka时遵守的就是AP原则
				CAP原则：CAP原则又称CAP定理，指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可兼得
				三大角色：1、Eureka Server 提供服务注册和发现；2、Service Provider服务提供方将自身服务注册到Eureka，从而使服务消费方能够找到；3、Service Consumer服务消费方从Eureka获取注册服务列表，从而能够消费服务
			使用注册：
				服务端：
				1,引用模块：POM.XML
					<dependency>
					<groupId>org.springframework.cloud<groupId>
					<artifactId>spring-cloud-starter-eureka-server<artifactId>
					</dependency>
				2,配置参数：application.properties或YML文件的配置
				格式：eureka.instance.hostname=localhost
					  #不要向注册中心注册自己
					  eureka.client.register-with-eureka=false
					  #禁止检索服务
					  eureka.client.fetch-registry=false
					  eureka.client.service-url.defaultZone=http://${eureka.instance.hostname}:${server.port}/eureka	
				3,申明使用：程序main入口，添加@EnableEurekaServer注解，来开启服务注册中心
				客户端：
				1,引用模块：POM.XML
					 <dependency>
						<groupId>org.springframework.cloud</groupId>
						<artifactId>spring-cloud-starter-eureka</artifactId>
					</dependency>
				2,配置参数：application.properties或YML文件的配置
				格式：
					#设置服务名
					spring:
					  application:
						name: 服务名
					eureka:
						  client: #客户端注册进eureka服务列表内
							service-url: 
							  defaultZone: http://localhost:7001/eureka
							  instance:
								instance-id: 服务实例名（设置后可以隐藏主机名）
							  prefer-ip-address: true #访问路径可以显示IP地址
							  #点击显示
							  info:
								  app.name: 服务程序名
								  company.name: 公司名
								  build.artifactId: $project.artifactId$
								  build.version: $project.version$
							  
				3,申明使用：主类上添加@EnableEurekaClient注解以实现Eureka中的DiscoveryClient实现，可以使用@EnableDiscoveryClient代替
			使用发现：
				申明使用，主启动类添加@EnableDiscoveryClient
			    使用时注入， @Autowired
							 private DiscoveryClient client;即可使用，注：DiscoveryClient是spring clould 对治理体系的一个抽象
			自我保护机制：某时刻某一个微服务不可用了，eureka不会立刻清理，依旧会对该微服务的信息进行保存
			集群处理：
				在Eureka服务器中添加配置：
				eureka: 
					instance:
						hostname: eureka1.com #eureka服务端的实例名称
					client: 
						register-with-eureka: false #false表示不向注册中心注册自己。
						fetch-registry: false #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务
					service-url: 
					#单机 defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/       #设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址（单机）。
					defaultZone: http://eureka1.com:7002/eureka/,http://eureka3.com:7003/eureka/
			与Dubbo的Zookeeper的比较：
				著名的CAP理论指出，一个分布式系统不可能同时满足C(一致性)、A(可用性)和P(分区容错性)。由于分区容错性P在是分布式系统中必须要保证的，因此我们只能在A和C之间进行权衡。
				因此,Zookeeper保证的是CP,Eureka则是AP。因此，Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服务瘫痪。

			-Consul：
				简介：Spring Cloud Consul是分布式的、高可用、横向扩展(AP原则)，它包含多个组件，但是作为一个整体，在微服务架构中为我们的基础设施提供服务发现和服务配置的工具。它包含了下面几个特性：
					  服务发现（service discovery）
					  健康检查（health checking）
					  Key/Value存储（一个用来存储动态配置的系统）
					  多数据中心（multi-datacenter）
				使用-客户端：
				1,引用模块：POM.XML
					<dependency>
					  <groupId>org.springframework.cloud</groupId>
					  <artifactId>spring-cloud-starter-consul-discovery</artifactId>
					</dependency>
				2,配置参数：application.properties或YML文件的配置
				格式：
					  spring.cloud.consul.host=localhost #域名
					  spring.cloud.consul.port=8500 #端口
	
				3,申明使用：程序main入口，添加@EnableDiscoveryClient注解，开启服务治理
				注意：consul不需要创建类似eureka-server的服务端吗？由于Consul自身提供了服务端，所以我们不需要像之前实现Eureka的时候创建服务注册中心，直接通过下载consul的服务端程序就可以使用。
				启动consul服务：$consul agent -dev
				
			-Nocas：
				参考Spring Cloud Alibaba 技术站的Nocas相关内容；
				
				详情参考：https://blog.csdn.net/qq_38765404/article/details/89521124

	负载均衡：
			-Ribbon（结合Eureka使用）：
			 简介：基于Netflix实现的一套客户端负载均衡的工具，主要功能是提供客户端的软件负载均衡算法。
			 负载均衡：将用户的请求基于某种规则平摊的分配到多个服务上，从而达到系统的HA，常见的负载均衡有软件Nginx，LVS，硬件F5等
				分类：集中式LB-即在服务的消费方和提供方之间使用独立的LB设施(可以是硬件，如F5, 也可以是软件，如nginx), 由该设施负责把访问请求通过某种策略转发至服务的提供方；
					  进程内LB-将LB逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选择出一个合适的服务器。Ribbon就属于进程内LB。
			 使用：
				1,引用模块：POM.XML
					 <dependency>
						<groupId>org.springframework.cloud</groupId>
						<artifactId>spring-cloud-starter-ribbon</artifactId>
					</dependency>
					<dependency>
						<groupId>org.springframework.cloud</groupId>
						<artifactId>spring-cloud-starter-eureka</artifactId>
					</dependency>
				2,配置参数：application.properties或YML文件的配置
				格式：（eureka配置）
					server:
						port: 80
						eureka:
							client:
							register-with-eureka: false
							service-url: 
							defaultZone: http://eureka1.com:7001/eureka/,http://eureka2.com:7002/eureka/,http://eureka3.com:7003/eureka/
	
				3,申明使用：1、程序main入口，添加@EnableDiscoveryClient注解，开启服务治理；2、在配置文件ConfigBean 中添加@LoadBalanced注解
				  -》结论：Ribbon和Eureka整合后服务消费方可以直接调用服务而不用再关心地址和端口号
			    4,策略IRule：简单轮询负载均衡RoundRobinRule，区别于RetryRule，随机负载均衡，加权响应时间负载均衡 ，区域感知轮询负载均衡
			 自定义Ribbon：	
				主启动类添加@RibbonClient注解，格式：@RibbonClient(name="MICROSERVICECLOUD",configuration=MySelfRule.class)，注意：这个自定义配置类不能放在@ComponentScan所扫描的当前包下以及子包下，
					否则我们自定义的这个配置类就会被所有的Ribbon客户端所共享，也就是说我们达不到特殊化定制的目的了。
				在配置文件ConfigBean中添加@LoadBalanced注解
			
			-Feign（声明式服务调用，WebService客户端）：它的使用方法是定义一个接口，然后在上面添加注解，同时也支持JAX-RS（Java API for RESTful Web Services）标准的注解。
			 特性：
				可插拔式的注解支持，包括Feign注解和JAX-RS注解;
				支持可插拔的HTTP编码器和解码器;
				支持Hystrix和它的Fallback;
				支持Ribbon的负载均衡;
				支持HTTP请求和响应的压缩
			 使用：
				1,引用模块：POM.XML
					 <dependency>
						<groupId>org.springframework.cloud</groupId>
						<artifactId>spring-cloud-starter-feign</artifactId>
					</dependency>
					　<dependency>
						<groupId>org.springframework.cloud</groupId>
						<artifactId>spring-cloud-starter-eureka</artifactId>
						<version>1.3.5.RELEASE</version>
					</dependency>
				2,配置参数：application.properties或YML文件的配置
				格式：（整合eureka配置）
					server:
						port: 80
						eureka:
							client:
							register-with-eureka: false
							service-url: 
							defaultZone: http://eureka1.com:7001/eureka/,http://eureka2.com:7002/eureka/,http://eureka3.com:7003/eureka/
	
				3,申明使用：1、程序main入口，添加@EnableDiscoveryClient注解，开启服务治理；同时添加@EnableFeignClients 来开启feign
			                2, 定义接口：
							   格式：value=“服务名称”,configuration = xxx.class 这个类配置Hystrix的一些精确属性
			                   @FeignClient(value = "serviceName",fallback = FeignFallBack.class)
							    public interface FeignService {
									@RequestMapping(value = "/ml", method= RequestMethod.GET)
									String method1(@RequestParam("name") String name) ;
								}
								@Component
								public class FeignFallBack implements FeignService{
							　　//实现的方法是服务调用的降级方法
								@Override
								public String method1() {
									return "error";
								}
								
	服务熔断器（断路器）：		 
			-Hystrix：
			 概念来源：服务雪崩：
				服务扇出：多个微服务之间调用的时候，假设微服务A调用微服务B和微服务C，微服务B和微服务C又调用其它的微服务，这就是所谓的“扇出”效应。
				解决方案：熔断模式（容错处理机制）、隔离模式（容错处理机制）、限流模式（预防模式）
			 简介：Hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统（SOA面向服务架构）里，许多依赖不可避免的会调用失败，比如超时、异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，以提高分布式系统的弹性。
				   “断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控（类似熔断保险丝），
				   向调用方返回一个符合预期的、可处理的备选响应（FallBack），而不是长时间的等待或者抛出调用方无法处理的异常，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。
			 服务熔断
				使用：
					概念：当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回"错误"的响应信息。 
						  SpringCloud框架里熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是5秒内20次调用失败就会启动熔断机制。熔断机制的注解是@HystrixCommand。
					1,引用模块：POM.XML
						 <dependency>
							<groupId>org.springframework.cloud</groupId>
							<artifactId>spring-cloud-starter-hystrix</artifactId>
						</dependency>
					2,配置参数：application.properties或YML文件的配置
					格式：（配合eureka配置）
						server:
							port: 80
							eureka:
								client:
								register-with-eureka: false
								service-url: 
								defaultZone: http://eureka1.com:7001/eureka/,http://eureka2.com:7002/eureka/,http://eureka3.com:7003/eureka/
		
					3,申明使用：1、程序main入口，添加@EnableCircuitBreaker注解，开启熔断支持；
								2、在控制层申明使用
									格式示例：fallbackMethod 快速应急的处理方法，进行服务降级处理
									@RequestMapping(value="/dept/get/{id}",method=RequestMethod.GET)
									@HystrixCommand(fallbackMethod = "processHystrix_Get")
									public Dept get(@PathVariable("id") Long id){
									    Dept dept =  this.service.get(id);
										if(null == dept){
										throw new RuntimeException("该ID："+id+"没有没有对应的信息");
									    }
										return dept;	
									}
									public Dept processHystrix_Get(@PathVariable("id") Long id){ 
										return new Dept().setDeptno(id)
											   .setDname("该ID："+id+"没有没有对应的信息,null--@HystrixCommand")
											   .setDb_source("no this database in MySQL");
									}
			 
			 服务降级Fallback
				使用： 
					概念：整体资源快不够了，忍痛将某些服务先关掉，待渡过难关，再开启回来。
						  服务降级处理是在客户端实现完成的，与服务端没有关系。
				    申明使用（与Feign结合使用）：	
						格式示例：
						@FeignClient(value = "MICROSERVICECLOUD",fallbackFactory=DeptClientServiceFallbackFactory.class)
						public interface DeptClientService{
							@RequestMapping(value = "/dept/get/{id}",method = RequestMethod.GET)
							public Dept get(@PathVariable("id") long id);
			            }
						
						@Component
						public class DeptClientServiceFallbackFactory implements FallbackFactory{
						
							@Override
							public Dept get(@PathVariable("id") long id){
								...
							}  
						}
						
						注意：在application.properties或YML文件的配置添加一行配置
						      feign: 
								hystrix: 
									enabled: true //开启   
			 
			 服务监控HystrixDashboard
			    使用：
				    概念：Hystrix还提供了准实时的监控（Hystrix Dashboard），Spring Cloud也提供了Hystrix Dashboard的整合，对监控内容转化成可视化界面。
					1,引用模块：POM.XML
						 <dependency>
							<groupId>org.springframework.cloud</groupId>
							<artifactId>spring-cloud-starter-hystrix</artifactId>
						</dependency>
						<dependency>
							<groupId>org.springframework.cloud</groupId>
							<artifactId>spring-boot-starter-actuator</artifactId>
						</dependency>
						
						在服务的监控一方添加如下配置
						<dependency>
							<groupId>org.springframework.cloud</groupId>
							<artifactId>spring-cloud-starter-hystrix-dashboard</artifactId>
						</dependency>
					2,配置参数：application.properties或YML文件的配置
					格式：
						server:
							port: 9901
		
					3,申明使用：1、程序main入口，添加@EnableHystrixDashboard注解，开启熔断监控的支持；
	
	路由网关：
			-Zuul：
			 概念：代理+路由+过滤三大功能，可以与Eureka整合并注册到注册中心里面
			 使用：
				1,引用模块：POM.XML
					<dependency>
						<groupId>org.springframework.cloud</groupId>
						<artifactId>spring-cloud-starter-eureka</artifactId>
					</dependency>
					<dependency>
						<groupId>org.springframework.cloud</groupId>
						<artifactId>spring-cloud-starter-zuul</artifactId>
					</dependency>
				2,配置参数：application.properties或YML文件的配置
				格式：
					zuul: 
					    prefix: /pre //前缀
						ignored-services: 服务名  //多个指定微服务以半角逗号分隔，所有可以用"*"通配符代替
						routes: 
							serverName.path: /serverName/**
							serverName.serviceId: 服务名 //给微服务起别名
							//或使用：serverName.url: http://${IP}:${PORT}/  //这种基于未使用服务注册中心的
						

				3,申明使用：1、程序main入口，添加@EnableZuulProxy注解，开启Zuul的支持；
				
	
	分布式配置中心：
				 -SpringCloud Config（与Git整合使用）
				 概念来源：分布式系统面临的---配置问题
				 概念：为微服务架构中的微服务提供集中化的外部配置支持，配置服务器为各个不同微服务应用的所有环境提供了一个中心化的外部配置
				    分类：服务端和客户端
						  服务端也称为分布式配置中心，它是一个独立的微服务应用，用来连接配置服务器并为客户端提供获取配置信息，加密/解密信息等访问接口
						  客户端则是通过指定的配置中心来管理应用资源，以及与业务相关的配置内容，并在启动的时候从配置中心获取和加载配置信息配置服务器默认采用git来存储配置信息，这样就有助于对环境配置进行版本管理，并且可以通过git客户端工具来方便的管理和访问配置内容。
					规则：1、不同环境不同配置，动态化的配置更新
						  2、运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息
						  3、当配置发生变动时，服务不需要重启即可感知到配置的变化并应用新的配置
						  4、将配置信息以REST接口的形式暴露
				 使用：
					 1、用自己的Github账户建一个统一配置中心仓库，并克隆到本地；
					 2、新建配置文件application.yml（保存格式必须为UTF-8）
					    格式参考示例：
						spring:
						  profiles:
							active:
							- dev
						---
						spring:
						  profiles: dev     #开发环境
						  application: 
							name: microservicecloud-config-dev
						---
						spring:
						  profiles: test   #测试环境
						  application: 
							name: microservicecloud-config-test
						#  请保存为UTF-8格式
					 3、push到git仓库
					 服务端配置使用：
						1,引用模块：POM.XML
							<dependency>
								<groupId>org.springframework.cloud</groupId>
								<artifactId>spring-cloud-config-server</artifactId>
							</dependency>
						2,配置参数：application.properties或YML文件的配置
									格式：	
									spring:
										application:
											name: microservicecloud-config
										cloud:
											config:
												server:
													git:
														uri: git@github.com***.git #GitHub上面的git仓库名字
						3,申明使用：1、程序main入口，添加@EnableConfigServer注解，开启Config的支持；		
						配置读取规则：
						  1、/{application}-{profile}.yml 如：http://config-3344.com:3344/application-dev.yml
						  2、/{application}/{profile}[/{label}] 如：http://config-3344.com:3344/application/dev/master
						  3、/{label}/{application}-{profile}.yml 如：http://config-3344.com:3344/master/application-dev.yml
					 客户端配置使用：
					      前提准备：
							本地仓库新建配置文件yml并提交到git仓库里，如：microservicecloud-config-client.yml
								参考示例：
									spring:
										profiles:
											active:
												- dev
									---
									server: 
										port: 8201 
									spring:
										profiles: dev
										application: 
											name: microservicecloud-config-client
									eureka: 
										client: 
											service-url: 
												defaultZone: http://eureka-dev.com:7001/eureka/   
									---
									server: 
										ort: 8202 
									spring:
										profiles: test
										application: 
											name: microservicecloud-config-client
									eureka: 
										client: 
											service-url: 
												defaultZone: http://eureka-test.com:7001/eureka/

						  1,引用模块：POM.XML
							<dependency>
								<groupId>org.springframework.cloud</groupId>
								<artifactId>spring-cloud-starter-config</artifactId>
							</dependency>
						  2,配置参数：bootstrap.yml配置文件的配置（系统级），而application.yml是用户级
									格式：	
									spring:
										cloud:
											config:
												name: microservicecloud-config-client #需要从github上读取的资源名称，注意没有yml后缀名
												profile: dev #本次访问的配置项
												label: master   
												uri: http://config-3344.com:3344  #本微服务启动后先去找3344号服务（链接Config服务端），通过SpringCloudConfig获取GitHub的服务地址
						  3,申明使用：
									测试：在控制层使用，如：@Value("${spring.application.name}")
															 private String applicationName;
						  
----------------------------------------------Spring Cloud Alibaba 技术篇---------------------------------------------------------						  
					 
	基本介绍：Spring Cloud Alibaba 致力于提供微服务开发的一站式解决方案，依托 Spring Cloud Alibaba，只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里微服务解决方案，
			  通过阿里中间件来迅速搭建分布式应用系统。
    基本技术栈：
			  1、服务限流降级：默认支持 Servlet、Feign、RestTemplate、Dubbo 和 RocketMQ 限流降级功能的接入，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控
			  2、服务注册与发现：适配 Spring Cloud 服务注册与发现标准，默认集成了 Ribbon 的支持
			  3、分布式配置管理：支持分布式系统中的外部化配置，配置更改时自动刷新
			  4、消息驱动能力：基于 Spring Cloud Stream 为微服务应用构建消息驱动能力
			  5、分布式事务：使用 @GlobalTransactional 注解， 高效并且对业务零侵入地解决分布式事务问题
			  6、阿里云对象存储：阿里云提供的海量、安全、低成本、高可靠的云存储服务。支持在任何应用、任何时间、任何地点存储和访问任意类型的数据
			  7、分布式任务调度：提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务
			  8、阿里云短信服务：覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建客户触达通道
					  
	1、服务注册与发现
		-Nocas（= Spring Cloud Eureka + Spring Cloud Config）：
				简介：Spring Cloud Alibaba 项目中开发分布式应用微服务的子组件，致力于服务发现、配置和管理微服务，基于 DNS 和基于 RPC 的服务发现。
				关键特性：
					1、服务发现和服务健康监测；
					2、动态配置服务（通过 Nacos Server 和 spring-cloud-starter-alibaba-nacos-config 实现配置的动态变更）；
					3、动态DNS服务与服务及其元数据管理（通过 Nacos Server 和 spring-cloud-starter-alibaba-nacos-discovery 实现服务的注册与发现）
				使用-客户端（服务注册与发现）：
				1,引用模块：POM.XML
					<!--Nacos的服务注册与发现模块-->
					<dependency>
						<groupId>org.springframework.cloud</groupId>
						<artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
					</dependency>
					<!--统一管理-->
					<dependencyManagement>
						<dependencies>
							<dependency>
								<groupId>org.springframework.cloud</groupId>
								<artifactId>spring-cloud-dependencies</artifactId>
								<version>Greenwich.RELEASE</version>
								<type>pom</type>
								<scope>import</scope>
							</dependency>
							<dependency>
								<groupId>org.springframework.cloud</groupId>
								<artifactId>spring-cloud-alibaba-dependencies</artifactId>
								<version>0.2.2.RELEASE</version>
								<type>pom</type>
								<scope>import</scope>
							</dependency>
						</dependencies>
				</dependencyManagement>
				2,配置参数：application.properties或YML文件的配置
				格式：
					 spring:
						  application:
							name: 程序名
						  cloud:
							nacos:
							  discovery:
								server-addr: 192.168.43.142:8848 # 服务IP与端口
									metadata: # 元数据管理
									  name1: healthy1 
									  name2: healthy2

				3,申明使用：程序main入口，添加@EnableDiscoveryClient注解，开启服务治理与发现
				
				使用-客户端（动态配置，相当于SpringCloud Config）：
				1,引用模块：POM.XML	
				<!--Nacos分布式配置模块-->
				<dependency>
					<groupId>org.springframework.cloud</groupId>
					  <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
				</dependency>
				<!--统一管理-->
				<dependencyManagement>
					<dependencies>
							<dependency>
								<groupId>org.springframework.cloud</groupId>
								<artifactId>spring-cloud-dependencies</artifactId>
								<version>Greenwich.RELEASE</version>
								<type>pom</type>
								<scope>import</scope>
							</dependency>
							<dependency>
								<groupId>org.springframework.cloud</groupId>
								<artifactId>spring-cloud-alibaba-dependencies</artifactId>
								<version>0.2.2.RELEASE</version>
								<type>pom</type>
								<scope>import</scope>
							</dependency>
					</dependencies>
				</dependencyManagement>

				2,配置参数：创建bootstrap.yml或创建bootstrap.properties文件
				格式：
					spring:
					  application:
						name: nacos-config-client # 统一配置中心客户端
					  cloud:
						nacos:
						  config:
							server-addr: 192.168.43.142:8848 # nacos服务端
							file-extension: yml
					server:
					  port: 9094 
				3、准备外部的统一配置文件：
							本地仓库新建配置文件yml（properties）并提交到git仓库里，如：nacos-config-client.properties或nacos-config-client.yml								
							# nacos默认加载的是nacos-config-client.properties文件，如果需要加载yml，需要在yml增加一行配置：file-extension: yml
				3,申明使用：程序main入口，添加@EnableDiscoveryClient注解，开启服务治理与发现	  
					  ACM （应用配置管理）配置加载规则说明：
						参考文档：https://www.alibabacloud.com/help/zh/doc-detail/94708.htm?spm=a2c63.p38356.b99.56.547b66ae7aDsVW
							# Nacos Spring Cloud 中，dataId 的完整格式如下：
							${prefix}-${spring.profile.active}.${file-extension}
							prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix来配置。
							spring.profile.active 即为当前环境对应的 profile，详情可以参考 Spring Boot文档。
							注意：当 spring.profile.active 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式变成 ${prefix}.${file-extension}
							file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。目前只支持 properties 和 yaml 类型。
							# @RefreshScope 实现配置自动更新
							
							采用默认值的应用要加载的配置规则就是：
							Data ID=${spring.application.name}.properties，Group=DEFAULT_GROUP。
	2、服务调用：
		 -Feign：声明式服务调用，与Netflix Feign 功能相似
				使用-客户端：
				1,引用模块：POM.XML	
				<!--openfeign依赖-->
				<dependency>
					<groupId>org.springframework.cloud</groupId>
					  <artifactId>spring-cloud-starter-openfeign</artifactId>
				</dependency>
				<!--Nacos的服务注册与发现模块-->
				<dependency>
					<groupId>org.springframework.cloud</groupId>
					<artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
				</dependency>
				<!--统一管理-->
				<dependencyManagement>
					<dependencies>
							<dependency>
								<groupId>org.springframework.cloud</groupId>
								<artifactId>spring-cloud-dependencies</artifactId>
								<version>Greenwich.RELEASE</version>
								<type>pom</type>
								<scope>import</scope>
							</dependency>
							<dependency>
								<groupId>org.springframework.cloud</groupId>
								<artifactId>spring-cloud-alibaba-dependencies</artifactId>
								<version>0.2.2.RELEASE</version>
								<type>pom</type>
								<scope>import</scope>
							</dependency>
					</dependencies>
				</dependencyManagement>

				2,配置参数：创建bootstrap.yml或创建bootstrap.properties文件
				格式：
					spring:
					  application:
						name: nacos-discovery-consumer-feign # 客户端名称
					  cloud:
						nacos:
						  config:
							server-addr: 192.168.43.142:8848 # nacos服务端
					server:
					  port: 9091
				3、申明使用：程序main入口，添加@EnableFeignClients注解，开启服务调用
						具体使用：定义一个接口
						@FeignClient("nacos-discovery-provider") //调用的服务名称
						public interface TestService {
							@GetMapping("/m1")
							String m1(@RequestParam(name = "name") String name);
						}

	3、其他：
		 -Webflux：替换了旧的Servlet线程模型。
		 - Spring Cloud Gateway ：网关配置，目标是替代Netflix ZUUL，其不仅提供统一的路由方式，并且基于Filter链的方式提供了网关基本的功能，例如：安全，监控/埋点，和限流等。
				使用-客户端：
				1,引用模块：POM.XML	
				<!--gateway依赖-->
				<dependency>
					<groupId>org.springframework.cloud</groupId>
					  <artifactId>spring-cloud-starter-gateway</artifactId>
				</dependency>
				<!--Nacos的服务注册与发现模块-->
				<dependency>
					<groupId>org.springframework.cloud</groupId>
					<artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
				</dependency>
				<!--统一管理-->
				<dependencyManagement>
					<dependencies>
							<dependency>
								<groupId>org.springframework.cloud</groupId>
								<artifactId>spring-cloud-dependencies</artifactId>
								<version>Greenwich.RELEASE</version>
								<type>pom</type>
								<scope>import</scope>
							</dependency>
							<dependency>
								<groupId>org.springframework.cloud</groupId>
								<artifactId>spring-cloud-alibaba-dependencies</artifactId>
								<version>0.2.2.RELEASE</version>
								<type>pom</type>
								<scope>import</scope>
							</dependency>
					</dependencies>
				</dependencyManagement>

				2,配置参数：创建bootstrap.yml或创建bootstrap.properties文件
				格式：
					spring:
						  application:
							name: nacos-discovery-gateway-server
						  cloud:
							nacos:
							  discovery:
								server-addr: 192.168.43.142:8848
								metadata:
								  name: healthy
							gateway:
							  routes:
								- id: nacos-discovery-provider
								  uri: lb://nacos-discovery-provider
								  predicates:
									- Path=/provider/**
								  filters:
									- StripPrefix=1
							  
							  discovery:
								locator:
								  enabled: true  #表明gateway开启服务注册和发现的功能，并且spring cloud gateway自动根据服务发现为每一个服务创建了一个router，这个router将以服务名开头的请求路径转发到对应的服务。
								  lowerCaseServiceId: true   #是将请求路径上的服务名配置为小写（因为服务注册的时候，向注册中心注册时将服务名转成大写的了），比如以/service-hi/*的请求路径被路由转发到服务名为service-hi的服务上。
								  filters:
									- StripPrefix=1
									
						server:
						  port: 9093

				3、申明使用：程序main入口，添加@EnableDiscoveryClient注解，开启服务调用
						使用示例：http://localhost:9093/provider/hello?name=zhansan
		 -Sentinel：
				介绍：随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 作为流量防卫组件，以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。
				特征：
					 1、丰富的应用场景：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等
					 2、完备的实时监控
					 3、广泛的开源生态：Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合
					 4、完善的 SPI（串行外设接口） 扩展点：Sentinel 提供简单易用、完善的 SPI 扩展接口。可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。
				组成：
					 核心库（Java 客户端）
					 控制台（Dashboard）		
					 使用：		
					 	 1、部署Sentinel Dashboard	
							下载地址：https://github.com/alibaba/Sentinel/releases
							启动(默认端口：8080)：
							java -jar sentinel-dashboard-1.6.0.jar
							java -jar -Dserver.port=8888 sentinel-dashboard-1.6.0.jar
							默认用户名密码：sentinel
							
						 2、核心库的配置使用：
							1,引用模块：POM.XML	
							<!--gateway依赖-->
							<dependency>
								<groupId>org.springframework.cloud</groupId>
								  <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>
							</dependency>
							<!--Nacos存储扩展-->
							<dependency>
								<groupId>org.springframework.cloud</groupId>
								<artifactId>sentinel-datasource-nacos</artifactId>
							</dependency>
							<!--统一管理-->
							<dependencyManagement>
								<dependencies>
										<dependency>
											<groupId>org.springframework.cloud</groupId>
											<artifactId>spring-cloud-dependencies</artifactId>
											<version>Greenwich.RELEASE</version>
											<type>pom</type>
											<scope>import</scope>
										</dependency>
										<dependency>
											<groupId>org.springframework.cloud</groupId>
											<artifactId>spring-cloud-alibaba-dependencies</artifactId>
											<version>0.2.2.RELEASE</version>
											<type>pom</type>
											<scope>import</scope>
										</dependency>
								</dependencies>
							</dependencyManagement>

							2,配置参数：创建bootstrap.yml或创建bootstrap.properties文件
							格式：
								spring:
								  application:
									name: nacos-discovery-sentinel
								  cloud:
									sentinel:
									  transport:
										dashboard: localhost:8888 #Sentinel Dashboard服务端地址 
									  datasource:
										ds:
										  nacos:
											server-addr: localhost:8848 #nacos服务地址
											dataId: ${spring.application.name}
											groupId: DEFAULT_GROUP
											ruleType: flow
								server:
								  port: 9095

							3、申明使用：访问sentinel服务列表并限流；通过nacos配置流控规则；
							   # 注意
								 Sentinel控制台中修改规则：仅存在于服务的内存中，不会修改Nacos中的配置值，重启后恢复原来的值。
								 Nacos控制台中修改规则：服务的内存中规则会更新，Nacos中持久化规则也会更新，重启后依然保持。
							4、优点:
									1、sentinel配置变动后通知非常的迅速, 秒杀springcloud原来的config几条街,
									   毕竟原来的config是基于git, 不提供可视化界面, 动态变更还需要依赖bus来通过所有的客户端变化
									2、与hystrix相比，sentinel更加的轻量级,并且支持动态的限流调整,更加友好的界面ui														
					
----------------------------------------------NoSQL缓存技术Redis技术篇----------------------------------------------------------------------------------								
	一、NoSQL入门：
			时代背景[架构演变]：
				单机MySQL:APP->DAL（数据访问层）->MySQL Instance （读写混合）
				Memcached(缓存)+MySQL+垂直拆分：（原因：数据量上升，复杂的数据结构[B+Tree]），引入了Memcached分布式缓存技术，为web服务提供缓存（弊端：hash的一致性引发缓存失效），
												APP->DAL（数据访问层）->cache
				Mysql主从复制读写分离：（原因：Memcached(缓存)解决了数据库读的问题，而写的问题依然严重），出现了Mysql的master-slave模式
																				  ->S（Read）
												APP->DAL（数据访问层）->cache -> M（Write）
																				  ->S（Read）
				分表分库+水平拆分+MySQL集群：（原因：流量数据，Mysql主从复制读写分离写的问题日趋严重），出现了MySQL Cluster集群
				Mysql扩展瓶颈：大文本字段效率低
				NOSQL：处理大数据运用而生				
																																								中间件
				当今架构流程：					企业级防火墙/负载均衡Nginx设备										DAL											  ------------>实时通讯/流媒体/移动信息/电子邮件等服务器					
								客户请求  --------------------------------------->  APP服务器（多台） ------------------------------> Mysql Cluster集群数据库 ------------>缓存服务器
																																							  ------------>文件（图片）服务器																
			扩展：高性能架构思路，对于高性能网站，请求量大，如何支撑?				
				1）必要减少请求
				   对于开发人员，提高开发质量（合并css，处理背景图片，优化mysql查询等），对于运维人员善用缓存，如：nginx的expires，利用浏览器缓存等,减少查询
				2）利用cdn技术来响应请求，CDN加速技术
				   CDN：Content Delivery Network，即内容分发网络。
				   CDN是构建在网络之上的内容分发网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。
				   CDN的关键技术主要有内容存储和分发技术。
				3）对请求的处理：服务器集群+负载均衡来支撑，这一步思考如何更好的响应高并发请求，既然请求是不可避免的，我们要做的是把工作内容”平均”分给每台服务器，最理想的状态每台服务器的性能都被充分利用

			含义：NoSQL(NoSQL = Not Only SQL )，意即“不仅仅是SQL”，泛指非关系型的数据库
			特点：易扩展、大数据量高性能、多样灵活的数据模型（适合于查询、增删字段是一件非常麻烦的事情）
			比较：
				RDBMS vs NoSQL
				RDBMS
				- 高度组织化结构化数据
				- 结构化查询语言（SQL）
				- 数据和关系都存储在单独的表中。
				- 数据操纵语言，数据定义语言
				- 严格的一致性
				- 基础事务
				NoSQL
				- 代表着不仅仅是SQL
				- 没有声明性查询语言
				- 没有预定义的模式
				- 键值对存储，列存储，文档存储，图形数据库
				- 最终一致性，而非ACID属性（数据库事务四个基本要素，原子性[Atomicity]、一致性[Consistency]、隔离性/独立性[Isolation]、持久性[Durability]）
				- 非结构化和不可预知的数据
				- CAP定理（指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可兼得）
				- 高性能，高可用性和可伸缩性
			基础产品：Redis、memcache、Mongdb
			大数据时代的特点：
				3V + 3高
					3V：海量Volume、多样Variety、实时Velocity
					3高：高并发、高可扩、高性能
			经典案例：以阿里巴巴的商品信息存放为例
					  架构演变：Orcale -> Java Servlet -> EJB -> 去EJB重构（Ibatis）-> 海量数据：Memcached 集群，分布式存储，Mysql数据拆分 -> 安全、镜像（敏捷、开放[网站开放，允许第三方接入]、体验）
					  数据源数据类型存储问题（数据层）：关系数据库MySQL、搜索引擎、缓存Memcached、KV、文档数据库、外部数据接口（银行）、列数据库...
					  商品信息存放：
						基础信息：存储关系型数据库（MySQL，去Oracle），如：商品价格、名称
						描述性、评价详情信息（多文字类）：文档数据库MongDB中，多文字信息，关系型数据库IO读写性能变差
						图片：分布式的文件存储系统，如：TFS（淘宝）、GFS（Google）、HDFS（Hadoop）
						商品关键字：搜索引擎
						商品的波段性的热点高频信息：缓存数据库
						计算类：外部系统，外部第3方支付接口
						
			大数据时代数据DAL的解决方案：UDSL（统一数据服务层）
				统一数据服务层的特征：
					映射：传统的ORM框架是不能实现跨多数据源与类型的映射，UDSL提供了解决方案
					API：UDSL提供了统一的查询与更新API，类似JPA
					热点缓存：二级缓存，实现流程：
							  网站 ->UDSL ->缓存（设置规则） ->查询/更新（根据索引、Key）
			
			NoSQL的数据模型：
				对比关系型与非关系型数据库设计：RDBMS使用ER图，NoSQL常用的BSON（是一种类似json的一种二进制形式的存储格式，				
				简称Binary JSON，支持内嵌的文档对象和数组对象）结构
				
			聚合模型：
				KV键值、bson、列族（方便数据压缩）、图形
				
			NoSQL分类：
					KV键值对：阿里、百度：memcache+redis，美团：redis+tair，新浪：BerkeleyDB+redis
					文档型数据库(bson格式比较多)：MongoDB（基于分布式文件存储的数据库）、CouchDB
					列存储数据库：分布式文件系统（Cassandra, HBase）
					图关系数据库：它不是放图形的，放的是关系比如:朋友圈社交网络、广告推荐系统，如：Neo4J, InfoGrid
			
			分布式数据库中CAP原理CAP+BASE[重点]：
				ACID：数据库事务四个基本要素，原子性[Atomicity]、一致性[Consistency]、隔离性/独立性[Isolation]、持久性[Durability]
						  原子性：说的是事务里的所有操作要么全部做完，要么都不做，事务成功的条件是事务里的所有操作都成功，只要有一个操作失败，整个事务就失败，需要回滚
						  一致性：数据库要一直处于一致的状态，事务的运行不会改变数据库原本的一致性约束，也即在事务开始之前和事务结束以后，数据库的完整性没有被破坏
						  独立性：指并发的事务之间不会互相影响，如果一个事务要访问的数据正在被另外一个事务修改，只要另外一个事务未提交，它所访问的数据就不受未提交事务的影响
						  持久性：一旦事务提交后，它所做的修改将会永久的保存在数据库上，即使出现宕机也不会丢失
						  
				CAP：指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可兼得（三选二）
					 说明：由于当前的网络硬件肯定会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的，所以只能在一致性和可用性之间进行权衡
						对比：   
								产品				   		原则 	特点
							传统关系型数据库RDBMS			AC    	单点集群，满足一致性，可用性的系统，通常在可扩展性上不太强大
							大多数网站架构					AP		满足可用性，分区容忍性的系统，通常可能对一致性要求低一些
							Redis、Mongodb、HBase			CP		满足一致性，分区容忍性的系统，通常性能不是特别高
						   
						结论：强一致性和可用性之间取一个平衡。大多数web应用，其实并不需要强一致性（尤其是读的一致性）。因此牺牲C换取A，这是目前分布式数据库产品的方向
				BASE：
					为了解决关系数据库强一致性引起的问题而引起的可用性降低而提出的解决方案
					BASE其实是下面三个术语的缩写：
					基本可用（Basically Available）
					软状态（Soft state）
					最终一致（Eventually consistent）
					它的思想是通过让系统放松对某一时刻数据一致性的要求（实时性）来换取系统整体伸缩性和性能上改观。
					因为在于大型系统往往由于地域分布和极高性能的要求，不可能采用分布式事务来完成这些指标，
					要想获得这些指标，我们必须采用另外一种方式来完成，这里BASE就是解决这个问题的办法。
				分布式与集群：
					分布式系统：由多台计算机和通信的软件组件通过计算机网络连接组成，具有高度的内聚性和透明性。
					分布式：不同的多台服务器上面部署不同的服务模块（工程），他们之间通过Rpc/Rmi（Remote Method Invocation,远程方法调用，仅支持Java语言）之间通信和调用，对外提供服务和组内协作
					集群：不同的多台服务器上面部署相同的服务模块，通过分布式调度软件进行统一的调度，对外提供服务和访问
					
	一、NoSQL入门：
		Redis:
			含义：REmote DIctionary Server(远程字典服务器)，是完全开源免费的，用C语言编写的，遵守BSD开源协议，是一个高性能的(key/value)分布式内存数据库，
			      基于内存运行，并支持持久化的NoSQL数据库，是当前最热门的NoSql数据库之一，也称为数据结构服务器
			与其他的KV缓存产品对比优势：
				1、Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用
				2、Redis不仅仅支持简单的Key-Value类型的数据，同时还提供string，list，set，zset，hash等数据结构的存储
				3、Redis支持数据的备份，即Master-Slave模式的数据备份
			作用：
				1、内存存储和持久化RDB/AOF：Redis支持异步将内存中的数据写到硬盘上，同时不影响继续服务
				2、发布、订阅消息系统
				3、取最新N个数据的操作，如：可以将最新的10条评论的ID放在Redis的List集合里面；模拟类似于HttpSession这种需要设定过期时间的功能；定时器、计数器
			官网：
				http://redis.io/           
				http://www.redis.cn/
				
			安装使用：
				Windows: redis-server.exe redis.conf
				Linux：企业级开发
					主要步骤：
						1、下载压缩包，下载获得redis-3.0.4.tar.gz后将它放入Linux目录/opt
						2、解压进入，/opt目录下，解压命令:tar -zxvf redis-3.0.4.tar.gz，得到redis-3.0.4文件
						3、安装，cd redis-3.0.4，在redis-3.0.4目录下执行make命令，注意：可能报错，可能原因：缺少gcc库（一款支持c语言的编译工具）的支持，下载yum install gcc-c++
						   再次安装，若报“jemalloc/jemalloc.h：没有那个文件或目录”错误，运行make distclean之后再make，测试环境：macke test（需要TCL环境支持，http://www.linuxfromscratch.org/blfs/view/cvs/general/tcl.html）
						   make完成后继续执行make install-安装
					默认安装目录：/usr/local/bin
						目录结构或文件：
							redis-benchmark：性能测试工具
							redis-check-aof：修复有问题的AOF文件
							redis-check-dump：修复有问题的dump.rdb文件
							redis-cli：客户端，操作入口
							redis-sentinel：redis集群使用[哨兵]
							redis-server：Redis服务器启动命令
					启动：	
						回到解压目录redis-3.0.4/下，主要目录或文件：redis.conf、sentinel.conf、src
						1）修改redis.conf文件将里面的daemonize no 改成 yes，让服务在后台启动
						2）备份配置文件redis.conf，如：redis.conf.bak
						3）启动：
							   安装路径下执行：redis-server [解压路径下]/redis-3.0.4/redis.conf
						   客户端测试：redis-cli（测试是否连通：ping 出现PONG说明服务通的）或 redis-cli -h 127.0.0.1 -p 6379
					关闭：
						单实例关闭：redis-cli shutdown
						多实例关闭，指定端口关闭:redis-cli -p 6379 shutdown
					基础知识：
						单进程模型：单进程模型来处理客户端的请求。对读写RW等事件的响应是通过对epoll函数的包装来做到的。
									Redis的实际处理速度完全依靠主进程的执行效率。
									epoll是Linux内核为处理大批量文件描述符而作了改进的epoll，是Linux下多路复用IO接口select/poll的增强版本，
									它能显著提高程序在大量并发连接中的系统CPU利用率。
						数据库：默认16个数据库，类似数组下标从零开始，初始默认使用零号库，切换库：select 数据库Id
								dbsize：查看当前数据库的key的数量，查看所有key： Keys *；keys 支持ANT风格，如：keys k？
								flushdb：清空当前库
								Flushall；通杀全部库
								统一密码管理：16个库都是同样密码，要么都OK要么一个也连接不上，Redis索引都是从零开始
			数据类型[重点]：
				string：是redis最基本的类型，可以理解成与Memcached一模一样的类型，一个key对应一个value。
						string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象。一个redis中字符串value最多可以是512M。
				hash：哈希无序，类似java里的Map；Redis hash 是一个键值对集合。hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。
				list：列表，是简单的字符串列表，按照插入顺序排序元素可以重复。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。它的底层实际是个链表。
				set：集合，Redis的Set是string类型的无序不可重复集合，它是通过HashSet实现实现的。
				zset：sorted set有序集合，Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。
					  不同的zset是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。
				使用：参考http://redisdoc.com/
			基本操作：
				Key：
					查看所有key： keys *
					判断某个key是否存在：exists key的名字，1表示存在，-1表示不存在
					移除key：move key db   --->当前库就没有了，被移除了
					给key设置过期时间：expire key 秒钟
					查看还剩多少秒过期：ttl key ，-1表示永不过期，-2表示已过期
					查看key的类型：type key
				String[单值单value]：
					 set/get/del/append/strlen：
					 Incr/decr/incrby/decrby：只有数字才能进行加减
					 getrange/setrange：
						 getrange：获取指定区间范围内的值，类似between......and的关系;从零到负一表示全部,如：getrange key 0 -1
						 setrange：设置指定区间范围内的值，格式是setrange key值 具体值，如：setrange key 1 xxx，1索引
					 setex(set with expire) 键 秒值/setnx(set if not exist) 键 秒值
						setex：设置带过期时间的key，动态设置。setex 键 秒值 真实值，如：setex k1 15 v1
						setnx：setnx:只有在key不存在时设置 key 的值，如：setnx k1 v1
				List[单值多value]：		
					 lpush/rpush/lrange：如：lrange list1 0 -1 	
					 lpop/rpop key：取元素[出栈]
					 lindex：通过索引获取列表中的元素，语法：lindex key index，如：lindex k1 5
					 llen：
					 lrem key 删N个value： * 从left往right删除2个值等于v1的元素，返回的值为实际删除的数量，如：LREM list1 2 v1
										   * LREM list1 0 value1，表示删除全部给定的值，零个就是全部值
					 ltrim key 开始索引 结束索引，截取指定范围的值后再赋值给key，如： ltrim key1 0 3
					 rpoplpush 源列表 目的列表：移除列表的最后一个元素，并将该元素添加到另一个列表并返回，如：rpoplpush l1 l2
					 lset key index value：指定索引位置添加元素
					 linsert key  before/after 值1 值2：插入元素，如：linsert k1 after 3 5
					总结：
						它是一个字符串链表，left、right都可以插入添加；
						如果键不存在，创建新的链表；如果键已存在，新增内容；如果值全移除，对应的键也就消失了。
						链表的操作无论是头和尾效率都极高，但假如是对中间元素进行操作，效率就很惨淡了。
				Set[单值多value，底层是hashSet]：		
					sadd/smembers/sismember：如：sadd set1 v1 v2 v3
					scard：获取集合里面的元素个数，如：scard set1
					srem key value：删除集合中元素，如：srem set1 v1
					srandmember key 某个整数：随机出几个指定个数的元数，如：srandmember set1 2
					spop key ：随机出栈，如：spop set1
					smove key1 key2 在key1里某个值：作用是将key1里的某个值赋给key2，如：smove set1 set2 v1
					数学集合类：
						差集：sdiff，在第一个set里面而不在后面任何一个set里面的项
						交集：sinter
						并集：sunion
				Hash[KV模式不变，但V是一个键值对，类似Java中的Map<String,Object>]：
					 hset/hget/hmset/hmget/hgetall/hdel：如：hmset hash1 id 1 name lisi age 20
					 hlen：
					 hexists key 在key里面的某个值的key：如：hexists hash1 id
					 hkeys/hvals key：如：hkeys hash1  ----->结果：id name age
					 hincrby/hincrbyfloat：给key里面的某个key的值增加整数/浮点数
					 hsetnx：给key里面的某个key不存在才赋值，如：hsetnx hash1 k1 44
				Zset[sorted set有序集合]：	 
					在set基础上，加一个score值。之前set是k1 v1 v2 v3，现在zset是k1 score1 v1 score2 v2	
					zadd/zrange：如：zadd z1 70 v1 80 v2 90 v3，zrange z1 0 -1 withscores
					zrangebyscore key 开始score 结束score [withscores] [limit]：如：zrangebyscore z1 (60 90 withscores			-(不包含，limit 开始下标步 多少步
					删除元素：zrem key 某score下对应的value值，如：zrem z1 v1
					zcard/zcount key score区间/zrank key 下标值/zscore key 对应值，获得分数
						zcard：获取集合中元素个数，如：zcard z1
						zcount：获取分数区间内元素个数，zcount key 开始分数区间 结束分数区间，如：zcount z1 60 80 
						zrank： 获取下标位置，如：zrank z1 v1
						zscore：按照key获得对应的分数，如：zscore z1 v1
					zrevrank key values值，作用是逆序获得下标，如：zrerank z1 v1
					zrevrange：与zrange相反
					zrevrangebyscore  key 结束score 开始score：与zrangebyscore相反
					
			配置文件[redis.conf]：
				位置：指定的配置文件目录下
				解析：
					units[单位]：
					如：
					# 1k => 1000 bytes
					# 1kb => 1024 bytes
					# 1m => 1000000 bytes
					# 1mb => 1024*1024 bytes
					# 1g => 1000000000 bytes
					# 1gb => 1024*1024*1024 bytes
						1  配置大小单位,开头定义了一些基本的度量单位，只支持bytes，不支持bit
						2  对大小写不敏感
					
					INCLUDES[包含]：
						通过includes包含，redis.conf可以作为总闸，包含其他的配置信息
						如：
						# include /path/to/local.conf
						# include /path/to/other.conf
					
					GENERAL[通用]:
						daemonize：是否开启守护进程模式，默认没有开启
						pidfile：进程ID所在文件，默认位置：pidfile /var/run/redis.pid
						port：监听端口，默认6379，如果设为0，禁用监听TCP socket
						tcp-backlog：
							设置tcp的backlog，backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列。
							在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。
							注意Linux内核会将这个值减小到/proc/sys/net/core/somaxconn的值，所以需要确认增大somaxconn和tcp_max_syn_backlog两个值来达到想要的效果。
						timeout：超时断开连接，默认0，表示关闭
						bind：绑定IP/域名，非必配项
						tcp-keepalive：单位为秒，如果设置为0，则不会进行Keepalive检测，建议设置60，长链接保持心跳，超出设置的数值，会断开socket连接
						loglevel：日志级别，默认有4种，默认是：verbose
							# debug (a lot of information, useful for development/testing)
							# verbose (many rarely useful info, but not a mess like the debug level)
							# notice (moderately verbose, what you want in production probably)
							# warning (only very important / critical messages are logged)
						logfile：日志文件名，默认：stdout # output for logging but daemonize, logs will be sent to /dev/null
						syslog-enabled：是否把日志输出到syslog中，默认NO
						syslog-ident：指定syslog里的日志标志，默认redis
							# Specify the syslog identity.
							# syslog-ident redis
						syslog-facility：指定syslog设备，值可以是USER或LOCAL0-LOCAL7，默认为local0
						databases：数据库，默认16个库，切换库：select dbid # dbid is a number between 0 and 'databases'-1
					
					SNAPSHOTTING[快照]：RDB是整个内存的压缩过的Snapshot，RDB的数据结构，可以配置复合的快照触发条件！
						Save：# Save the DB on disk 将数据保存到磁盘，语法：save <秒钟> <写操作次数> 或 save <seconds> <changes>
							默认：
							#   after 900 sec (15 min) if at least 1 key changed
							#   after 300 sec (5 min) if at least 10 keys changed
							#   after 60 sec if at least 10000 keys changed
							save 900 1 						 -15分钟内改了1次                      
							save 300 10						 -5分钟内改了10次
							save 60 10000					 -1分钟内改了1万次
						
						    注意：如果想禁用RDB持久化的策略，只要不设置任何save指令，或者给save传入一个空字符串参数也可以，如：save ""
						
						stop-writes-on-bgsave-error：默认yes，快照关闭了导致不能持久化的问题
													 即当bgsave快照操作出错时停止写数据到磁盘，这样后面写错做均会失败，为了不影响后续写操作，故需将该项值改为no。
						rdbcompression：默认开启yes，
										对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。
										如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能
						rdbchecksum：在存储快照后，还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约
									 10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能
						dbfilename：默认：dump.rdb # The filename where to dump the DB
						dir：本地数据库存放的路径，redis的路径目录，默认./
					
					REPLICATION[复制]:	# Master-Slave replication 主从复制，默认关闭该功能
										主从复制含义：主机数据更新之后，根据配置和策略，自动同步到备机的机制。Master以写为主，Slave以读为主。实现了读写分离与容灾恢复。
										Redis 支持简单易用的主从复制（master-slave replication）功能， 该功能可以让从服务器(slave server)成为主服务器(master server)的精确复制品
						语法：
							方式一：配置从服务器，只需在配置文件中增加一行：slaveof <masterip> <masterport>，如果主机有密码，需要配置访问密码：masterauth <master-password>
							方式二：通过redis客户端工具连接到从（slave）服务器，输入主服务器的IP和端口，然后同步就会开始：SLAVEOF [masterip] [masterport]						
						参数：
							slave-serve-stale-data：默认yes，表示主从复制中，从服务器可以响应客户端请求；
					SECURITY[安全]:	访问密码的查看、设置和取消
						# Require clients to issue AUTH <PASSWORD> before processing any other commands.This might be useful in environments in which you do not trust
						# others with access to the host running redis-server.
						使用[客户端连接工具设置]：
							config get requirepass												-获取
							config set requirepass "123456"										-设置，设置成功后，下次操作需要Auth
							auth 123456															-认证
					
					LIMITS[限制]:
						maxclients：客户端最大连接数限制，设置redis允许同时可以与多少个客户端进行连接。默认情况下为10000个客户端。
									如果达到了此限制，redis则会拒绝新的连接请求，并且向这些连接请求方发出“max number of clients reached”以作回应。
						maxmemory：设置redis可以使用的最大内存量。一旦到达内存使用上限，redis将会试图移除内部数据，移除规则可以通过maxmemory-policy来指定。
								   如果redis无法根据移除规则来移除内存中的数据，或者设置了“不允许移除”，那么redis则会针对那些需要申请内存的指令返回错误信息，比如SET、LPUSH等。							   
								   但是对于无内存申请的指令，仍然会正常响应，比如GET等。如果你的redis是主redis（说明你的redis有从redis），
								   那么在设置内存使用上限时，需要在系统中留出一些内存空间给同步队列缓存，只有在你设置的是“不移除”的情况下，才不用考虑这个因素。
							使用：maxmemory <bytes>
							# maxmemory can be a good idea mainly if you want to use Redis as a 'state' server or cache, not as a real DB. 
						
						maxmemory-policy[设置内存使用上限策略]：
							1）volatile-lru：使用LRU算法移除key，只对设置了过期时间的键，volatile：易发辉的意思
							2）allkeys-lru：使用LRU算法移除key
							3）volatile-random：在过期集合中移除随机的key，只对设置了过期时间的键
							4）allkeys-random：移除随机的key
							5）volatile-ttl：移除那些TTL值最小的key，即那些最近要过期的key
							6）noeviction：不进行移除。针对写操作，只是返回错误信息
						
						maxmemory-samples：设置样本数量，LRU算法和最小TTL算法都并非是精确的算法，而是估算值，所以你可以设置样本的大小，	redis默认会检查这么多个key并选择其中LRU的那个。						
										   
					APPEND ONLY MODE[追加]：默认关闭no，是否开启aof持久化
						appendonly：no
						appendfilename：append only 文件名，默认：appendonly.aof
						appendfsync：是否同步，默认有3中配置
							1）always：同步持久化，每次发生数据变更会被立即记录到磁盘，性能较差但数据完整性比较好
							2）everysec：出厂默认推荐，异步操作，每秒记录，如果一秒内宕机，有数据丢失
							3）no 从不同步
						no-appendfsync-on-rewrite：重写时是否可以运用Appendfsync，用默认no即可，保证数据安全性。
						auto-aof-rewrite-min-size：设置重写的基准值，当文件大于基准值时触发
						auto-aof-rewrite-percentage：设置重写的基准值
				
				详细参数说明[附]：
					1. Redis默认不是以守护进程的方式运行，可以通过修改该配置项，使用yes启用守护进程
					   daemonize no
					2. 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定
					   pidfile /var/run/redis.pid
					3. 指定Redis监听端口，默认端口为6379，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字
					   port 6379
					4. 绑定的主机地址
					   bind 127.0.0.1
					5. 当客户端闲置多长时间后关闭连接，超时断开连接，如果指定为0，表示关闭该功能
					   timeout 300
					6. 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose
					   loglevel verbose
					7. 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null
					   logfile stdout
					8. 设置数据库的数量，默认数据库为0，可以使用SELECT 命令切换数据库，SELECT dbid
					   databases 16
					9. 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合
						  save[快照保存] 
						  Redis默认配置文件中提供了三个条件，来保存数据：
						  save 900 1
						  save 300 10
						  save 60 10000
						  分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。
					10. 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大
					    rdbcompression yes
					11. 指定本地数据库文件名，默认值为dump.rdb
					    dbfilename dump.rdb
					12. 指定本地数据库存放目录
					    dir ./
					13. 设置当本机为slave服务时，设置master的IP及端口，在Redis启动时，它会自动从master进行数据同步
					    slaveof 
					14. 当master服务设置了密码保护时，slave服务连接master的密码
					    masterauth 
					15. 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH 命令提供密码，默认关闭
					    requirepass foobared
					16. 设置同一时间最大客户端连接数，默认无限制，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息
					    maxclients 128
					17. 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区
					    maxmemory 
					18. 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no
					    appendonly no
					19. 指定aof文件名，默认为appendonly.aof
					    appendfilename appendonly.aof
					20. 指定更新日志条件，共有3个可选值： 
					    appendfsync:
							no：表示等操作系统进行数据缓存同步到磁盘（快） 
							always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） 
							everysec：表示每秒同步一次（折中，默认值），appendfsync everysec
					21. 指定是否启用虚拟内存机制，默认值为no，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中
					    vm-enabled no
					22. 虚拟内存文件路径，默认值为/tmp/redis.swap，注意：不可多个Redis实例共享
					    vm-swap-file /tmp/redis.swap
					23. 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0
					    vm-max-memory 0
					24. Redis swap文件[redis.swap]分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的数据大小来设定的，建议如果存储很多小对象，page大小最好设置为32或者64 bytes；如果存储很大的数据对象，则可以使用更大的page，如果不确定，就使用默认值
					    vm-page-size 32						
					25. 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，在磁盘上每8个pages将消耗1byte的内存。
					    vm-pages 134217728
						# The total swap size is vm-page-size * vm-pages
					26. 设置访问swap文件[redis.swap]的线程数,最好不要超过机器的核数,如果设置为0，那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4
					    vm-max-threads 4
					27. 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启
					    glueoutputbuf yes
					28. 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法
					    hash-max-zipmap-entries 64
					    hash-max-zipmap-value 512
					29. 指定是否激活重置哈希，默认为开启
					    activerehashing yes
					30. 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件
					    include /path/to/local.conf
				
			持久化：
				RDB（Redis DataBase）：SNAPSHOTTING[快照]的使用
					含义：在指定的时间间隔内将内存中的数据集快照写入磁盘[save]，也就是行话讲的Snapshot快照，它恢复时是将dump.rdb快照文件直接读到内存里，
						  Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。					
						  整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能，如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，
						  但是RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。						  
					
										子进程								  持久化结束
						  fork ---------------------------> 临时文件	----------------------> 临时文件替换上次持久化好的文件dump.rdb
					
					Fork的作用：fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）
								数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程
				
					保存文件名：dump.rdb
					触发RDB快照：
						默认配置位置：安装目录/usr/local/bin/dump.rdb，备份后再使用：cp dump.rdb dump.bak.rdb
						save或者是bgsave：
							Save：save时只管保存，其它不管，全部阻塞
							BGSAVE[后台保存]：Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求，可以通过lastsave命令获取最后一次成功执行快照的时间。
							注意：执行flushall命令，也会产生dump.rdb文件，但里面是空的，无意义；	  
					恢复数据：
						将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可；提示：如何获取安装目录？CONFIG GET dir
					优势与劣势：
						优势：适合大规模的数据恢复，对数据完整性和一致性要求不高；
						劣势：fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑；
					
					禁用RDB：动态停止RDB保存规则：redis-cli config set save ""	
					
				AOF（Append Only File）：
					含义：以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，
						  redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。
						  
					保存文件名：appendonly.aof
					AOF启动/修复/恢复：
						正常恢复：
							启动：设置Yes，修改默认的appendonly no，改为yes
							恢复：将有数据的aof文件复制一份保存到对应安装目录(config get dir)，重启redis然后重新加载
							
						异常恢复：
							启动：设置Yes，修改默认的appendonly no，改为yes，然后备份被写坏的AOF文件，注：appendonly.aof文件损坏后重新加载启动会报错
							修复：redis-check-aof --fix
							恢复：重启redis然后重新加载
					rewrite：
						含义：AOF采用文件追加的方式，文件会越来越大为避免出现此种情况，新增了重写机制，
							  当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集，keyi使用bgrewriteaof。
						原理：AOF文件持续增长而过大时，会fork出一条新进程来将文件重写(也是先写临时文件最后再rename)，遍历新进程的内存中的数据，
						      每条记录有一条set语句。重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令方式重写了一个新的aof文件，这点和快照有点类似。
						触发机制：redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。
						优势与劣势：
							优势：appendfsync always  [每修改同步]同步持久化，每次发生数据变更会被立即记录到磁盘，性能较差但数据完整性比较好
								  appendfsync everysec [每秒同步]异步操作，每秒记录，如果一秒内宕机，有数据丢失
								  appendfsync no 从不同步
							劣势：相同数据集的数据而言aof文件要远大于rdb文件，恢复速度慢于rdb；
								  aof运行效率要慢于rdb，每秒同步策略效率较好，不同步效率和rdb相同
				总结：
					官方建议：
						1）RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储
						2）AOF持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，
						   AOF命令以redis协议追加保存每次写的操作到文件末尾，Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大；	
						3）只做缓存，如果只希望数据在服务器运行的时候存在，你也可以不使用任何持久化方式  
					同时开启两种持久化方式：
						在这种情况下，当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整
						RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。
						那要不要只使用AOF呢？建议不要，因为RDB更适合用于备份数据库(AOF在不断变化不好备份)，
						快速重启，而且不会有AOF可能潜在的bug，留着作为一个万一的手段。
						
					建议：
						因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。
						如果开启AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了。
						代价一是带来了持续的IO，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。
						只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。
						如果不开启AOF，仅靠Master-Slave Replication 实现高可用性也可以。能省掉一大笔IO也减少了rewrite时带来的系统波动。
						代价是如果Master/Slave同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个Master/Slave中的RDB文件，载入较新的那个。
						
			事务[区分于RDBMS中的事务ACID]：
				含义：可以一次执行多个命令，本质是一组命令的集合。一个事务中的所有命令都会序列化，按顺序地串行化执行而不会被其它命令插入，不许加塞。
				作用：一个队列中，一次性、顺序性、排他性的执行一系列命令。
				命令：
					discard：取消事务
					exec：执行事务块内的命令
					multi：事务块的开始
					unwatch：取消对key的监视
					watch：监视key
				使用：
					正常执行，语法：multi 命令块 exec
					放弃事务，语法：multi 命令块 discard
					全体连坐，语法：multi 命令块[含有错误指令] exec ，结果一个出错，都不执行
					冤头债主，语法：multi 命令块[含有错误执行结果] exec ，抛出错误信息
					监视[监控]：
						悲观锁/乐观锁/CAS(Check And Set)：
							悲观锁：顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。
									传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。
							乐观锁(Optimistic Lock)：顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。
													 乐观锁适用于多读的应用类型，这样可以提高吞吐量，乐观锁策略:提交版本必须大于记录当前版本才能执行更新。
						语法：
							watch key                                                       -监控了key，如果key被修改了，后面一个事务的执行失效;一旦执行了exec之前加的监控锁后面执行会被取消掉了
							
						结论：
							1）Watch指令，类似乐观锁，事务提交时，如果Key的值已被别的客户端改变，比如某个list已被别的客户端push/pop过了，整个事务队列都不会被执行
							2）通过WATCH命令在事务执行之前监控了多个Keys，倘若在WATCH之后有任何Key的值发生了变化，EXEC命令执行的事务都将被放弃，同时返回Nullmulti-bulk应答以通知调用者事务执行失败
							
							3）单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。
							4）没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，
												   也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头痛的问题。
							5）不保证原子性：redis同一个事务中如果有一条命令执行结果失败，其后的命令仍然会被执行，没有回滚					   
						
						事务执行流程：
							1）开启：以MULTI开始一个事务
							2）入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面[QUEUED]
							3）执行：由EXEC命令触发事务
						
			发布与订阅[注意与jMS的区别]：
				含义：
					进程间的一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。
				流程图：
					
												订阅SUBSCRIBE						发布消息PUBLISH
					客户端（支持多个）	---------------------------->channel <------------------------- 服务端
										<---------------------------
												消息MESSAGE
				结论：
					先订阅后发布后才能收到消息，可以一次性订阅多个，如：SUBSCRIBE c1 c2 c3；订阅支持通配符*，如：PSUBSCRIBE new*
					发息发布，PUBLISH c2 xxxxx；PUBLISH new1 xxxxx
					 
 			REPLICATION[复制，(Master/Slave)]：
				含义：
					也就是我们所说的行话主从复制，主机数据更新后根据配置和策略，自动同步到备机的master/slaver机制，Master以写为主，Slave以读为主。
				作用：
					读写分离
					容灾恢复
				使用：
					原则：坚持配从(库)不配主(库)
					从库配置：slaveof <masterip> <masterport>，注意：每次与master断开之后，都需要重新连接[客户端操作]，除非你配置进redis.conf文件；查看Master-Slaves复制信息：info replication
					细节[修改配置文件]:
						1）需要拷贝多份[redis.conf]配置文件；如：cp redis.conf [自定义配置路径]/redis6379.conf；
																 cp redis.conf [自定义配置路径]/redis6380.conf；
																 cp redis.conf [自定义配置路径]/redis6381.conf；
						2）开启守护进程[配置文件]：
							如：
								daemonize yes							-开启守护进程
								pidfile /var/run/redis6379.pid			-指定进程ID
								port 6379								-指定端口号
								logfile	"log6379.log"					-指定日志文件
								dbfilename dump6379.rdb					-指定RDB文件名
					3种方案：
						一主二仆[一个Master两个Slave]：
							开启Master和Slave服务：
							   启动服务主SERVER：安装路径下执行redis-server [自定义配置路径]/redis6379.conf，客户端连接：redis-client -p 6379
							   启动服务从SERVER：安装路径下执行redis-server [自定义配置路径]/redis6380.conf，客户端连接：redis-client -p 6380，配置从服务器：SLAVEOF 127.0.0.1 6379
							   启动服务从SERVER：安装路径下执行redis-server [自定义配置路径]/redis6381.conf，客户端连接：redis-client -p 6381，配置从服务器：SLAVEOF 127.0.0.1 6379
							   
							观察日志：
							   主机日志：观察控制台数据同步到从服务器成功！
							   备机日志：Master-Slaver数据同步成功！
							   查看Master-Slaves复制信息：info replication
							问题：
								1）切入点问题？slave1、slave2是从头开始复制还是从切入点开始复制?比如从k4进来，那之前的K123是否也可以复制?全量复制/增量复制
								2）从机是否可以写W？set可否？
								3）主机shutdown后情况如何？从机是上位还是原地待命？投票选举新的Master
								4）主机又回来了后，主机新增记录，从机还能否顺利复制？
								5）其中一台从机down后情况如何？重启后它能跟上大部队吗？可以
						薪火相传：
							结论：
								1）上一个Slave可以是下一个slave的Master，Slave同样可以接收其他slaves的连接和同步请求，
								   那么该slave作为了链条中下一个的master，可以有效减轻master的写压力
								2）中途变更转向:会清除之前的数据，重新建立拷贝最新的数据；slaveof 新主库IP 新主库端口
						反客为主：配置文件中或客户端工具添加一行：SLAVEOF no one					-使当前数据库停止与其他数据库的同步，转成主数据库	
						
				原理分析：
					1）slave启动成功连接到master后会发送一个同步[sync]命令；
					2）Master接到同步[sync]命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，
					   master将传送整个数据文件到slave,以完成一次完全同步；
					3）全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中
					4）增量复制：Master继续将新的所有收集到的修改命令依次传给slave，完成同步；但是只要是重新连接master,一次完全同步（全量复制)将被自动执行
				
				哨兵模式：
					含义：反客为主的自动版，能够后台监控主机Master是否故障，如果故障了根据投票数自动将从库Slaver转换为主库；
					使用：
						1）[自定义配置文件目录下]/新建文件：sentinel.conf
						2）配置内容：sentinel monitor 被监控数据库名字[自定义，如：host6379] 127.0.0.1 6379 1 
									 上面最后一个数字1，表示Master主机挂掉后Salve投票看让谁接替成为主机，得票数多少后成为主机;
						3）启动哨兵：redis-sentinel [自定义配置文件目录下]/sentinel.conf，在启动一主二从；
					结论：
						1）当Master服务宕机后，所有的Slaver进行投票选举推出新的Master
						2）当主机重启后，只能以Slaver的角色加入队伍当中
						3）一组sentinel能同时监控多个Master	
					缺点：
						由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，
						当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。
				
			Redis对应Java客户端：Jedis、Spring-data-redis

----------------------------------------------MysqL高级运维知识技术篇------------------------------------------------------------------------
	一、Mysql运算符：
		安全等于运算符[<=>]：规则均为NULL时，其返回值为1，否则返回0；
						如：
						SELECT NULL <=>1;  						-0
						SELECT 1<=>0;							-0
						SELECT NULL <=>NULL; 					-1
		最值运算符：
			LEAST()或least()运算符，返回最小值；如：SELECT LEAST(2,0),LEAST('a','b','c'),LEAST(10,NULL);					-0,a,null
			GREATEST()或greatest()运算符，返回最大值；SELECT GREATEST(2,0),GREATEST('a','b','c'),GREATEST(10,NULL);			-2,c,null
		REGEXP[正则]运算符:
			正则表达式：在不同的开发语言中，正则表达式的基本语法都是一样的，只是在使用方式上有所差别
			注意：MySQL 支持转义字符 
				# 单引号：\'
				# 双引号：\''，如：INSERT INTO test(`name`) value('\'');
				# 反斜杠：\\
				# 回车符：\r
				# 换行符：\n
				# 制表符：\tab
				# 退格符：\b
			规则：
				# '\b' 匹配一个字边界，即字与空格间的位置
				# '\B' 匹配\b之外的任意字符
				# '\d' 匹配0-9的任意一个数字，如：/^\d$/ 表示数字
				# '\D' 匹配\d之外的任意字符
				# '\f' 匹配换页符
				# '\r' 匹配回车符
				# '\s' 匹配任何空白字符(包括空格、制表符、换页符、换行符等)
				# '\S' 匹配任何非空白字符
				# '\t' 匹配制表符
				# '\v' 匹配垂直制表符
				# '\n' 匹配换行符
				# '\w' 匹配包括下划线在内的任意单词字符(包括A-Z、a-z、0-9、_，就是行话:数字、字母、下划线)，
						如：/^\w{6,16}$/ 表示6-16位字母、数字、下划线组成的
				# '\W' 匹配\w之外的所有字符
				# '^'  匹配以该字符后面的字符开头的字符串，如：SELECT name FROM t_person WHERE name REGEXP '^st';
				# '$'  匹配以该字符前面的字符结尾的字符串，如：SELECT name FROM t_person WHERE name REGEXP 'ok$';
				# '.'  表示任何一个单字符，除\n外
				# '[]' 匹配在方括号内的任一个字符
						 如：“[abc]" 匹配a、b或c。“[a-z]”匹配任何单个字母，而“[0-9]”匹配任何单个数字	
				# '*' 匹配零个或多个在他前面的字符或子表达式，如：'zx*' 可以匹配z后面跟0到无数个x(「z」或「zxx」皆可)
					  如：“x*”匹配任何数量的'*'字符,等价于'{0,}'，“[0-9]*”匹配任何数量的数字，而“.*”匹配任何数量的任何字符
				# '?' 匹配零次或一次匹配前面的字符或子表达式 
				# '+' 匹配至少一个在他前面的字符，等价于{1,}
				# '|' 或，如：p1|p2|p3表示匹配 p1 或 p2 或 p3；g|food 匹配g或food；(g|f)ood 匹配good或food
				# '[^字符集合]' 匹配不在指定集合中的任何字符，如： '[^abc]' 可以匹配不在abc内的任意字符
				# '{n,}'或'{n,m}'，如：“字符串{n,}”表示前面的字符串至少匹配n次；“字符串{n,m}”表示匹配前面的字符串不少于n次，不多于m次
				  示例：'a{5,8}'匹配5-8个a；'123{3}'匹配结果12333；'(456){2}'匹配结果456456
			  
		逻辑运算符：
			逻辑与：AND 或&&；逻辑或 OR或||
				如：
				SELECT * FROM testuser WHERE gender ='女' AND `name` LIKE '%赵%';
				SELECT * FROM testuser WHERE gender ='女' && `name` LIKE '%赵%';
			异或XOR运算符：
				当任意一个操作数为NULL时，返回值为NULL;对于非NULL的操作数，
				如果两个操作数都是非0值或者都是0值，则返回结果为0，反之为1，
				XOR等同于a AND (NOT b))或者NOT a AND (b)
				如：SELECT 1 XOR 1, 0 XOR 0,1 XOR 0,1 XOR NULL,1 XOR 1 XOR 1;					-0,0,1,null,1
		
	二、Mysql事务管理：
			Mysql事务是必须满足4个条件（ACID）：
				原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）
			注意：
				1）在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务；
				2）事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行；
				3）事务用来管理 insert,update,delete 语句；
		    事务控制语句：
				BEGIN 或 START TRANSACTION 显式地开启一个事务
				COMMIT 或 COMMIT WORK。COMMIT 会提交事务，并使已对数据库进行的所有修改成为永久性的
				ROLLBACK 或 ROLLBACK WORK。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改
				SAVEPOINT identifier，SAVEPOINT 允许在事务中创建一个保存点，一个事务中可以有多个 SAVEPOINT
				RELEASE SAVEPOINT identifier 删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常
				ROLLBACK TO identifier 把事务回滚到标记点
				SET TRANSACTION 用来设置事务的隔离级别。InnoDB 存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ 和 SERIALIZABLE
			事务的处理方式：
				方式一：用 BEGIN, ROLLBACK, COMMIT来实现
				方式二：直接用 SET 来改变 MySQL 的自动提交模式；SET AUTOCOMMIT=0 禁止自动提交；SET AUTOCOMMIT=1 开启自动提交；
			结论：
				在 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作。
				因此要显式地开启一个事务务须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交。
				如：
					BEGIN;
					SQL insert,update,delete 语句；
					COMMIT/ROLLBACK;					-数据库表有改变/数据库表没有改变
		
	三、Mysql视图[虚表]：
			含义：视图（view）是一种虚拟存在的表，是一个逻辑表，本身并不包含数据，而是由一个SELECT语句保存在数据字典中的。
				  通过视图，可以展现基表的部分数据；视图数据来自定义视图的查询中使用的表，使用视图动态生成。
			优点：
				为了保障数据安全性，提高查询效率，简单（是过滤好的复合条件的结果集）、安全（用户只能查询或修改所能见到得到的数据）、数据独立（屏蔽真实表结构变化带来的影响）
			
			语法：	  
				# CREATE [OR REPLACE] [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}]     -- 创建、替换、选择算法[未定义的[默认]，合并，临时的] 
				# VIEW view_name [(column_list)] 										-- 视图名、列名
				# AS select_statement 													-- 查询SELECT语句
				# [WITH [CASCADED | LOCAL] CHECK OPTION] 								-- 控制权限，推荐使用，可以保证数据的安全性
			基本格式：
			　　create view <view_name>[(column_list)]
				as select语句
				with check option;
			示例：
				-- 建表、插入数据
				CREATE TABLE student (stuno INT ,stuname NVARCHAR(60));											-学生表（学号、姓名）
				CREATE TABLE stuinfo (stuno INT ,class NVARCHAR(60),city NVARCHAR(60));							-学生信息表（学号、班级、城市）
				INSERT INTO student VALUES(1,'wanglin'),(2,'gaoli'),(3,'zhanghai');
				INSERT INTO stuinfo VALUES(1,'wuban','henan'),(2,'liuban','hebei'),(3,'qiban','shandong');
				
				-- 创建视图
				CREATE VIEW stu_class(id,NAME,class) AS SELECT student.`stuno`,student.`stuname`,stuinfo.`class`
				FROM student,stuinfo WHERE student.`stuno`=stuinfo.`stuno` with check option;
				
				-- 查看视图														  
					方法：
						方式一：SELECT * FROM stu_class								-- 类似查表的方式
						方式二：DESCRIBE 或 DESC
								DESCRIBE stu_class; 或 DESC stu_class;
						方式三：SHOW TABLE STATUS LIKE
								SHOW TABLE STATUS LIKE 'stu_class'; 								-- comment项为view表示视图
								SHOW TABLE STATUS LIKE 'stuinfo';							    	-- 基表
						方式四：SHOW CREATE VIEW
								SHOW CREATE VIEW stu_class;
								SELECT * FROM `information_schema`.`VIEWS`; 						-- 查看MySQL数据库中所有视图的详细信息
				-- 修改视图
					含义：通过视图更新的时候都是转到基表进行更新，如果对视图增加或者删除记录，实际上是对基表增加或删除记录
					语法：
						# ALTER OR REPLACE [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}]
						# VIEW view_name [(column_list)]
						# AS select_statement
						# [WITH [CASCADED | LOCAL] CHECK OPTION]
						如：
						DELIMITER $$																-- 分隔符

						CREATE OR REPLACE VIEW `stu_class` AS 										-- 创建或替换
						SELECT
						  `student`.`stuno`  AS `id`
						FROM (`student` JOIN `stuinfo`)
						WHERE (`student`.`stuno` = `stuinfo`.`stuno`) WITH CHECK OPTION $$

						DELIMITER ;
						
						DESC stu_class;																-- 查看
						SELECT * FROM stu_class;													-- 查看
					DML操作更新视图[单表]：
						结论：
							如：
							ALTER VIEW stu_class AS SELECT stuno,stuname FROM student;					-- 修改视图
							
							UPDATE stu_class SET stuname='xiaofang' WHERE stuno=2; 						-- 修改视图数据
							SELECT * FROM student; 														-- 原表的数据也改变
							INSERT INTO stu_class VALUES(6,'haojie');
							DELETE FROM stu_class WHERE stuno=1;
						注意：
							并非所有视图都可以做DML操作，以下情况例外：
								①select子句中包含distinct
							　　②select子句中包含组函数
							　　③select语句中包含group by子句
							　　④select语句中包含order by子句
							　　⑤select语句中包含union 、union all等集合运算符
							　　⑥where子句中包含相关子查询
							　　⑦from子句中包含多个表
							　　⑧如果视图中有计算列，则不能更新
							　　⑨如果基表中有某个具有非空约束的列未出现在视图定义中，则不能做insert操作
				
				-- 删除视图
					# 语法 ：视图本身没有数据，因此对视图进行的DML操作最终都体现在基表中
					# DROP VIEW [IF EXISTS]
					# view_name [, view_name] ...
					# [RESTRICT | CASCADE]
					如：
					DROP VIEW IF EXISTS stu_class; 
					-- SHOW CREATE VIEW stu_class; 														-- Table '[库名].stu_class' doesn't exist
		
	四、Mysql触发器：
			含义：触发器是与表有关的数据库对象，在满足定义条件时触发，并执行触发器中定义的语句集合。
			特点：
				1、有begin end体，begin end之间的语句可以写的简单或者复杂的
			　　2、什么条件会触发：I、D、U
			　　3、什么时候触发：在增删改前或者后
			　　4、触发频率：针对每一行执行
			　　5、触发器定义在表上，附着在表上
				也就是由事件来触发某个操作，事件包括INSERT语句，UPDATE语句和DELETE语句；可以协助应用在数据库端确保数据的完整性
			注意：
				尽量少使用触发器，不建议使用！
				触发器是针对每一行的；对增删改非常频繁的表上切记不要使用触发器，因为它会非常消耗资源
			使用：
				语法：
				# CREATE TRIGGER trigger_name trigger_time trigger_event  
				# ON tbl_name FOR EACH ROW trigger_stmt
				 
				参数解释 ：trigger_name 触发器名称; trigger_time 触发时间，值有：BEFORE或AFTER; 
				           trigger_event 激发事件，值有：INSERT UPDATE DELETE; tbl_name 表名 
		   	               trigger_stmt 触发程序激活时执行的语句，是BEGIN ... END复合语句结构。
				名词解释：
					OLD & NEW ：表示触发器的所在表中，触发了触发器的那一行数据，来引用触发器中发生变化的记录内容[原数据/新数据]；
				
				
				-- 单执行[有一个执行语句]触发器
				CREATE TABLE account(acct_num INT ,amount DECIMAL(10,2));								-- 建表
				CREATE TRIGGER ins_sum BEFORE INSERT ON account											-- 触发器
				FOR EACH ROW SET @SUM=@SUM+new.amount;

				#申明变量
				DECLARE @SUM INT
				SET @SUM=0
				INSERT INTO account VALUES(1,1.00),(2,2.00)
				SELECT @SUM
				select * from account;
				
				-- 多执行[多个执行语句]触发器
				CREATE TABLE `user` (																	-- 建表
				  `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT '用户ID',
				  `account` VARCHAR(255) DEFAULT NULL COMMENT '用户账号',
				  `name` VARCHAR(255) DEFAULT NULL COMMENT '用户姓名',
				  `address` VARCHAR(255) DEFAULT NULL COMMENT '用户地址',
				  PRIMARY KEY (`id`)
				) ENGINE=INNODB DEFAULT CHARSET=utf8;

				CREATE TABLE `user_history` (															-- 建表
				  `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT '主键ID',
				  `user_id` BIGINT(20) NOT NULL COMMENT '用户ID',
				  `operatetype` VARCHAR(200) NOT NULL COMMENT '操作的类型',
				  `operatetime` DATETIME NOT NULL COMMENT '操作时间',
				  PRIMARY KEY (`id`)
				) ENGINE=INNODB DEFAULT CHARSET=utf8;
				
				
				DROP TRIGGER IF EXISTS `tri_insert_user`;												-- 清空触发器										
				
				DELIMITER ;;
				CREATE TRIGGER `tri_insert_user` AFTER INSERT ON `user` FOR EACH ROW BEGIN 				-- 新增
					INSERT INTO user_history(user_id, operatetype, operatetime) VALUES (new.id, 'add a user', NOW());
				END
				;;
				DELIMITER ;

				DROP TRIGGER IF EXISTS `tri_update_user`;												-- 清空触发器				
				DELIMITER $$
				CREATE TRIGGER `tri_update_user` AFTER UPDATE ON `user` FOR EACH ROW BEGIN 				-- 修改
					INSERT INTO user_history(user_id,operatetype, operatetime) VALUES (new.id, 'update a user', NOW());
				END $$
				DELIMITER ;

				DROP TRIGGER IF EXISTS `tri_delete_user`;												-- 清空触发器
				DELIMITER |
				CREATE TRIGGER `tri_delete_user` AFTER DELETE ON `user` FOR EACH ROW BEGIN 				-- 删除
					INSERT INTO user_history(user_id, operatetype, operatetime) VALUES (old.id, 'delete a user', NOW());
				END
				|
				DELIMITER ;
				
				注意：分割线[语句结束符]可以使用的符号[可以自定义]：$$ ;; | // 

				-- 向user表中插入数据
				INSERT INTO `user`(account, `name`, address) VALUES ('zhangsan.@sina.cn', 'zhangsan', '合肥');
				INSERT INTO `user`(account, `name`, address) VALUES ('lisi.@sina.cn', 'lisi', '蚌埠');
				INSERT INTO `user`(account, `name`, address) VALUES ('wangwu.@sina.cn', 'wangwu', '芜湖'),('zhaoliu.@sina.cn', 'zhaoliu', '安庆');
				-- 向user表中修改数据
				UPDATE `user` SET `name` = 'qianqi', account = 'qianqi.@sina.cn', address='铜陵' WHERE `name`='zhaoliu';
				-- 向user表中删除数据
				DELETE FROM `user` WHERE `name` = 'wangwu';

				-- 查看触发器
				SHOW TRIGGERS;																  -- 查看所有的触发器
				SELECT * FROM `information_schema`.`TRIGGERS` WHERE `TRIGGER_NAME`='ins_sum'; -- 查看指定触发器
				
				-- 删除触发器，注意：基表删除后，触发器不复存在
				# 语法：DROP TRIGGER [schema_name.]trigger_name
				DROP TRIGGER `db1`.`ins_sum`;				  
				  
	五、Mysql存储过程[函数]：
			含义：存储过程简称过程，Stored Procedure，是一种在数据库中存储复杂程序，以便外部程序调用的一种数据库对象。
				  简单点，可以将其理解为没有返回值的函数，一般存储过程并不显示结果，而是把结果返回给你指定的变量。
				  存储过程是为了完成特定功能的SQL语句集，经编译创建并保存在数据库中，用户可通过指定存储过程的名字并给定参数(需要时)来调用执行。
				  存储过程思想上很简单，就是数据库 SQL 语言层面的代码封装与重用。
			优点：
				存储过程可封装，并隐藏复杂的商业逻辑
				存储过程可以回传值，并可以接受参数
				存储过程无法使用 SELECT 指令来运行，因为它是子程序，与查看表，数据表或用户定义函数不同
				存储过程可以用在数据检验，强制实行商业逻辑等
			缺点：
				存储过程，往往定制化于特定的数据库上，因为支持的编程语言不同。当切换到其他厂商的数据库系统时，需要重写原有的存储过程。
				存储过程的性能调校与撰写，受限于各种数据库系统。
			
			使用：参考：https://blog.csdn.net/qq_40884473/article/details/78442457 	
				基本格式：
					-- 创建存储过程，声明结束符
					DELIMITER $  													-- 声明存储过程的结束符
					CREATE PROCEDURE pro_name()    									-- 存储过程名称(参数列表)，参数：IN：表示输入参数，可以携带数据带存储过程中；
																													 OUT：表示输出参数，可以从存储过程中返回结果；
																													 INOUT：表示输入输出参数，既可以输入功能，也可以输出功能
					BEGIN
						-- 可以写多个sql语句;       								-- sql语句+流程控制
						SELECT * FROM table_name;
					END $  															-- 结束结束符
					
					-- 执行存储过程
					CALL pro_name();   												-- CALL 存储过程名称(参数);
					
					-- 删除存储过程 
					DROP PROCEDURE [IF EXISTS] pro_name;
					 
				完整格式：
					# CREATE PROCEDURE sp_name ([ proc_parameter ]) [ characteristics..] routine_body 
					# 参数：sp_name 存储过程名称
					#		proc_parameter 参数列表，形式：[IN|OUT|INOUT] param_name type
					#	
					#  characteristic: 											    -- 特征项
					#    LANGUAGE SQL  												    -- SQL语言
					#  | [NOT] DETERMINISTIC 											-- 存储过程执行的结果是否确定
					#  | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA } -- 程序包含、不包含、读、写SQL语句
					#  | SQL SECURITY { DEFINER | INVOKER } 							-- 安全性  定义者 调用者
					#  | COMMENT 'string' 												-- 注释
					#   
					#  routine_body: 													-- SQL代码的内容 用BEGIN...END来表示SQL代码的开始和结束
				示例：
					输入参数：
						DELIMITER $
						CREATE PROCEDURE pro_findById(IN eid INT)  						-- IN: 输入参数
						BEGIN
							SELECT * FROM t_employee WHERE id=eid;
						END $ 
						
						DELIMITER ;
						 						
						CALL pro_findById(4);											-- 调用
					输出参数：
						DELIMITER $
						CREATE PROCEDURE pro_Out(OUT str VARCHAR(20))  					-- OUT：输出参数
						BEGIN								
							SET str='hellojava';										-- 给参数赋值
						END $
						
						DELIMITER ;
						问题：如何接收？？？答案使用Mysql变量						
						CALL pro_Out(@NAME);													-- 调用
						SELECT @NAME;
						
						Mysql变量：全局变量、会话变量、局部变量
							全局变量：全局变量又叫内置变量，是mysql数据库内置的变量，对所有连接都起作用。
									  查看所有全局变量：show variables；查看某个全局变量：select @@变量名；如：select @@basedir
									  修改全局变量：set 变量名=新值；character_set_client: mysql服务器的接收数据的编码；character_set_results：mysql服务器输出数据的编码；
							会话变量：
								只存在于当前客户端与数据库服务器端的一次连接当中。如果连接断开，那么会话变量全部丢失！
								定义会话变量: set @变量=值；查看会话变量：select @变量
							局部变量：
								在存储过程中使用的变量就叫局部变量，只要存储过程执行完毕，局部变量就丢失。
								
					输入输出参数：
						DELIMITER $
						CREATE PROCEDURE pro_InOut(INOUT n INT)  							-- INOUT：输入输出参数
						BEGIN						   
						   SELECT n;														-- 查看变量
						   SET n =500;
						END $																
			
						SET @n=10;															-- 调用				 
						CALL pro_InOut(@n);						 
						SELECT @n;
					
					条件判断：
						DELIMITER $
						CREATE PROCEDURE pro_If(IN num INT,OUT str VARCHAR(20))
						BEGIN
							IF num=1 THEN
								SET str='星期一';
							ELSEIF num=2 THEN
								SET str='星期二';
							ELSEIF num=3 THEN
								SET str='星期三';
							ELSE
								SET str='输入错误';
							END IF;
						END $
						 						
						CALL pro_If(4,@str);											--调用						 
						SELECT @str;
					
					循环功能：						
						DELIMITER $
						CREATE PROCEDURE proWhile(IN num INT,OUT result INT)
						BEGIN	
							DECLARE	i INT DEFAULT 1;										--定义一个局部变量
							DECLARE vsum INT DEFAULT 0;
							WHILE i<=num DO
								  SET vsum = vsum+i;
								  SET i=i+1;
							END WHILE;
							SET result=vsum;
						END $
						 
						CALL pro_While(100,@result);									--调用						 
						SELECT @result;
					
					将查询的结果赋值给变量[INTO]:
						DELIMITER $
						CREATE PROCEDURE pro_findById(IN eid INT,OUT vname VARCHAR(20) )
						BEGIN
							SELECT empName INTO vname FROM t_employee WHERE id=eid;
						END $
						
						CALL pro_findById2(1,@NAME);									--调用						 
						SELECT @NAME;
						
	六、Mysql存储函数：				
			含义：MySQL存储函数（自定义函数），函数一般用于计算和返回一个值，可以将经常需要使用的计算或功能写成一个函数。
			使用：
				语法：
					CREATE OR ALTER FUNCTION func_name ([param_name type[,...]])		--创建或修改
					RETURNS type
					[characteristic ...] 
					BEGIN
						routine_body
					END;
				
					参数说明：
						1）func_name ：存储函数的名称。
						2）param_name type：可选项，指定存储函数的参数。type参数用于指定存储函数的参数类型，该类型可以是MySQL数据库中所有支持的类型。
						3）RETURNS type：指定返回值的类型。
						4）characteristic：可选项，指定存储函数的特性。
						5）routine_body：SQL代码内容。
					
					调用存储函数：
						在MySQL中，存储函数的使用方法与MySQL内部函数的使用方法基本相同。
						用户自定义的存储函数与MySQL内部函数性质相同。区别在于，存储函数是用户自定义的。而内部函数由MySQL自带。
						语法结构：SELECT func_name([parameter[,…]]);
						示例：
							-- 创建用户信息表
							CREATE TABLE IF NOT EXISTS tb_user
							(
								id INT AUTO_INCREMENT PRIMARY KEY COMMENT '用户编号',
								name VARCHAR(50) NOT NULL COMMENT '用户姓名'
							) COMMENT = '用户信息表';
							 
							-- 添加数据
							INSERT INTO tb_user(name) VALUES('pan_junbiao的博客');
							INSERT INTO tb_user(name) VALUES('KevinPan');
							INSERT INTO tb_user(name) VALUES('pan_junbiao');
							INSERT INTO tb_user(name) VALUES('阿标');
							INSERT INTO tb_user(name) VALUES('panjunbiao');
							INSERT INTO tb_user(name) VALUES('pan_junbiao的CSDN博客');
							INSERT INTO tb_user(name) VALUES('https://blog.csdn.net/pan_junbiao');
							-- 创建存储函数
							DROP FUNCTION IF EXISTS func_user;
							CREATE FUNCTION func_user(in_id INT)
							RETURNS VARCHAR(50)
							BEGIN
								DECLARE out_name VARCHAR(50);						 
								SELECT name INTO out_name FROM tb_user
								WHERE id = in_id;						 
								RETURN out_name;
							END;
							-- 调用存储函数
							SELECT func_user(1);
							SELECT func_user(2);
							
					删除存储函数：DROP FUNCTION IF EXISTS func_name;
			
			Mysql的存储过程与存储函数的区别：
				1）存储函数有且只有一个返回值，而存储过程不能有返回值。就是说能不能使用return。
				2）存储函数只能有输入参数，而且不能带in, 而存储过程可以有多个in,out,inout参数。
				3）存储过程中的语句功能更强大，存储过程可以实现很复杂的业务逻辑，而函数有很多限制，如不能在函数中使用insert,update,delete,create等语句；
				   存储函数只完成查询的工作，可接受输入参数并返回一个结果，也就是函数实现的功能针对性比较强。比如：工期计算、价格计算。
				4）存储过程可以调用存储函数。但函数不能调用存储过程。
				5）存储过程一般是作为一个独立的部分来执行(call调用)。而函数可以作为查询语句的一个部分来调用。
		
		Mysql系统内置函数：
			字符串函数：
				SELECT CONCAT_WS('-','1st','2nd','3rd'),CONCAT_WS('-','1st',NULL,'3rd'); 					--字符串拼接，结果为：1st-2nd-3rd，1st-3rd；
				SELECT INSERT('warWalf',2,2,'BB'); 															--替换，结果为：wBBWalf
				SELECT LPAD('hello',4,'??'),RPAD('hello',10,'??'); 											--填充，结果为：hell，hello?????
				SELECT TRIM(' book ') `trim`; 																--去除两端空格，结果为：book
				SELECT TRIM('xy' FROM 'xyxboxyokxxyxy');																	结果为：xboxyokx
				SELECT REPEAT('str',3); 																	--重复，结果为：strstrstr
				SELECT STRCMP('txt','txt2') ,STRCMP('txt2','txt'),STRCMP('txt','txt'); 						--比较字符串大小，返回-1或1或0，结果为：-1,1,0
				SELECT LOCATE('ball','football'),POSITION('ball' IN 'football') ,INSTR('football','ball');  --查找位置，结果为：5,5,5
				SELECT ELT(3,'1st','2nd','3rd'),ELT(3,'net','os'); 											--查找字符串，结果为：3rd，null
				SELECT FIELD('hi','hihi','hey','hi','bas') AS col1,
					   FIELD('hi','hihi','lo','hilo','foo') AS col2; 									    --查找在字符数组中的位置[返回索引]，结果为：3,0
				SELECT FIND_IN_SET('hi','hihi,hey,hi,bas'); 												--查找在字符数组中的位置[返回索引]，结果为：3
				SELECT MAKE_SET(1,'a','b','c') AS col1,
				       MAKE_SET(1|4,'hello','nice','world') AS col2; 										--二进制返回的字符串，结果为：a hello,world
				
			数值函数：
				SELECT TRUNCATE(1.32,1); 																	--截取小数后一位，结果为：1.3
				SELECT MOD(31,8);																			--取余，结果为：7
				SELECT ROUND(1.36,1);																		--四舍五入，结果为：1.4
				SELECT HEX('this is a test str'); 															--十六进制表示，结果为：746869732069732061207465737420737472
				CHAR_LENGTH()																				--字符长度，对于char型的字符串会去除左右的空格
				LENGTH()																					--字符长度
			
			日期时间函数：
				SELECT NOW(),CURDATE(),CURRENT_DATE(),CURRENT_TIMESTAMP(),LOCALTIME(),SYSDATE(); 		    --2017-08-07 14:14:49 2017-08-07 2017-08-07 2017-08-07 14:14:49 2017-08-07 14:14:49 2017-08-07 14:14:49
				SELECT UTC_DATE(),UTC_TIME();																--2019-07-04 02:50:56
				SELECT MONTHNAME('2013-8-2')；																--获取月份；August
				SELECT QUARTER('11-04-01'); 																--返回季度 1~4
				SELECT MINUTE('11-02-03 10:10:06'); 														--分钟
				SELECT SECOND('10:23:10'); 																	--秒数
				SELECT DAYNAME('2013-2-3'); 																--返回星期；Sunday 
				SELECT EXTRACT(YEAR FROM '2013-2-3'); 														--返回年数 2013
				SELECT TIME_TO_SEC('23:22:00'); 															--转换为秒数；转换公式为：小时*3600+分钟*60+秒  84120
				SELECT SEC_TO_TIME('84120'); 																--转换为时间；23:22:00
				DATE_FORMAT()																				--where 表名.字段 = DATE_FORMAT(NOW(),'%Y-%m-%d'); 今日
				WEEKOFYEAR() 																				--表示一年中的第几周;WHERE WEEKOFYEAR( 表名.时间字段（如：create_time）) = WEEKOFYEAR(NOW());本周内;
			
			日期计算：
				SELECT DATE_ADD('2013-2-3',INTERVAL 1 MONTH); 												--增加日期：2013-03-03 
				SELECT ADDDATE('2013-2-3',INTERVAL 1 WEEK); 												--增加日期：2013-02-10 
				SELECT DATE_SUB('2013-2-3',INTERVAL 1 WEEK); 												--减少日期：2013-01-27
				SELECT SUBDATE('2013-2-3',INTERVAL 1 WEEK); 												--减少日期：2013-01-27
				SELECT ADDTIME('2013-2-3 01:05:06','10:50:20'); 											--增加时间：2013-02-03 11:55:26
				SELECT SUBTIME('2013-2-3 01:05:06','10:50:20'); 											--减少时间：2013-02-02 14:14:46
				SELECT DATEDIFF('2008-12-30','2007-12-29') AS DiffDate；									--时间差,返回天数；367
				SELECT LAST_DAY('2003-02-05');  															--每月最后一天：2003-02-28
				SELECT DATE_FORMAT(NOW(),'%Y-%m-%d %H:%i:%s');												--格式化日期：2017-08-07 10:20:11
				SELECT TIME_FORMAT('100:00:00', '%H %k %h %I %l'); 											--格式化时间 '%H %k %h %I %l' 表示小时
				SELECT DATE_FORMAT(NOW(),GET_FORMAT(TIMESTAMP,'ISO')); 										--格式化日期 2017-08-07 10:36:35 
				
				--今天
				SELECT DATE_FORMAT(NOW(),'%Y-%m-%d 00:00:00') AS '今天开始';
				SELECT DATE_FORMAT(NOW(),'%Y-%m-%d 23:59:59') AS '今天结束';

				--昨天
				SELECT DATE_FORMAT( DATE_SUB(CURDATE(), INTERVAL 1 DAY), '%Y-%m-%d 00:00:00') AS '昨天开始';
				SELECT DATE_FORMAT( DATE_SUB(CURDATE(), INTERVAL 1 DAY), '%Y-%m-%d 23:59:59') AS '昨天结束';

				--上周
				SELECT DATE_FORMAT( DATE_SUB( DATE_SUB(CURDATE(), INTERVAL WEEKDAY(CURDATE()) DAY), INTERVAL 1 WEEK), '%Y-%m-%d 00:00:00') AS '上周一';
				SELECT DATE_FORMAT( SUBDATE(CURDATE(), WEEKDAY(CURDATE()) + 1), '%Y-%m-%d 23:59:59') AS '上周末';

				--本周
				SELECT DATE_FORMAT( SUBDATE(CURDATE(),DATE_FORMAT(CURDATE(),'%w')-1), '%Y-%m-%d 00:00:00') AS '本周一';
				SELECT DATE_FORMAT( SUBDATE(CURDATE(),DATE_FORMAT(CURDATE(),'%w')-7), '%Y-%m-%d 23:59:59') AS '本周末';
				--上面的本周算法会有问题,因为mysql是按照周日为一周第一天，如果当前是周日的话,会把时间定为到下一周
				SELECT DATE_FORMAT( DATE_SUB(CURDATE(), INTERVAL WEEKDAY(CURDATE()) DAY), '%Y-%m-%d 00:00:00') AS '本周一';
				SELECT DATE_FORMAT( DATE_ADD(SUBDATE(CURDATE(), WEEKDAY(CURDATE())), INTERVAL 6 DAY), '%Y-%m-%d 23:59:59') AS '本周末';

				--上月
				SELECT DATE_FORMAT( DATE_SUB(CURDATE(), INTERVAL 1 MONTH), '%Y-%m-01 00:00:00') AS '上月初';
				SELECT DATE_FORMAT( LAST_DAY(DATE_SUB(CURDATE(), INTERVAL 1 MONTH)), '%Y-%m-%d 23:59:59') AS '上月末';

				--本月
				SELECT DATE_FORMAT( CURDATE(), '%Y-%m-01 00:00:00') AS '本月初';
				SELECT DATE_FORMAT( LAST_DAY(CURDATE()), '%Y-%m-%d 23:59:59') AS '本月末';	
				
				--示例
				SELECT * FROM test_user WHERE TO_DAYS(create_time) = TO_DAYS(NOW()); 										--当天数据
				SELECT * FROM test_user WHERE testuser.create_time LIKE CONCAT('%',DATE_FORMAT(NOW(),'%Y-%m-%d'),'%'); 		--当天数据
				SELECT * FROM test_user WHERE TO_DAYS(NOW()) - TO_DAYS(create_time) = 1; 									--昨天数据
				SELECT * FROM test_user WHERE create_time > DATE_SUB(NOW(), INTERVAL 7 DAY) AND create_time <= NOW(); 		--近7天
				SELECT * FROM test_user WHERE create_time > DATE_SUB(NOW(), INTERVAL 30 DAY) AND create_time <= NOW(); 		--近30天
				SELECT * FROM test_user WHERE WEEKOFYEAR(create_time) = WEEKOFYEAR(NOW()); 									--当前这周数据(不包括上周日)
				SELECT * FROM test_user WHERE YEARWEEK(DATE_FORMAT(create_time,'%Y-%m-%d')) = YEARWEEK(NOW()); 				--当前这周数据(包括上周日)
				SELECT * FROM test_user WHERE YEARWEEK(DATE_FORMAT(create_time,'%Y-%m-%d')) = YEARWEEK(NOW())-1; 			--上一周数据
				SELECT * FROM test_user WHERE WEEKOFYEAR(create_time) = WEEKOFYEAR(NOW())-1; 								--上一周数据
				SELECT * FROM test_user WHERE DATE_FORMAT(create_time, '%Y%m') = DATE_FORMAT(CURDATE(), '%Y%m'); 			--本月数据
				SELECT * FROM test_user WHERE PERIOD_DIFF( DATE_FORMAT(NOW(),'%Y%m'),DATE_FORMAT(create_time,'%Y%m')) =1; 	--上月数据
				SELECT * FROM test_user WHERE QUARTER(create_time)= QUARTER(NOW()); 										--本季度的数据
				SELECT * FROM test_user WHERE QUARTER(create_time)= QUARTER(DATE_SUB(NOW(),INTERVAL 1 QUARTER)); 			--上季度的数据
				SELECT * FROM test_user WHERE QUARTER(create_time)= QUARTER(DATE_ADD(NOW(),INTERVAL 1 QUARTER)); 			--下季度的数据
				SELECT * FROM test_user WHERE YEAR(create_time)=YEAR(NOW()); 												--今年的数据
				SELECT * FROM test_user WHERE YEAR(create_time)=YEAR(DATE_SUB(NOW(),INTERVAL 1 YEAR)); 						--去年的数据
				SELECT * FROM test_user WHERE create_time BETWEEN DATE_SUB(NOW(),INTERVAL 3 MONTH) AND NOW(); 				--距现在3个月的数据
				
			条件判断函数：
				SELECT IF(3>2,2,3); 										--返回2
				SELECT IFNULL(1,2),IFNULL(NULL,10); 						--假如V1不为NULL，则IFNULL(V1,V2)的返回值为v1；否则其返回值为v2
			
				# CASE函数
				# 语法一：
				#	SELECT 
				#	    表字段,
				#	CASE
				#	    WHEN （Bollean值）条件1 THEN 结果表达式1
				#	    WHEN （Bollean值）条件2 THEN 结果表达式2
				#	    ELSE 结果表达式3 END  
				#	FROM 表名
				#

				# 语法二：
				#	SELECT 
				#	    表字段1,
				#	CASE 表字段2
				#	    WHEN 值1 THEN 结果表达式1
				#	    WHEN 值2 THEN 结果表达式2
				#	    ELSE 结果表达式3  END 
				#	FROM 表名
			
			MySQL系统信息函数：
				SELECT VERSION(),CONNECTION_ID();													--返回MySQL 的版本、链接数（ID）
				SHOW PROCESSLIST; 																	--查看线程，只显示100个
				SHOW FULL PROCESSLIST; 																--包括所有线程
				SELECT DATABASE(),SCHEMA(); 														--当前数据库
				SELECT USER(),CURRENT_USER(),SYSTEM_USER(),SESSION_USER();							--用户名
				SELECT CHARSET('abc') ,CHARSET(CONVERT('abc' USING latin1)),CHARSET(VERSION()); 	--字符集
				SELECT COLLATION(_latin2 'abc'),COLLATION(CONVERT('abc' USING utf8)); 				--字符集排列方式 latin2_general_ci utf8_general_ci
			 
			加密函数：
			SELECT PASSWORD('NEWPWD'); 																--*067906D546600BF74D1435B72BDD12D45421DD17
			SELECT MD5('123'); 																		--(32位十六进制数字组成)202cb962ac59075b964b07152d234b70			 
			#加密
			SELECT ENCODE('uetec','123'); 															--'123'密码 'uetec'加密字符串，结果为：��WJ 加密后乱码			
			#解密
			SELECT DECODE(ENCODE('uetec','123'),'123'); 											--uetec
			
			SELECT FORMAT(12332.123465,4); 				 											--格式化函数,数字格式化,进行四舍五入，结果为：12,332.1235			
			SELECT CONV('a',16,2); 																	--进制转换，将十六进制的a转换为二进制表示的数值，结果为：1010 
			
			SELECT INET_ATON('192.168.1.200'); 														--3232235976，IP地址与数字相互转换的函数，优化存储空间
			SELECT INET_NTOA('3232235976'); 														--192.168.1.200
			SHOW VARIABLES LIKE 'character_set_%';  												--查看当前MySQL使用的字符集
			SELECT  CAST(100 AS CHAR(2)),CONVERT('2013-8-9 12:12:12',TIME);						    --数据类型的转换
		
	七、数据库设计PowerDesigner
		1、工具产生的原因：
			不同数据库（MySql、Oracle）表相互转换存储，提供可视化界面查看表与表之间关系以及表结构
		2、工具使用：
			使用管理者身份运行软件->创建物理模型->在工作空间创建表设计表->建立表之间的关联关系（关系：子表连向主表）->将物理模型（后缀为pdm的文件）导出SQL脚本文件，然后在数据库中执行即可；
		3、物理模型反转（反向操作）：
		   含义：将数据库中的表转化为PDM文件，使用步骤：file->Reverse Engieer->Database->配置要反转的数据库的数据源->反转操作
		   
	八、MyCAT数据库分库分表高可用（数据库中间层：OneProxy、MaxScale）
		1、含义：由阿里团队用JAVA语言开发，对于DBA数据库管理员来说，相当于MySQL的SERVER层，不存储数据，所有数据存储在MySQL里，而MySQL相当于存储层；
				 对于研发来说，等同于MySQL，是透明的，但对SQL有些限制；
				 对于系统架构来说，是数据库中间件层，可以实现对后端数据库的分库分表和读写分离，对前端运用影藏了后端数据库的存储逻辑；
		  数据库中间层：位于前端运用（APP）与后端数据库（MySQL）中间；
		2、作用：作为分布式数据库（相对于关系型数据库）的中间层（APP->MyCAT->MYSQL/SQL SERVER/MongoDB等）；实现后端数据库读写分离以及负载均衡；控制数据库连接数量（池的作用）
					        读/写	
				 传统：APP----------->主库MySQL
				 当读的负载大后，演变成                 写
					   APP----------->中间层（MyCAT）---------->主库MySQL
													 ---------->从库，即实现了读写分离，从库可以有多个；	
													    读
		         当主库宕机后，在一主一从模式下，从库自动实现承担起读写的功能，实现了高可用；当在一主多从模式下，其中一个从库实现了承担起读写的功能，而其他数据库不能同步；
				 如何解决这个问题？？？
				 可以利用MySQL的主从复制同步数据，具体产品有：MHA（Master High Availability）、MMM (MySQL Master-Master Replication Manager) 等
				 当写的负载大后，怎么解决？？？
				 对业务数据库进行垂直拆分，将Master（主库）按业务拆分成多个数据库（如：用户库、商品库）；
				 APP----------->中间层（MyCAT/虚拟的数据DB又称逻辑库，它的作用管理拆分好的多个数据库）---------->多个拆分好的库；
				 对业务数据库进行水平拆分（基于垂直拆分基础上），对于某个已拆分好的数据库进行水平拆分（基于某种规则F（c））；
		3、MyCAT基本元素：
			逻辑库：对于应用来说相当于MySQL中的数据库，逻辑库对应后端多个物理数据库，当中并不保存数据；
			逻辑表：对于应用来说相当于MySQL中的数据表，逻辑库对应后端多个物理数据库中的表，当中并不保存数据；分类：按是否分片分为：分片表（按水平拆分的，表结构相同，存储数据不同，汇总在一起才是真正的数据表）与非分片表、
			 全局表：所有分片都存在的表（通常是字典表）、ER关系表；
		4、MyCAT安装：	
				1）下载解压安装包；
				2）安装好JDK1.7+；
				3）为新建的MyCAT新建系统运行账户（权限控制）；
				4）为MyCAT与JDK配置好系统环境变量，便于后期使用；
		5、	MyCAT配置文件
				1）种类：server.xml：系统参数、用户权限配置；scheme.xml：逻辑库与逻辑表配置；rule.xml：水平切分时配置一些规则；log4j2.xml：配置日志格式以及级别；
			2）详细说明：
			   server.xml配置文件说明
			   用途：系统参数配置、用户权限控制、配置SQL防火墙以及SQL拦截功能；
			   <system>系统参数： 
			   如：
			   <system>
					<property name="serverPort">3306</property><!-- 服务端口->
					<property name="managerPort">3306</property><!-- 管理端口->
					<property name="nonePasswordLogin">0</property><!-- 密码登陆，0需要密码；1不需要密码，默认0->
					<property name="bindIp">0.0.0.0</property><!-- 绑定Ip，0.0.0.0允许所有Ip->
					<property name="frontWriteQueueSize">2048</property><!-- 前端允许队列大小->
					<property name="charset">utf-8</property><!-- 字符集编码->
					<property name="txIsolation">2</property><!-- 事务隔离， repeatable可重复读read可读commited已提交->
					<property name="processors">8</property><!-- 进程数->
					<property name="idleTimeOut">18000000</property><!-- 空闲超时数，单位毫秒->
					<property name="sqlExecuteTimeOut">300</property><!-- SQL执行的超时时间，单位秒->
					<property name="useSqlStat">0</property><!-- 1为开启实时统计、0为关闭 -->
					<property name="useGlobalTableCheck">0</property>
					<property name="sequnceHandleType">2</property>
					<property name="defaultMaxLimit">100</property><!-- 返回数据集大小限制，行数->
					<property name="maxPacketSize">104857600</property><!-- 最大包大小->
			   </system>
			   <user>用户参数： 
			    <user name="test" defaultAccount="true"><!-- 默认用户->
					<property name="usingDecrypt">1</property><!-- 是否加密，1加密->
					<!-- <property name="password">XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX</property>-><!-- 加密密码，通过java -cp Mycat-server-1.6.5-release.jar io.mycat.util.DecryptUtil 0:root:123456 ->
					<property name="password">123456</property><!-- 明文密码->
					<property name="schemas">db1,db2</property><!-- 当前用户访问的逻辑库，可以配置多个->
					<property name="readOnly">false</property><!-- 是否只读用户->
			   </user>
				<user name="test">
					<privileges check="true"><!-- 权限->
						<schema name="db1" dml="0110"><!-- 逻辑库的权限，dml表示insert、update、select、delete权限，0不具有，1具有->
							<table name="tb1" dml="0000"></table><!-- 逻辑表的权限->
							<table name="tb2" dml="1111"></table>
						</schema>
					</privileges><!-- 权限->
			   </user> 
			 log4j2.xml（Apache）配置文件说明
			   用途：输出日志格式配置；日志级别控制；
			   <PatternLayout>
					<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS}[%t]%5p - %m%n</pattern><!-- 时间、线程、级别、消息、换行->
			   <PatternLayout>
			   日志级别：
			   <asyncRoot level="info" includeLocation="true" />
			   All -> Trace -> Debug -> Info -> Warn -> Error -> Fatal -> OFF （级别越来越高，输出信息越少）
			   rule.xml配置文件说明
			   用途：配置水平分片的分片规则；配置水平分片的分片规则对应的分片函数；
			   如：
			   <tableRule name="hash-mod-4_id"><!-- 分片规则，名称->
					<rule>
						<columns>id</columns><!-- 分片规则，列值->
						<algorithm>hash-mod-4</algorithm><!-- 分片规则，算法，取<function>的name属性->
					</rule>
			   </tableRule>
			   <function name="hash-mod-4"
						class="io.mycat.route.function.PartitionByHashMod">
						<property name="count">4</property><!-- 将表分4分->
			   </function>
			   常用的分片算法：
					简单取模-PartitionByMod （对分片列取模）
					如：
					<tableRule name="customer_login"><!-- 分片规则，名称->
						<rule>
						  <columns>customer_id</columns><!-- 分片列->
						  <algorithm>mod-long</algorithm>
						</rule>
					  </tableRule>
					<function name="mod-long" class="io.mycat.route.function.PartitionByMod">
						<property name="count">2</property><!-- 分片基数->
					</function>
					特点：分片列整数类型的表；
					哈希取模-PartitionByHashMod （对分片列进行哈希运算后再取模）
					如：
					<tableRule name="customer_login"><!-- 分片规则，名称->
						<rule>
						  <columns>login_name</columns><!-- 分片列->
						  <algorithm>mod-long</algorithm>
						</rule>
					  </tableRule>
					<function name="mod-long" class="io.mycat.route.function.PartitionByHashMod">
						<property name="count">2</property><!-- 分片基数->
					</function>
					特点：可以运用于多种数据类型如字符串日期，对分片列hash再mod
					分片枚举-PartitionByFileMap
					如：
					<tableRule name="customer_login"><!-- 分片规则，名称->
						<rule>
						  <columns>arear_id</columns><!-- 分片列->
						  <algorithm>mod-long</algorithm>
						</rule>
					  </tableRule>
					<function name="mod-long" class="io.mycat.route.function.PartitionByFileMap">
						<property name="mapFile">partion-hash-init.txt</property><!-- 指定分片枚举值与节点关系，具体的节点由scheme.xml指定->
						<property name="type">0</property><!-- 数据类型：0整型，非0字符串->
						<property name="defaultNode">0</property><!-- 默认分片节点，>=0启动默认节点->
					</function>
					特点：人为的根据枚举值指定数据存储的位置，需要配置好枚举值与节点关系（$MYCAT/conf目录下）
					字符串范围取模分片-PartitionByPrefixPattern（指定字符串首字母长度进行ASCII值运算并求和与取模基数取模）
					如：
					<tableRule name="customer_login"><!-- 分片规则，名称->
						<rule>
						  <columns>login_name</columns><!-- 分片列->
						  <algorithm>partition-prefix-pattern</algorithm>
						</rule>
					  </tableRule>
					<function name="partition-prefix-pattern" class="io.mycat.route.function.PartitionByPrefixPattern">
						<property name="mapFile">partition-prefix-pattern.txt</property><!-- 指定分片范围值与节点关系，具体的节点由scheme.xml指定->
						<property name="patternValue">128</property><!-- 取模基数->
						<property name="prefixPattern">2</property><!-- 字符串前缀->
					</function>
					特点：指定字符串前N个字符确认存储位置，需要配置好范围值与节点关系（$MYCAT/conf目录下）
				scheme.xml（逻辑库，逻辑表）配置文件说明
				用途：配置逻辑库与逻辑表；配置逻辑表所存储的数据节点（真实的物理节点）；配置数据节点所对应的物理数据库服务器信息；
				<scheme>标签-定义逻辑库
				如：<scheme name="db1" checkSQLscheme="false" sqlMaxLimit="1000"></scheme><!-- 逻辑库名称、返回结果集行数，-1关闭限制、发给MyCAT的SQL是否含库名（库名.表名）->
				<table>标签-定义逻辑表
				如：<table name="customer_login" primaryKey="customer_id" dataNode="db01,db02" rule="customer_login"/><!-- 逻辑表名称（与后端物理表名保持一致）、逻辑表主键、数据节点（后端物理数据库）、分片规则，对应rule.xml中的tableRule->
				<dataNode>标签-定义逻辑表所对应的存储物理数据库	
				如：<dataNode name="db01" dataHost="mysql01" database="db1"/><!-- 数据节点名称、分片所在的物理主机、物理数据库名称->
				<dataHost>标签-定义后端数据库主机信息
				如：<dataHost name="mysql01" maxCon="1000" minCon="10" balance="3" writeType="0" dbType="mysql" dbDriver="native" switchType="1" >
					<!-- 物理主机名称
						 最大/最小连接数（池作用）
						 balance：0不开启读写分离机制（都在主库），1全部的readHost与stand by writeHost参与select语句的负载均衡（双主双从），2全部的readHost与writeHost参与select语句的负载均衡（写压力不大）,3全部的readHost参与select语句的负载均衡（一主多从）
					     写类型，取值0或1，一般为0
						 数据库类型，如：mysql、mongodb
						 数据库驱动，取值有：native原生的，jdbc
						 切换类型，值有1或-1，-1关闭切换功能（主从复制）
					-->
					<heartbeat>select user()<heartbeat><!-- 心跳检测，检查后端数据库是否可用-->
					<writeHost host="192.168.1.1" url="192.168.1.1:3306" user="root" password="123456"><!-- 主机名、url、后端数据库用户名、密码-->
						<readHost host="192.168.1.2" url="192.168.1.2:3306" user="root" password="123456"><readHost><!-- 从库，可以是多个-->
					<writeHost/><!-- 主库-->
				<dataHost/>	
		6、数据库架构升级之垂直分库
			案例分析：                  写负载很大
				APP、web（前端应用）  --------------->后端数据库MySQL（订单/用户/仓配/商品模块） ？？？ ------------->解决方法：增加内存、CPU、磁盘IO读写
				
				另外一种方案：
				
				APP、web（前端应用）  -------------->数据库中间件MyCAT（虚拟库可以与数据库保持同名、池的作用管理数据库连接数）   ------------->后端多个数据库（订单/仓配、用户、商品模块）
			垂直分库的步骤：
				分析业务模块之间的关系
					订单（冗余商品信息、API接口获取用户信息）/仓配、用户、商品模块
				复制数据库到其他实例（主从复制，主库192.168.1.2从库3-5）
					备份原数据库并记录相关事务日志点；（主库备份事务、存储过程、触发器、事件）
						mysqldump --master-data=2 --single-transaction --routines --triggers --events -uroot -p imooc_db > back_immoc.sql
					在原数据库中建立备份用户（主库）；
						create user 'im_repl'@'192.168.1.%' identified by '123456'；（创建用户）
						grant replication slave on *.* to  'im_repl'@'192.168.1.%'；（授权）
					在新数据库上恢复备份数据库（从库）；
						mysql -uroot -p order_db < back_immoc.sql
					在新实例上配置复制链路（从库）；
						change master to master_host='192.168.1.2',master_user='im_repl',master_password='123456',master_log_file='mysql-bin.00001',MASTER_POS_LOG='453251'；（相关事务点）
						show slave status；（查看状态）
						change replication filter replication_rewrite_db=((immoc_db,order_db))；（过滤重命名）
					在新实例上启动复制；
						start slave；
					结论：192.168.1.2 原始库immooc；192.168.1.3 order_db（订单库）；192.168.1.4 product_db（商品库）；192.168.1.5 customer_db（用户库）；期初从库与主库数据表完全一致；
				配置MyCAT垂直分库（主库）
					
				通过MyCAT来访问DB
					
				删除原库中已迁移的库
			
					
----------------------------------------------Linux运维相关知识篇---------------------------------------------------------------------									
							
	方向：运维工程师、嵌入式工程师
	应用领域：1、个人桌面应用；2、服务器（免费、稳定、高效）；3、嵌入式领域（内核小，对网络有良好的支持，成本小，物联网运用广泛）
	一、基础篇
			含义：是一款操作系统，免费、开源、安全、高效、稳定，处理高定发十分强悍
			创始人：Linus 林纳斯
			发行版本：redhat（centos、redhat）、ubuntu、suse 、红旗（Fedora）
			Linux与Unix关系：GUN计划Linux内核
			与windows的比较：
						Linux  										windows
				收费：  费用低											高
				维护：   开源，全球爱好者提供技术支持			      微软
				安全性：  高                                          低，补丁  
				使用习惯： 命令行                                       图形界面
				定制性：   强                                            弱
				应用场景：  企业级										桌面操作系统
				
		使用：
			学习阶段：安装VM（虚拟机，提供虚拟空间，前提：BIOS开启了对虚拟化设备的支持），再安装Linux系统（centos）
				网络连接（TCP）三种形式：
					桥连接：Linux可以和其它的系统通信，但是可能造成ip冲突。
					NAT（网络地址转换方式）连接: linux可以访问外网，不会造成ip冲突。
					主机模式：linux是一个独立的主机，不能访问外网。
				vmtools工具使用：
					1、在windows与centos之间使用粘贴命令
					2、设立共享文件
					
		Linux目录结构：
			简介：Linux采用的是树状的目录结构，根目录/。在Linux世界，一切皆文件。
			基本目录介绍：
				/bin：命令目录
				/sbin：系统管理员使用的命令目录
				/home：家目录，普通用户家目录，默认以用户名命名
				/root：超级管理员用户目录
				/boot：引导目录，启动时加载的核心文件，如：镜像文件
				/proc：虚拟目录，是系统内存的映射
				/srv：service缩写，当一些服务启动需要读取的数据目录
				/tmp：临时目录
				/dev：设备，类似于windows的设备管理器，以文件形式存储
				/media：媒体目录，会自动识别设备，如：U盘
				/mnt：临时挂载目录
				/opt：安装软件目录，默认为空
				/usr/local：软件安装所在目录，一般是源码安装方式
				/var：可变目录，经常修改的文件，包括日志文件
				/selinux：安全子系统，类似360	
				/etc：配置文件目录
					  /etc/passwd  -用户（user）的配置文件，记录用户的各种信息，每行的含义：用户名:口令:用户标识号:组标识号:注释性描述:主目录:登录Shell，如：zwj:x:503:504::/home/zwj:/bin/bash
					  /etc/shadow -口令的配置文件，每行的含义：登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志
					  /etc/group -组(group)的配置文件，记录 Linux 包含的组的信息，每行含义：组名:口令:组标识号:组内用户列表
					  /etc/inittab -修改系统的运行级别
		远程登录：
			远程登录（安全模拟终端）软件：Xshell、SecureCRT （支持SSH(Secure SHell远程管理协议) SSH1,SSH2（密文传输）都属于TCP（传输控制协议，软件与软件之间的通讯）协议
										  ,区别于IP（计算机与计算机之间的通讯）协议 以及 Microsoft windows平台的TELNET（明文传输）协议），使用前提：Linux操作系统开启了SSHD服务，此服务监听22号端口
			上传和下载的文件：Xftp 基于windows平台强大的ftp、sftp文件传输软件
					ftp:文件传输协议，默认端口20和21，其中20用于传输数据，21用于传输控制信息，sftp：（SSH File Transfer Protocol）安全文件传送协议
			图形化操作Linux软件的工具：Xmanager
		编辑器：
			vi：所有的linux都会内置
			vim：是vi的增强版，以颜色来区分语法是否正确，代码补全等功能
			三种模式：
				正常模式：默认模式
				编辑/插入模式：按i、I、o、O、a、A、r、R，一般按i		
				命令行模式：通过提供相关指令，实现存盘、读取、替换、显示行号、离开vim等一系列动作
				相互转化：					
									按i
					正常模式	---------------->      编辑模式	
							    <----------------
							        按ESC
							
									按：或/
					正常模式	---------------->      命令行模式（wq、q、q!）
							    <----------------		
									按ESC
				快捷键：
					1) 拷贝当前行yy：拷贝当前行向下的 5 行，5yy，并粘贴（p）
					2) 删除当前行dd：删除当前行向下的 5 行 5dd		
					3) 在文件中查找某个单词[命令行下/关键字，回车查找,输入n就是查找下一个]		
					4) 设置文件的行号或取消文件的行号[命令行下:set nu和:set nonu]		
					5) 编辑/etc/profile 文件，使用快捷键到文档的最末行[G]和最首行[gg],注意这些都是在正常模式下执行的。		
					6) 在一个文件中输入"linux" ,然后又撤销这个动作，再正常模式下输入u		
					7) 编辑/etc/profile 文件，并将光标移动到第20行，第一步：显示行号:set nu，第二步：输入20这个数，第三步: 输入 shift+g	
	二、实操篇
		关机/重启：
			halt：直接使用，效果等价于关机；reboot：重启系统；syn：把内存的数据同步到磁盘
			shutdown -h now : 表示立即关机
			shutdown -h 1 : 表示 1 分钟后关机
			shutdown -r now: 立即重启				
			注意：当关机或者重启时，都应该先执行sync指令，把内存的数据写入磁盘，防止数据丢失。				
		用户登录和注销：
			注销：logout 即可注销用户
			切换系统管理员身份：su - 用户名
			注意：logout注销指令在图形运行级别无效，在运行级别3下有效
				运行级别7种：
				0 ：关机                                       -系统停机状态，系统默认运行级别不能设为 0，否则不能正常启动
				1 ：单用户【找回丢失密码】					   -单用户工作状态，root 权限，用于系统维护，禁止远程登陆
				2：多用户状态没有网络服务					   -多用户状态(没有 NFS)，不支持网络
				3：多用户状态有网络服务						   -完全的多用户状态(有 NFS)，登陆后进入控制台命令行模式
				4：系统未使用保留给用户						   -系统未使用，保留
				5：图形界面									   -X11 控制台，登陆后进入图形 GUI 模式
				6：系统重启									   -系统正常关闭并重启，默认运行级别不能设为 6，否则不能正常启动
				常用运行级别是 3 和 5 ，要修改默认的运行级别可改文件/etc/inittab中的 id:5:initdefault:这一行中的数字
				切换运行级别：
					init [012356]，如：init 5
				如何找回密码？（以root账户为例）
				思路： 进入到单用户模式，然后修改 root 密码。因为进入单用户模式，root 不需要密码就可以登录
				总结：开机->在引导时输入 回车键-> 看到一个界面输入 e -> 看到一个新的界面，选中第二行（编辑内核）在输入 e-> 在这行最后输入1 ,再输入 回车键->再次输入 b ,这时就会进入到单用户模式。
					  这时，我们就进入到单用户模式，使用passwd 指令来修改 root 密码。					  
		用户管理：
			说明：Linux系统是一个多用户多任务的操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号，然后以这个账号的身份进入系统
				  Linux的用户需要至少要属于一个组  
			添加用户：
				useradd [选项] 用户名，如：useradd xm
					当创建用户成功后，会自动的创建和用户同名的家目录，也可以通过 useradd -d 指定目录，如：useradd -d /home/xm1 xm
					指定用户组：useradd -g 用户组 用户名，如：useradd -g xiaoming xm
					修改用户组：usermod -g 用户组 用户名，如：usermod -g xiaoqiang xm 
		    修改用户密码：
				passwd 用户名，如：passwd xm
			删除用户：
				userdel [选项] 用户名，如：userdel xm（保留家目录），userdel -r xm（删除家目录）
			查询用户信息：
				id 用户名，如：id root（会显示uid、gid、组名）
			切换用户：
				在操作Linux中，如果当前用户的权限不够，可以通过 su - 指令，切换到高权限用户
				su – 切换用户名，如：su – xf
				注意：从权限高的用户切换到权限低的用户，不需要输入密码，反之需要；当需要返回到原来用户时，使用 exit 指令
			用户组：
				类似于角色，系统可以对有共性的多个用户进行统一的管理
				增加组：groupadd 组名，如：groupadd wudang
				删除组：groupdel 组名，如：groupdel wudang
				
		帮助指令：
			man [指令或配置文件] -获得帮助信息，如：man ls
			help 指令 -获得shell内置命令的帮助信息，如：help ls
		文件目录：
			pwd：显示当前工作目录的绝对路径
			ls [选项] [目录或是文件]: list缩写，如：ls -al /etc
				常用选项
				-a ：显示当前目录所有的文件和目录，包括隐藏的。
				-l ：以列表的方式显示信息	
			cd [参数] -切换到指定目录，参数：可以是绝对路径和相对路径
			  cd ~ 或 cd 回到家目录
			  cd .. 回到上一级目录
			创建目录（make directory）：
				mkdir [选项] 要创建的目录，如：mkdir -p /home/xm/student
					常用选项
					-p ：创建多级目录
			删除目录（remove directory）：	
				rmdir [选项] 要删除的空目录，如：rmdir /home/xm/student
				提示：如果需要删除非空目录，需要使用 rm -rf 要删除的目录
			创建空文件：
				touch 文件名称1 文件名称2，如：touch 1.txt 2.txt
			拷贝文件：
				cp [选项] source dest，如：cp -r /home/test /home/zwj
				常用参数
				-r ：递归复制整个文件夹
				注意：原路径与目标路径存在相同文件时，强制覆盖不提示的方法：\cp
			删除文件/目录：
				rm [选项] 要删除的文件或目录，如：rm -rf /home/test
				常用参数
				-r ：递归删除整个文件夹
				-f ：强制删除不提示
			重命名/移动文件或目录：
				mv oldNameFile newNameFile -重命名
				mv /sourceFolder /targetFolder -移动文件或目录
			查看文件：
				cat [选项] 要查看的文件，如：cat -n /etc/profile
				常用选项
				-n ：显示行号
				cat 文件名 | more [分页浏览]  -注意：cat只能浏览文件，而不能修改文件
				
				more 要查看的文件 -基于 VI 编辑器的文本过滤器，它以全屏幕的方式按页显示文本文件的内容，more
					 指令中内置了若干快捷键，如：more /etc/profile
					快捷键：
						空白键（space）   -向下翻一页
						Enter             -向下翻一行
						q                 -离开
						ctrl+f            -向下滚动一屏
						ctrl+b            -向上滚动一屏
						=                 -输出当前行号
						:f                -输出文件名和当前行号
	
				less 指令用来分屏查看文件内容，less 指令在显示文件内容时，并不是一次将整个文件加载之后才显示，而是根据显示
					 需要加载内容，对于显示大型文件具有较高的效率。				 
					 less 要查看的文件，如：less /opt/金庸-射雕英雄传精校版.txt
					 less也指令中内置了若干快捷键
					快捷键：
						空白键（space）/pagedown   -向下翻一页
						pageup   				   -向上翻一页
						q                          -离开
						/字符串                    -向下搜索字符串，n向下查找；N向上查找
						?字符串                    -向上搜索字符串，n向上查找；N向下查找
						
				head 显示文件的开头部分内容，默认情况下 head 指令显示文件的前 10 行内容，如：head -n 5 /etc/profile
					 head 文件        -查看文件头10行内容
					 head -n 5 文件   -查看文件头5行内容
					 
				tail 用于输出文件中尾部的内容，默认情况下 tail 指令显示文件的后 10 行内容
					 tail 文件        -查看文件尾10行内容
					 tail -n 5 文件   -查看文件尾5行内容
					 tail -f 文件     -实时追踪该文档的所有更新，工作中使用多				
				
			输出重定向/追加：
				>输出重定向: 会将原来的文件的内容覆盖
				>>追加：不会覆盖原来文件的内容，而是追加到文件的尾部
				如：ls -l >文件，如：ls -l > a.txt , 将 ls -l 的显示的内容覆盖写入到 a.txt 文件，如果该文件不存在，就创建该文件
					ls -al >>文件，如：ls -l >> aa.txt , 列表的内容追加到文件 aa.txt 的末尾
					cat 文件1 > 文件2 （功能描述：将文件1的内容覆盖到文件2）	
			输出指令：
				echo [选项] [输出内容]，如：echo $PATH
			
			软连接/符号链接（link缩写）：
				类似于 windows 里的快捷方式，主要存放了链接其他文件的路径
				ln -s [原文件或目录] [软链接名]       -给原文件创建一个软链接，如：ln -s /root liknToRoot，注意：删除软链接时，rm -rf liknToRoot（后面不需要/）
				当我们使用 pwd 指令查看目录时，仍然看到的是软链接所在目录
			
			执行过的历史命令：
				history：查看已经执行过历史命令，也可以执行历史指令，如：history 10        -最近执行的10条命令
						 执行历史命令：先找到对应命令编号，然后！编号，如：!178
		
		时间日期：			 
			date：显示当前日期
				date +%Y 					显示当前年份
				date +%m 					显示当前月份
				date +%d 					显示当前是哪一天
				date "+%Y-%m-%d %H:%M:%S"   显示年月日时分秒 
			date：设置日期
			date -s 字符串时间，如：date -s 2018-10-10 11:22:22
			
		日历：
			cal [选项] 不加选项，显示本月日历
			cal 2020 显示2020年日历
	
		查找：
			find：从指定目录向下递归地遍历其各个子目录，将满足条件的文件或者目录显示在终端
			find [搜索范围] [选项] 搜索的文件或目录
			选项：
				-name				按文件名
				-user				按文件所属用户
				-size				按文件大小
			如：find /home -name 1.txt
				find /home -size +1M  （+大于，-小于）
		
		快速定位文件路径：
			locate 指令利用事先建立的系统中所有文件名称及路径的locate 数据库实现快速定位给定的文件。
				   Locate 指令无需遍历整个文件系统，查询速度较快。为了保证查询结果的准确度，管理员必须定期更新 locate 时刻 
			locate 搜索文件
			注意：由于 locate 指令基于数据库进行查询，所以第一次运行前，必须使用 updatedb 指令创建 locate 数据库
			如：updatedb 
				locate 1.txt            -返回文件路径
		
		过滤查找与管道符|：
			grep 过滤查找，管道符“|”，表示将前一个命令的处理结果输出传递给后面的命令处理
			grep [选项] 查找内容 源文件
			常用选项
				-n 显示匹配行号
				-i 忽略大小写
			如：cat 1.txt | grep -n yes          -区分大小写
			
		压缩与解压：
			gzip/gunzip：
				gzip 文件                        -压缩文件，只能将文件压缩为*.gz 文件，不会保留源文件，如：gzip 1.txt
				gunzip 文件.gz                   -解压文件
			
			zip/unzip：
				zip [选项] XXX.zip 目录路径              -压缩文件，压缩文件和目录，如：zip -r package.zip /home/
				常用参数：
					-r 递归压缩，即压缩目录
				unzip [选项] XXX.zip 			 		 -解压文件，如：unzip -d /opt/tmp/ package.zip 
				常用参数：
					-d<目录> ：指定解压后文件的存放目录
			
			tar：打包指令[重要]，最后打包后的文件是 .tar.gz 的文件
				tar [选项] XXX.tar.gz 打包的内容（目录或文件） -打包目录，压缩后的文件格式.tar.gz
				常用参数：
					-c 产生.tar打包文件
					-v 详细信息
					-f 指定压缩后的文件名
					-z 打包同时压缩
					-x 解压.tar打包文件
			
				打包并压缩：如：tar -zcvf package.tar.gz 1.txt 2.txt	
				解压文件：如：tar -zxvf package.tar.gz -C /opt/               -C指定解压路径
			
		组管理与权限管理
			在 linux 中的每个用户必须属于一个组，不能独立于组外。在 linux 中每个文件有所有者、所在组、其它组的概念
			文件或目录所有者：一般为文件的创建者,谁创建了该文件，就自然的成为该文件的所有者
				查看所有者：ls -ahl
				修改所有者：chown 用户名 文件名，如：chown -R tom kkk/	
							chown newowner:newgroup 文件名
							-R 如果是目录，则使其下所有子文件或目录递归生效
			
			文件或目录所在组：当某个用户创建了一个文件后，默认这个文件的所在组就是该用户所在的组
				查看所在组：ls -ahl
				修改所在组：chgrp 组名 文件名，如：chgrp -R police kkk/		
							-R 如果是目录，则使其下所有子文件或目录递归生效
			
			文件或目录其它组：除文件的所有者和所在组的用户外，系统的其它用户都是文件的其它组
			
			改变用户所在的组：
				在添加用户时，可以指定将该用户添加到哪个组中，同样的用 root 的管理权限可以改变某个用户所在的组
				usermod -g 组名 用户名
				usermod -d 目录名 用户名        -改变该用户登陆的初始目录
				
			文件或目录权限：
				ls -l 中显示的内容如下：
				-rwxrw-r-- 1 root root 1213 Feb 2 09:39 abc
				0-9 位说明
				1)第 0 位确定文件类型(d[目录], -[普通文件] , l[软链接] , c[字符设备，鼠标、键盘等] , b[块文件，硬盘])
				2)第 1-3 位确定所有者（该文件的所有者）拥有该文件的权限。---User
				3)第 4-6 位确定所属组（同用户组的）拥有该文件的权限，---Group
				4)第 7-9 位确定其他用户拥有该文件的权限 ---Other
				后面的字符含义：
					第一位：如果是文件，表示硬链接数，如果是目录表示子目录数
					第二位：所有者
					第三位：所在组
					第四位：文件大小，如果是目录是4096
					第五位：时间，最后修改时间
					最后一位：文件名
			
				权限解析：
					rwx 作用到文件
					1) [ r ]代表可读(read): 可以读取,查看
					2) [ w ]代表可写(write): 可以修改,但是不代表可以删除该文件,删除一个文件的前提条件是对该文件所在的目录有写权限，才能删除该文件.
					3) [ x ]代表可执行(execute):可以被执行
					rwx 作用到目录
					1) [ r ]代表可读(read): 可以读取，ls 查看目录内容
					2) [ w ]代表可写(write): 可以修改,目录内创建+删除+重命名目录
					3) [ x ]代表可执行(execute):可以进入该目录
				
				修改权限：
					chmod 指令，可以修改文件或者目录的权限
					变更权限方式一：+ 、-、= 变更权限
						u:所有者g:所有组o:其他人 a:所有人(u、g、o 的总和)	
						chmod u=rwx,g=rx,o=x 文件目录名
						chmod o+w 文件目录名
						chmod a-x 文件目录名
					变更权限方式二：利用数字变更权限
						规则：r=4 w=2 x=1,rwx=4+2+1=7
						chmod u=rwx,g=rx,o=x 文件目录名 相当于 chmod 751 文件目录名
			
			crond 定时任务调度：
				简单任务：直接在crontab中加入任务即可
				负责任务：写脚本（Shell编程）
				
				任务调度：是指系统在某个时间执行的特定的命令或程序
				任务调度分类：1.系统工作：有些重要的工作必须周而复始地执行。如病毒扫描等
							  2.个别用户工作：个别用户可能希望执行某些程序，比如对 mysql 数据库的备份
				
				crontab [选项]
				常用选项
					-e 编辑当前用户crontab任务
					-l 查询当前用户所有的crontab任务
					-r 删除当前用户所有的crontab任务
				重启任务调度：service crond restart
			    如：
					设置任务调度文件：/etc/crontab
					设置个人任务调度，执行 crontab –e 命令，接着输入任务到调度文件，如：*/1 * * * * ls –l /etc/ > /tmp/to.txt
					意思说每小时的每分钟执行ls –l /etc/ > /tmp/to.txt 命令
				
				cron表达式：注意与Java的cron表达式的区别，它是由5位占位符组成的，从分钟开始				
				    分钟 小时 天 月 星期
				
				简单脚本运用：
					每隔 1 分钟，就将当前的日期信息，追加到/tmp/mydate文件中
					1) 先编写一个文件 /home/mytask.sh，添加内容：date >> /tmp/mydate
					2) 给 mytask.sh 一个可以执行权限，chmod 744 /home/mytask.sh
					3) crontab -e，添加：*/1 * * * * /home/mytask.sh
					4) 成功
			
		Linux 磁盘分区、挂载
			分区基础知识：
				MBR分区:
				1.最多支持四个主分区
				2.系统只能安装在主分区
				3.扩展分区要占一个主分区
				4.MBR 最大只支持 2TB，但拥有最好的兼容性
				GTP分区：
				1.支持无限多个主分区（但操作系统可能限制，比如 windows 下最多 128 个分区）
				2.最大支持 18EB 的大容量（1EB=1024 PB，1PB=1024 TB ）
				3.windows7 64 位以后支持 gtp
			原理介绍：
				Linux 采用了一种叫“载入”的处理方法，将一个分区和linux的一个目录联系起来，这时要载入的一个分区将使它的存储空间在一个目录下获得
			硬盘介绍：
				1)Linux 硬盘分 IDE 硬盘和 SCSI 硬盘，目前基本上是 SCSI 硬盘
				2)对于 IDE 硬盘，驱动器标识符为“hdx~”,其中“hd”表明分区所在设备的类型，这里是指 IDE 硬
				  盘了。“x”为盘号（a 为基本盘，b 为基本从属盘，c 为辅助主盘，d 为辅助从属盘）,“~”代表分区，
				  前四个分区用数字 1 到 4 表示，它们是主分区或扩展分区，从 5 开始就是逻辑分区。例，hda3 表示为
				  第一个 IDE 硬盘上的第三个主分区或扩展分区,hdb2 表示为第二个 IDE 硬盘上的第二个主分区或扩展
				  分区。
				3)对于 SCSI 硬盘则标识为“sdx~”，SCSI 硬盘是用“sd”来表示分区所在设备的类型的，其余则
				  和 IDE 硬盘的表示方法一样。
			
			查看磁盘分区：
				lsblk -f 查看当前系统的分区情况，查看各分区大小：lsblk
				经典案列：如何挂载一块新的硬盘？
				主要步骤：
					1、虚拟机添加一块硬盘
					2、分区，指令：fdisk /dev/sdb         -初始化
					3、格式化：mkfs -t ext4 /dev/sdb1 
					4、设置挂载：mount 设备名称（分区） 目录名称 mount /dev/sdb1 /home/newdisk
					5、取消挂载：umount 设备名称或目录名称 umount /dev/sdb1
					6、永久挂载：编辑/etc/fstab文件，添加一行/dev/sdb1 /home/newdisk ext4 defaults 0 0，再执行mount -a 计时生效
			硬盘健康情况查询：
				查看系统磁盘使用情况：df -lh
				指定目录磁盘使用情况：默认为当前目录
					du -h /目录
					参数：-s 指定目录占用大小汇总
						  -h 带计量单位
						  -a 含文件 
						  --max-depth=1 子目录深度
						  -c 列出明细的同时，增加汇总值
					
			        如：查询/opt目录的磁盘占用情况，深度为 1，du -ach --max-depth=1 /opt
				常用指令：
					1、查询/home目录下的文件个数：ls -l /home | grep "^-" | wc -l
					2、查询/home目录下的目录个数：ls -l /home | grep "^d" | wc -l
					3、查询/home目录下的文件个数（包括子文件夹）：ls -lR /home | grep "^-" | wc -l
					4、查询/home目录下的目录个数（包括子文件夹）：ls -lR /home | grep "^d" | wc -l	
				目录结构：tree
		
		Linux 网络配置
			查看网络：ifconfig
			查看当下服务器是否连接通目标主机：ping，如： ping www.baidu.com
			测试端口：telnet，如：telnet 192.168.1.175:8080
			获取网络：
				1、自动获取：IP不固定
				2、固定网络：直接修改置文件指定IP,并可以连接到外网，编辑vim /etc/sysconfig/network-scripts/ifcfg-eth0
							 修改后，一定要重启服务（reboot重启系统/service network restart）
							 
			查看系统网络情况：
				netstat [选项]，如：netstat -anp | grep sshd
				选项参数：
					-an 按一定顺序排列输出
					-p	显示哪个进程在调用
		
		进程管理：
			含义：
				1)在 LINUX 中，每个执行的程序（代码）都称为一个进程。每一个进程都分配一个 ID 号
				2)每一个进程，都会对应一个父进程，而这个父进程可以复制多个子进程
				3)每个进程都可能以两种方式存在的。前台与后台，前台进程就是用户目前的屏幕上可以进
				  行操作的。后台进程则是实际在操作，但由于屏幕上无法看到的进程，通常使用后台方式执行
				4)一般系统服务都是以后台进程的方式存在，而且都会常驻在系统中，直到关机才才结束	
			显示系统执行的进程：
				后台运行的进程：
					ps -aux 
					参数说明：-a 终端所有的进程信息；-u 以用户格式显示进程信息； -x 显示后台运行的进程参数
					1)指令：ps –aux|grep xxx
					2)指令说明
						•System V 展示风格
						•USER：用户名称
						•PID：进程号
						•%CPU：进程占用 CPU 的百分比
						•%MEM：进程占用物理内存的百分比
						•VSZ：进程占用的虚拟内存大小（单位：KB）
						•RSS：进程占用的物理内存大小（单位：KB）
						•TTY：终端名称,缩写 .
						•STAT：进程状态，其中 S-睡眠，s-表示是会话的先导进程，N-表示进程拥有比普通优先
							   级更低的优先级，R-正在运行，D-短期等待（不可被唤醒的睡眠状态 , 通常进程可能在等待 I/O 的情况），Z-僵死进程，T-被跟踪或者被停止等等
						•STARTED：进程的启动时间
						•TIME：CPU 时间，即进程使用 CPU 的总时间
						•COMMAND：启动进程所用的命令和参数，如果过长会被截断显示
				
				显示所有进程信息（全格式）：ps -ef 
					参数说明：-e 显示所有进程 -f 全格式
					1)指令：ps –ef|grep xxx
					2)指令说明
						•UID：用户 ID
						•PID：进程 ID
						•PPID：父进程 ID
						•C：CPU 用于计算执行优先级的因子。数值越大，表明进程是 CPU 密集型运算，执行优先级会
							降低；数值越小，表明进程是 I/O 密集型运算，执行优先级会提高
						•STIME：进程启动的时间
						•TTY：完整的终端名称
						•TIME：CPU 时间
						•CMD：启动进程所用的命令和参数
				
					三种风格：
						BSD 风格的参数，前面不加破折线
						Unix 风格的参数，前面加单破折线
						GNU 风格的长参数，前面加双破折线
			终止进程：
				介绍:若是某个进程执行一半需要停止时，或是已消了很大的系统资源时，此时可以考虑停止该进程
				kill [选项] 进程号 			-通过进程号杀死进程 
				killall 进程名称			-通过进程名称杀死进程，也支持通配符，这在系统因负载过大而变得很慢时使用
				选项：-9:表示强迫进程立即停止
			查看进程树：
				pstree [选项] ,可以更加直观的来看进程信息，如：pstree -p
				常用选项：
				-p :显示进程的 PID
				-u :显示进程的所属用户
			
			动态监控进程：
				指令：Top，Top 与 ps 最大的不同之处，在于 top 在执行一段时间可以更新正在运行的的进程
				top [选项]
				选项参数：
					-d 秒数 								-每隔几秒后更新，默认3秒
					-i										-不显示僵死或闲置进程
					-p 进程号                               -指定进程ID，显示进程信息
				交互说明：
					P（以CPU使用率排序） M（以内存使用率排序） N（以PID排序） q（退出top）
				如：监视特定用户：top 回车 输入u ，再输入用户名
				    终止进程：top 回车 输入k ，再输入PID
				   
				
		服务管理：
			含义：本质就是进程，但是是运行在后台的，通常都会监听某个端口，等待其它程序的请求，比如(mysql,sshd、防火墙等)，因此又称为守护进程。
			service 服务名 [start | stop | restart | reload | status]
			注：在 CentOS7.0 后，不再使用service ,而是 systemctl
			如：service iptables start   			 -启动防火墙
			
			服务自动启或服务永久关闭：ckconfig
				查看服务名：
					1、指令： setup -> 系统服务 就可以看到系统服务
					2、/etc/init.d/服务名称，如： ls -l /etc/init.d/
					
				Linux系统开机流程：开机	-> BIOS ->/boot ->init进程名 ->运行级别 ->运行对应的服务
				
				chkconfig 指令：可以给每个服务的各个运行级别设置自启动/关闭，语法：chkconfig [服务名] --list|grep xxx
					chkconfig --level 5 服务名 on/off，如：chkconfig --level 5 sshd off
														   chkconfig [--level 5] iptables off
					
				注意：chkconfig重新设置服务后自启动或关闭，需要重启机器 reboot 才能生效
		防火墙：
			查看所有开放的端口：firewall-cmd --zone=public --list-ports
			添加：				firewall-cmd --zone=public --add-port=80/tcp --permanent    （--permanent永久生效，没有此参数重启后失效）			
			重新载入：			firewall-cmd --reload
			查看：				firewall-cmd --zone=public --query-port=80/tcp
			删除：				firewall-cmd --zone=public --remove-port=80/tcp --permanent 
			批量开放端口：
				firewall-cmd --permanent --zone=public --add-port=100-500/tcp
				firewall-cmd --permanent --zone=public --add-port=100-500/udp
				firewall-cmd --reload
					
		Linux包管理：
			rpm：一种用于互联网下载包的打包及安装工具，，它包含在某些 Linux 分发版中，它生成具有.RPM扩展名的文件。RPM 是 RedHat Package Manager（RedHat 软件包管理工具）的缩写，类似 windows
				 的 setup.exe，Linux 的分发版本都有采用（suse,redhat, centos 等等），可以算是公认的行业标准了
			    查询指令：
					查询已安装的 rpm 列表：rpm –qa|grep xx，如：rpm –qa|grep firefox
					rpm -qa :查询所安装的所有 rpm 软件包
					rpm -qa | more [分页显示]
					rpm -qa | grep X [rpm -qa | grep firefox ]
					rpm -q 软件包名 :查询软件包是否安装，如：rpm -q firefox					
					rpm -qi 软件包名 ：查询软件包信息
					rpm -ql 软件包名 :查询软件包中的文件，如：rpm -ql firefox					
					rpm -qf 文件全路径名 查询文件所属的软件包，如：rpm -qf /etc/passwd	rpm -qf /root/install.log
				卸载：
					rpm -e RPM包的名称，如：rpm -e firefox
					注意：1) 如果其它软件包依赖于您要卸载的软件包，卸载时则会产生错误信息
						  2) 如果非要卸载，添加参数：--nodeps,就可以强制删除，但是一般不推荐这样做，因为依赖于该软件包的程序可能无法运行，如：rpm -e --nodeps foo
				安装：					
					rpm -ivh RPM包全路径名称，如：rpm -ivh firefox.XXX.rpm
					参数说明：
						i=install 安装
						v=verbose 提示
						h=hash 进度条
			yum：是一个 Shell 前端软件包管理器。基于RPM包管理，能够从指定的服务器自动下载 RPM 包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包，使用 yum 的前提是可以联网		
				基本指令：
					查询yum服务器是否有需要安装的软件：yum list|grep xx，如：yum list|grep firefox 
					安装指定的yum包：yum install xxx，如：yum install firefox
					
	三、搭建：JavaEE环境：
			JDK：配置环境变量，vim /etc/profile
				 JAVA_HOME=/opt/jdk1.7.0_79
				 PATH=/opt/jdk1.7.0_79/bin:$PATH
				 export JAVA_HOME PATH
			注意：需要注销用户，环境变量才能生效！	 
			
			Tomcat：解压[tar -zxvf apache-tomcat.tar.gz] -> 启动：bin/下执行.startup.sh
			注意：需要开放端口，外部才能访问！
				修改防火墙开放端口[centos7.0以下的版本]：vim /etc/sysconfig/iptables，
				添加一行：-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 8080:9000 -j ACCEPT，
				重启防火墙service iptables restart
			
			Eclipse：解压 -> 安装目录执行./eclipse
			
			MySql：略
				
	四、大数据Shell编程：	
		简介：
			1)Linux 运维工程师在进行服务器集群管理时，需要编写Shell程序来进行服务器管理
			2)对于JavaEE和Python程序员来说，工作的需要，要求编写一些Shell脚本进行程序或者是服务器的维护，比如编写一个定时备份数据库的脚本
			3)对于大数据程序员来说，需要编写Shell程序来管理集群
			
			Shell是一个命令行CMD解释器，它为用户提供了一个向Linux内核发送请求以便运行程序的界面系统
			级程序，用户可以用Shell来启动、挂起、停止甚至是编写一些程序	
		Shell入门：
			脚本要求：
				1) 脚本以#!/bin/bash 开头
				2) 脚本需要有可执行权限+x（如：chmod 744 XX.sh）
				3）单行注释：#
				4）多行注释：：<<!                        !
			执行方式：
				1) 输入脚本的绝对路径或相对路径，如：./1.sh
				2) sh+脚本，不推荐，如： sh 1.sh
				   
		Shell变量：
			变量分为：系统变量和用户自定义变量，系统变量：$HOME、$PWD、$SHELL、$USER 等等，如：echo "home=$HOME"
			显示当前shell中所有变量：set
			
			自定义变量：
				规则：
					1) 变量名称可以由字母、数字和下划线组成，但是不能以数字开头
					2) 等号两侧不能有空格
					3) 变量名称一般习惯为大写
				使用：
				1)定义变量：变量=值，如：A=10 				echo "A=$A"
				2)撤销变量：unset 变量，如：unset A
				3) 声明静态变量：readonly 变量，注意：不能 unset，如：readonly B=100 				echo "B=$B"
				将命令的返回值赋值给变量：
					1）A=`ls -la` 反引号，运行里面的命令，并把结果返回给变量 A
					2）A=$(ls -la) 等价于反引号
			
			环境变量：
				基本语法：
				1) export 变量名=变量值 											-将shell变量输出为环境变量
				2) source 配置文件													-让修改后的配置信息立即生效
				3) echo $变量名														-查询环境变量的值
			    如：配置Tomcat环境变量，vim /etc/profile 添加一行：export TOMCAT_HOME=/opt/tomcat，保存退出
					source /etc/profile 让修改后的配置信息立即生效，使用：echo $TOMCAT_HOME
			
			位置参数变量：
				含义：当执行一个shell脚本时，如果希望获取到命令行的参数信息，就可以使用到位置参数变量，比如 ： ./m1.sh 100 200, 	
					  这个就是一个执行shell 的命令行，可以在 m1.sh脚本中获取到参数信息
				基本语法：
					$n  					-n为数字，$0代表命令本身，$1-$9代表第一到第九个参数，10以上的参数需要用大括号包含，如${10}
					$* 						-*代表命令行中所有的参数，$*把所有的参数看成一个整体
					$@						-@代表命令行中所有的参数，不过$@把每个参数区分对待
					$#						-#代表命令行中所有参数的个数
					
			预定义变量：
				含义： shell设计者事先已经定义好的变量，可以直接在shell脚本中使用
				基本语法：
					$$   				    -当前进程的进程号（PID）
					$!						-后台运行的最后一个进程的进程号（PID）
					$？ 					-最后一次执行的命令的返回状态。如果这个变量的值为 0，证明上一个命令正确执行；
											 如果这个变量的值为非 0（具体是哪个数，由命令自己来决定），则证明上一个命令执行不正确了
					
			运算符：
				1) “$((运算式))”或“$[运算式]”
				2) expr m + n 注意 expr 运算符间要有空格
				3) expr m - n
				4) expr \*, /, % 乘，除，取余
				如：计算：(2+3)*6
					方式一：$(((2+3)*6))
					方式二：$[(2+3)*6]
					方式三：TEMP `expr 2 + 3`
							RESULT=`expr $TEMP \* 6`
			
			条件判断：
				基本语法：
					[ condition ]（注意 condition 前后要有空格）#非空返回 true，可使用$?验证（0 为 true，>1 为 false）
					如：[condition] && echo OK || echo notOK                   -条件满足，执行后面的语句
			判断条件：
				1)比较运算符
					= 字符串比较
					-lt 小于
					-le 小于等于
					-eq 等于
					-gt 大于
					-ge 大于等于
					-ne 不等于
					如：if [ 23 -gt 22 ]
						then
							echo "dayu"
						fi	
				2)按照文件权限进行判断
					-r 有读的权限 [ -r 文件 ]
					-w 有写的权限 [ -w 文件 ]
					-x 有执行的权限 [ -x 文件 ]
				3)按照文件类型进行判断
					-f 文件存在并且是一个常规的文件
					-e 文件存在
					-d 文件存在并是一个目录
					如：if [ -e /home/1.txt ]
						then
							echo "exist"
						fi	
			流程控制：
				if条件判断：
					基本语法：
					if [ 条件判断式 ];then
					程序
					fi
					或者
					if [ 条件判断式 ]
					then
					程序
					elif [ 条件判断式 ]
					then
					程序
					fi
				注意：（1）[ 条件判断式 ]，中括号和条件判断式之间必须有空格 (2) 推荐使用第二种方式
				
				case语句：
					case $变量名 in
					"值 1"）
					如果变量的值等于值 1，则执行程序 1
					;;
					"值 2"）
					如果变量的值等于值 2，则执行程序 2
					;;
					…省略其他分支…
					*）
					如果变量的值都不是以上的值，则执行此程序
					;;
					esac
				
				for循环控制：
					for 变量 in 值 1 值 2 值 3…
					do
					程序
					done
					或者
					for (( 初始值;循环控制条件;变量变化 ))
					do
					程序
					done
				while循环控制：
					while [ 条件判断式 ]
					do
					程序
					done
				
			读取控制台输入：
				read(选项)(参数)
				选项：
					-p：指定读取值时的提示符
					-t：指定读取值时等待的时间（秒），如果没有在指定的时间内输入，就不再等待了
				参数：
					变量：指定读取值的变量名
				如：
					read -t 10 -p "请输入一个数NUM=" NUM
					echo "你输入的值是NUM=$NUM" 
			函数：
				分类：系统函数、自定义函数
				系统函数：
					basename：返回完整路径最后 / 的部分，常用于获取文件名
					basename [pathname] [suffix] 							-basename 命令会删掉所有的前缀包括最后一个（‘/’）字符，然后将字符串显示出来，
																			 suffix 为后缀，如果 suffix 被指定了，basename 会将 pathname 或 string 中的 suffix 去掉
					如：basename /home/1.txt								-结果： 1.txt
						basename /home/1.txt .txt  							-结果： 1
	
					dirname：返回完整路径最后 / 的前面的部分，常用于返回路径部分
					dirname 文件绝对路径                                    -从给定的包含绝对路径的文件名中去除文件名（非目录的部分），然后返回剩下的路径（目录的部分）
					如：dirname /home/1.txt									-结果： /home
				
				自定义函数：
					[ function ] funname[()]
					{
					Action;
					[return int;]
					}
					调用直接写函数名：funname [值]
					如：计算2个输入参数的和
						function getSum(){
							SUM=$[SN1+$N2]
							echo "参数的和=$SUM"
						}
						
						read -p "请输入一个数N1=" N1
						read -p "请再输入一个数N2=" N2
						
						调用：getSum $N1 $N2
			
			综合案例：
				需求分析（提示：使用crond定时器）
				1)每天凌晨 2:10 备份 数据库 DB 到 /data/backup/db
				2)备份开始和备份结束能够给出相应的提示信息
				3)备份后的文件要求以备份时间为文件名，并打包成 .tar.gz 的形式，比如：2018-03-12_230201.tar.gz
				4) 在备份的同时，检查是否有 10 天前备份的数据库文件，如果有就将其删除
				编写脚本(备份逻辑)：
					vim /usr/sbin/mysql_db_backup.sh
						BACKUP=/data/backup/db
						echo "------------------------开始备份---------------------"
						echo "------------------------备份的路径是：$BACKUP/$DATETIME.tar.gz---------------------"
						#主机
						HOST=localhost
						#用户名
						DB_USER=root
						#密码
						DB_PWD=123456
						#备份数据库的名称
						DATEBASE=DB
						#创建备份的路径，如果备份的路径文件夹存在，就使用，否则则创建
						[ ! -d "$BACKUP/$DATETIME" ] && mkdir -p "$BACKUP/$DATETIME"
						#执行mysql备份数据库的指令
						mysqldump -u${DB_USER} -p${DB_PWD} --host=$HOST $DATEBASE | gzip > $BACKUP/$DATETIME/$DATETIME.tar.gz
						#打包备份文件
						cd $BACKUP
						tar -zcvf $DATETIME.tar.gz $DATETIME
						#删除临时文件
						rm -rf $BACKUP/$DATETIME
						#删除10天前的备份文件
						find $BACKUP -mtime +10 -name "*.tar.gz" -exec rm -rf {} \; 
						echo "------------------------备份文件成功---------------------"
				将脚本添加到crontab配置里：
					10 2 * * * /usr/sbin/mysql_db_backup.sh
					
	五、其他：
			Ubuntu：
				含义：Ubuntu（友帮拓、优般图、乌班图）是一个以桌面应用为主的开源 GNU/Linux 操作系统，Ubuntu是基于 GNU/Linux，支持 x86、amd64（即 x64）和 ppc（Pocket PC，掌上电脑的操作平台） 架构，由全球化的专业开发团队（Canonical Ltd）
					  打造的。专业的 Python 开发者一般会选择 Ubuntu 这款 Linux 系统作为生产平台
				安装：略，支持中文需要安装中文语言包
					  左侧图标栏System Settings（系统设置）->Language Support（语言支持）选项卡 ->Install / Remove Languages ->
					  Chinese(Simplified) -> Apply Changes ->把汉语（中国）拖到第一位 -> 重启
				用户：安装 ubuntu 成功后，都是普通用户权限，并没有最高 root 权限，如果需要使用 root 权限的时候，
					  通常都会在命令前面加上 sudo。使用 su 命令来直接切换到 root 用户的，但是如果没有给 root 设置初始密码，就会抛出 su :
					  Authentication failure 这样的问题
				设置密码：
					  1) 输入 sudo passwd 命令，输入一般用户密码并设定 root 用户密码
					  2) 设定 root 密码成功后，输入 su 命令，并输入刚才设定的 root 密码，就可以切换成 root 了
					     提示符$代表一般用户，提示符#代表 root 用户
					  3) 输入 exit 命令，退出 root 并返回一般用户
				软件管理：
					apt 是 Advanced Packaging Tool 的简称，是一款安装包管理工具
					在 Ubuntu 下，我们可以使用 apt 命令可用于软件包的安装、删除、清理等，类似于 Windows 中的软件管理工具
				使用：
					sudo apt-get update 										-更新镜像源
					sudo apt-get install package 								-安装包
					sudo apt-get remove package 								-删除包
					sudo apt-cache search package 								-搜索软件包
					sudo apt-cache show package									-获取包的相关信息，如说明、大小、版本等
					sudo apt-get install package --reinstall					-重新安装包
					
					sudo apt-get -f install										-修复安装
					sudo apt-get remove package --purge 						-删除包，包括配置文件等
					sudo apt-get build-dep package 								-安装相关的编译环境

					sudo apt-get upgrade 										-更新已安装的包
					sudo apt-get dist-upgrade 									-升级系统
					sudo apt-cache depends package 								-了解使用该包依赖那些包
					sudo apt-cache rdepends package 							-查看该包被哪些包依赖
					sudo apt-get source package									-下载该包的源代码
				
				国内镜像源：https://mirrors.tuna.tsinghua.edu.cn/
				
				备份镜像源：sudo cp /etc/apt/sources.list /etc/apt/sources.list.backup
				
			使用SSH远程登录：
				SSH 为 Secure Shell 的缩写，由 IETF 的网络工作小组（Network Working Group）所制定；SSH 为
				建立在应用层和传输层基础上的安全协议
				SSH 是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。常用于远程登录，以
				及用户之间进行资料拷贝。几乎所有 UNIX 平台—包括 HP-UX、Linux、AIX、Solaris、Digital UNIX、
				Irix，以及其他平台，都可运行 SSH。
				使用 SSH 服务，需要安装相应的服务器和客户端。客户端和服务器的关系：如果，A 机器想被 B
				机器远程控制，那么，A 机器需要安装 SSH 服务器，B 机器需要安装 SSH 客户端
				和 CentOS 不一样，Ubuntu 默认没有安装 SSHD 服务，因此，我们不能进行远程登录
				
				安装：
					sudo apt-get install openssh-server                         -安装了 SSH 服务端和客户端
					service sshd restart                                        -启动了 sshd 服务，监听端口 22
					
					
				从Linux 客户机连接Linux 服务机：
					基本语法：
					ssh 用户名@IP，如：ssh atguigu@192.168.188.131，使用 ssh 访问，如访问出现错误。可查看是否有该文件 ～/.ssh/known_ssh 尝试删除该文件解决
					登出：exit 或者 logout				
				
----------------------------------------------Nginx WEB服务器篇----------------------------------------------------------------------------------												
	一、基本介绍：参考：https://www.runoob.com/linux/nginx-install-setup.html
			含义：Nginx("engine x")是一款是由俄罗斯的程序设计师Igor Sysoev所开发高性能的Web和反向代理服务器，也是一个IMAP/POP3/SMTP邮件代理服务器。
				  在高连接并发的情况下，Nginx是Apache服务器不错的替代品，目前的版本有：稳定版、开发版和历史稳定版。业界使用其产品的公司如：腾讯、新浪
			安装：
				下载地址: http://nginx.org/download/nginx-1.4.2.tar.gz				  
				yum install pcre pcre-devel									-nginx依赖于pcre库,要先安装pcre、pcre-devel
				cd /usr/local/src/
				wget http://nginx.org/download/nginx-1.4.2.tar.gz
				tar -zxvf nginx-1.4.2.tar.gz 								-解压
				cd nginx-1.4.2
				./configure --prefix=/usr/local/nginx						-配置安装路径
				make && make install 										-安装
			启动：
				目录结构：cd /usr/local/nginx，会看到：				
					conf 														-配置文件  
					html 														-网页文件
					logs  														-日志文件 
					sbin  														-主要二进制程序
				启动：./sbin/nginx
				注意：默认端口80，如果被占用，需要停止80端口所对应的程序或服务
					  1）查看端口：netstat -antp | grep 80                      -得到80端口对应的进程ID
					  2）暴力停止：Pkill -9 PID
			信号源控制：
				1）TERM、INT													-快速关闭
				2）QUIT 														-优雅的关闭进程,即等请求结束后再关闭
				3）HUP 															-改变了配置文件,平滑的重读配置文件（新配置替代旧配置）
				4）USR1 														-重读日志,在日志按月/日分割时有用
				5）USR2															-平滑的升级
				6）WINCH														-优雅关闭旧的进程(配合USR2来进行升级)
				具体语法:
					Kill -信号选项 nginx的PPID（主进程ID），如：Kill -HUP 4873
					Kill -信号控制 `cat [安装路径下]/logs/nginx.pid`，如：Kill -USR1 `cat [安装路径下]/logs/nginx.pid`					
		
		附[总结]：
		nginx常用指令：
			启动命令：[安装路径下]/usr/local/nginx/sbin/nginx
			停止命令：[安装路径下]/usr/local/nginx/sbin/nginx -s stop 强制关闭
					  [安装路径下]/usr/local/nginx/sbin/nginx -s quit 安全关闭
			重启命令：[安装路径下]/usr/local/nginx/sbin/nginx -s reload		  
			测试配置文件：[安装路径下]/usr/local/nginx/sbin/nginx -t
			检测是否出错：[安装路径下]/usr/local/nginx/sbin/nginx -c
			查看帮助：[安装路径下]/usr/local/nginx/sbin/nginx -h
			查看进程：ps -ef | grep nginx
			平滑重启：kill -HUP Nginx主进程号
		查看端口：
			netstat -antp |grep 80									-端口是否被占用
			ps -ef | grep 8081 										-进程
			top 
			
	二、配置文件：					
			位置：/usr/local/nginx/conf/nginx.conf
			文件解析：
				全局区：
					#工作的子进程,可以自行修改,但太大无益,因为要争夺CPU,一般设置为 CPU数*核数
					worker_processes 1; 
					
					#是否以守护进程开启
					daemon：默认on 可选值on/off
					
					#是否主进程中开启多个子线程
					master_process：默认on 可选值on/off
					
					#一般配置nginx连接的特性
					Event {					
					 #如1个worker能同时允许多少连接，如下指一个子进程最大允许连1024个连接
					 worker_connections  1024;
					}
					
					#配置http服务器的主要段
					http { 
						 #日志
						 #access_log  logs/access.log  main;
						 #超时时间
						 keepalive_timeout 75;
						 #全局设置
						 location / {
							deny 192.168.1.2;						//拒绝指定客户端访问
							allow 192.168.1.3/300;					//允许指定客户端访问[IP段]
							denyall;
						 }						 
						 #虚拟主机段
						 Server1 {							   
								#定位,把特殊的路径或文件再次定位，如image目录单独处理；.php单独处理
								Location {
								}
								#解析超时
								resolver_timeout 30s;

						 }
						 Server2 {
						 }
					}
					
					如：
						基于域名虚拟主机
						server {
							#监听端口  
							listen 80;
							#监听域名，需要域名映射，在hosts文件中添加映射；支持配置多个域名，使用空格隔开；
							server_name 1xuepai.com; 
							#定位,把特殊的路径或文件再次定位
							#日志
							#access_log  logs/host.access.log  main;
							location / {
									#根目录定位，绝对路径
									root /var/www/1xuepai.com; 
									#alias 别名
									index index.html;
							}
						}
						基于端口虚拟主机
						server {
							#监听端口
							listen 8080;
							#监听端口
							server_name 192.168.1.175;
							location / {
									#根目录定位，绝对路径
									root /var/www/html8080;
									index index.html;
							}
						}
					
					日志管理：
						在nginx的http段与server段,都有类似信息#access_log信息;
						如在server段：#access_log logs/host.access.log  main说明该server段访问日志的文件是logs/host.access.log,
						使用的格式”main”格式。除了main格式，也可以自定义其他格式
						
					格式说明：
						main格式：
							log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
											  '$status $body_bytes_sent "$http_referer" '
											  '"$http_user_agent" "$http_x_forwarded_for"';

							main格式是默认定义好一种日志的格式,并起个名字，便于引用
							main类型的日志,记录的 remote_addr.... http_x_forwarded_for等选项

							1: 日志格式选项说明（以main格式为例）：											
									远程IP - 远程用户/用户时间 请求方法(GET/POST)
									请求状态 请求体body长度 referer来源信息
									http_user_agent用户代理/蜘蛛，被转发的请求的原始IP
									http_x_forwarded_for:在经过代理时,代理把本来IP加在此头信息中,传输你的原始IP

							2: 声明一个log_format并命名：
									log_format mylog '$remote_addr- "$request" '
													 '$status $body_bytes_sent "$http_referer" '
														'"$http_user_agent" "$http_x_forwarded_for"';
						
							3：使用：
								如：在http/server/location,我们就可以引用 mylog 自定义的日志格式
									Nginx允许针对不同的server做不同的Log ，(有的web服务器不支持,如lighttp)
								
								声明log   	log位置         	 log格式;
								access_log logs/access_mylog.log  mylog;   
								
					案例：Shell编程+Crontab定时任务+nginx信号管理，完成日志按日期存储						
						  分析思路: 
							凌晨00:01,把昨天的日志重命名，放在相应的目录下，再USR1信息号控制nginx重新生成新的日志文件							
							
							脚本:
							编辑脚本vim logback.sh
							#!/bin/bash
							base_path='/usr/local/nginx/logs'
							log_path=$(date -d yesterday +"%Y%m")
							day=$(date -d yesterday +"%d")
							mkdir -p $base_path/$log_path
							mv $base_path/access.log $base_path/$log_path/access_$day.log
							#echo $base_path/$log_path/access_$day.log
							kill -USR1 `cat /usr/local/nginx/logs/nginx.pid`  -- 加载日志

							定时任务
							Crontab 编辑定时任务，crontab -e 
							01 00 * * * /xxx/path/logback.sh  每天0时1分(建议在02-04点之间,系统负载小)
							
					定位Location管理[server段]：
						含义：location 有”定位”的意思, 根据Uri来进行不同的定位
							  在虚拟主机的配置中,是必不可少的,location可以把网站的不同部分,定位到不同的处理方式上，比如, 碰到.php，如何调用PHP解释器?就需要location					
						
						基础语法：
							#中括号可以不写任何参数,此时称为一般匹配，也可以写参数	
							location [=|~|~*|^~] patt {
							}							  						
							因此,大类型可以分为3种
							location patt{}  [一般匹配]
							location = patt {} [精准匹配]							
							location ~ patt{} [正则匹配]
						
						Uri解析过程：						
							   先判断有没有精准匹配,如果有,则停止匹配过程，返回结果
							   #如果 $uri == patt,匹配成功，使用configA
							   location = patt {
									config A
							   }
							   如：
								  #精准匹配
								  location = / {
											root   /var/www/html/;
											index  index.htm index.html;
								  }	
								  #一般匹配
								  location / {
											root   /usr/local/nginx/html;
											index  index.html index.htm;
								  }
							说明：
								如果访问http://xxx.com/，定位流程是：								　
								1: 精准匹配中”/”,得到index页为index.htm，结束
								2: 再次访问http://xxx.com/index.htm,此次内部转跳uri已经是”/index.htm”,根目录为/usr/local/nginx/html								
								3: 最终结果,访问了/usr/local/nginx/html/index.htm
							
							再来看，正则也来参与
								location / {
									root   /usr/local/nginx/html;
									index  index.html index.htm;
								}

								location ~ image {
									root /var/www/;
									index index.html;
								}
							说明：
								如果我们访问http://xx.com/image/logo.png
								此时，“/”与”/image/logo.png”匹配
								同时，”image”正则 与”image/logo.png”也能匹配,谁发挥作用?
								正则表达式的成果将会使用，图片真正会访问/var/www/image/logo.png 								
							再如：
								location / {
									root   /usr/local/nginx/html;
									index  index.html index.htm;
								}
								 
								location /foo {
									root /var/www/html;
									index index.html;
								}
							我们访问 http://xxx.com/foo
							对于uri“/foo”,两个location的patt,都能匹配，即 ‘/’能从左前缀匹配 ‘/foo’, ‘/foo’也能左前缀匹配’/foo’，							
							此时, 真正访问/var/www/html/index.html，原因:’/foo’匹配的更长,因此使用它
						结论：
							1）请求Uri，先判断是否有精准匹配，如果命中，返回结果并结束解析过程
							2）判断普通命中，如果多个命中，记录最长的命中结果，注意只是记录不结束，以最长的为准（与普通匹配顺序无关）
							3）判断正则匹配，按顺序从上到下匹配，只要有1个匹配，结束匹配过程并返回结果（与正则顺序有关）
						
					重写rewrite：功能类似于location
						前提：Linux系统得安装pcre库（Perl Compatible Regular Expressions，perl兼容正则表达式），安装pcre库是为了使Nginx支持HTTP Rewrite模块
						含义：该指令通过正则表达式的使用来改变URI.可以同时存在一个或者多个指令，按照顺序一次对URL进行匹配和处理
						位置：该指令在server块或server块内的location块中配置 
						相关指令：
							关键字：
								if  (条件) {}  #设定条件,再进行重写 
								set #设置变量
								return #返回状态码 
								break #跳出rewrite
								rewrite #重写

							语法格式：
							If 空格 (条件) {
								重写模式
							}
							说明：
								条件写法：3种
								1: “=”来判断相等, 用于字符串比较
								2: “~” 用正则来匹配(此处的正则区分大小写)， ~* 不区分大小写的正则								  
								3: -f -d -e来判断是否为文件,为目录,是否存在
							全局变量：
								$args							-请求URL中的请求参数，如：http://www.myweb.name/server/source?arg1=value1&arg2=value2中的arg1=value1&arg2=value2
								$content_length					-请求头中的Content_Length字段
								$content_type					-请求头中的Content_type字段
								$document_root					-请求的根路径
								$document_uri					-请求中的uri，不包括请求指令，如：http://www.myweb.name/server/source?arg1=value1&arg2=value2中的/server/source
								$host							-请求URL中的主机部分，如：http://www.myweb.name/server中的www.myweb.name，在nginx中server中的server_name配置项配置
								$http_user_agent				-客户端的代理信息
								$http_cookie					-客户端的cookie信息
								$limit_rate						-Nginx服务器对网络速率的限制，限速
								$remote_addr					-客户端地址
								$remote_port					-客户端与服务端连接的端口号
								$remote_user					-客户端用户
								$request_body_file        		-请求体本地资源文件名称
								$request_method					-请求方法，如：GET/POST
								$request_filename				-请求资源文件路径名	
								$request_uri					-请求中的uri，包括请求指令	
								$query_string					-与$args相同
								$scheme							-客户端请求使用的协议，如：HTTP、HTTPS、FTP协议
								$server_protocol         		-客户端请求协议的版本，如：HTTP/1.0、HTTP/1.1
								$server_addr					-服务器地址
								$server_name					-服务器名称
								$server_port					-服务器端口号
								$uri							-与$document_uri相同								
							例子:
								#客户端为100的禁止访问
								if  ($remote_addr = 192.168.1.100) {
									return 403;
								}
								#判断IE浏览器并重写
								if ($http_user_agent ~ MSIE) {
										rewrite ^.*$ /ie.htm;
										break; #不break会循环重定向
								}

								if (!-e $document_root$fastcgi_script_name) {
									rewrite ^.*$ /404.html break; #此处还要加break
								} 
								说明：
									以xx.com/dsafsd.html这个不存在页面为例，观察访问日志(tail logs/access.log), 日志中显示的访问路径,依然是GET /dsafsd.html HTTP/1.1						
									提示: 服务器内部的rewrite和302重定向跳转不一样，跳转的话URL都变了，变成重新http请求404.html，
										  而内部rewrite，上下文没变，就是说fastcgi_script_name（默认SCRIPT_FILENAME = $fastcgi_script_name）仍然是dsafsd.html，因此会循环重定向，所有需要break										 
							
							set:设置变量，可以用来达到多条件判断时作标志用来达到apache下的rewrite_condition的效果							
								如下: 
								#判断浏览器并重写，且不用break
								if ($http_user_agent ~* msie) {
												set $isie 1;
								}
								if ($fastcgi_script_name = ie.html) {
									set $isie 0;
								}
								if ($isie 1) {
									rewrite ^.*$ ie.html;
								}
							
						Rewrite语法：Rewrite 正则表达式  重定向后的位置					
						goods-3.html ---->goods.php?goods_id=3
						goods-([\d]+)\.html --->goods.php?goods_id =$1  

						location /ecshop {						
							index index.php;
							rewrite goods-([\d]+)\.html$ /ecshop/goods.php?id=$1;
							rewrite category-(\d+)-b(\d+)\.html /ecshop/category.php?id=$1&brand=$2;					
						}
						#注意:用Url重写时, 正则里如果有”{}”,正则要用双引号""包起来
						
					nginx + php 编译流程：	
						fastcgi含义：
							apache是把php当做自己的一个模块来启动的，而nginx则是把http请求变量转发给php进程，
							即php独立进程，与nginx进行通信称为fastcgi运行方式
						总结：	
							把请求的信息转发给默认9000端口的PHP进程，让PHP进程处理指定目录下的PHP文件					
							如下例子:
							location ~ \.php$ {
								root html;
								fastcgi_pass   127.0.0.1:9000;
								fastcgi_index  index.php;
								fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
								include        fastcgi_params;
							}
							说明：
								1: 碰到php文件
								2: 把根目录定位到html
								3: 把请求上下文转交给9000端口PHP进程
								4: 并告诉PHP进程，当前的脚本是 $document_root$fastcgi_script_name(注:PHP会去找这个脚本并处理)
								
					网页压缩与传播速度优化：
						案例：
							观察网易新闻news.163.com的头信息
							请求:
							Accept-Encoding:gzip,deflate,sdch,br
							响应:
							Content-Encoding:gzip
							Content-Length:36093
							再把页面另存下来,观察,约10W字节,实际传输的36093字节,原因-就在于gzip压缩上							
							原理: 
							浏览器---请求---->声明可以接受gzip压缩或deflate压缩或compress或sdch压缩或br压缩
							从http协议的角度看---请求头声明acceopt-encoding: gzip deflate sdch br (是指压缩算法,其中sdch是google倡导的一种压缩方式,目前支持的服务器尚不多)
							服务器-->回应---把内容用gzip方式压缩---->发给浏览器
									浏览<-----解码gzip-----接收gzip压缩内容----

							推算一下节省的带宽:
							假设 news.163.com  PV（page view页面浏览量）  2亿
							2*10^8  *  9*10^4 字节 == 
							2*10^8 * 9 * 10^4  * 10^-9 = 12*K*G = 18T，节省的带宽是非常惊人的！
						
						使用：
							位置：HTTP段
							参数说明：
								#gzip配置的参数
								gzip on|off  #是否开启gzip
								gzip_buffers 32 4K| 16 8K #缓冲(压缩在内存中缓冲几块? 每块多大?)
								gzip_comp_level [1-9] #推荐6 压缩级别(级别越高,压的越小,越浪费CPU计算资源)
								gzip_disable #正则匹配URI 什么样的Uri不进行gzip
								gzip_min_length 200 #开始压缩的最小长度(再小就不要压缩了,意义不在)
								gzip_http_version 1.0|1.1 #开始压缩的http协议版本(可以不设置,目前几乎全是1.1协议)
								gzip_proxied          #设置请求者代理服务器,该如何缓存内容
								gzip_types text/plain  application/xml #对哪些类型的文件用压缩 如txt,xml,html ,css
								gzip_vary on|off  #是否传输gzip压缩标志

								注意: 
								图片/mp3这样的二进制文件,不必压缩,因为压缩率比较小, 比如100->80字节,而且压缩也是耗费CPU资源的								
								比较小的文件不必压缩
					
					Nginx缓存设置，提高网站的性能：		
						介绍：对于网站的图片,尤其是新闻站, 图片一旦发布, 改动的可能是非常小的.希望能否在用户访问一次后,图片缓存在用户的浏览器端,且时间比较长的缓存，在nginx中用expires设置
						使用：在[虚拟主机]location或if段里来写
							  格式：  
							  expires 30s;
							  expires 30m;
							  expires 2h;
							  expires 30d;
							注意：服务器的日期要准确,如果服务器的日期落后于实际日期,可能导致缓存失效！  
							如：
							location  ^~ /imgs/ {
								root opt/wangjialuo/;
								expires 1d;									
							}
						
						缓存另一种手段：利用304状态码
							304状态码：
							   如果客户端发送了一个带条件的GET请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个304状态码。
							   简单的表达就是：服务端已经执行了GET，但文件未变化！
							原理是: 服务器响应文件内容时同时响应etag标签(内容的签名,内容一变,它也变)和 last_modified_since 2个标签值
									浏览器下次去请求时,头信息发送这两个标签, 服务器检测文件有没有发生变化，如无，直接头信息返回 etag,last_modified_since
									浏览器知道内容无改变,于是直接调用本地缓存。这个过程,也请求了服务器,但是传着的内容极少。		
									对于变化周期较短的,如静态html,js,css,比较适于用这个方式！
							
					Nginx反向代理与负载均衡：
						介绍：apache
							反向代理[动静分离]：nginx利用proxy实现，如：客户端发起一个PHP请求，Nginx服务器自己不处理，通过proxy_pass转发给其他服务器（如：apache）
												来处理，而且Nginx服务器只负责处理静态的数据
							负载均衡：nginx利用upstream实现，反向代理后端如果有多台服务器（如：多台apache）,自然形成负载均衡
							
							问题：如何利用proxy_pass指向多台服务器?
							实现过程：把多台服务器用upstream指定绑定在一起并起个组名,然后proxy_pass指向该组；
							负载均衡流程：
																	upstream[指向组名]	     服务器1[组成员]
								客户端 ----------------> nginx ----------------------------> 服务器2[组成员]
																					         服务器3[组成员]
							负载均衡算法IRule：
								分类：区别于Java后台的SpringBoot技术栈的负载均衡
									1）轮询，默认的策略，如果server挂掉，能自动剔除
									2）加权，默认是1
									    如：									   
										upstream  1xuepai.com {   
											server   192.168.99.100:42000 weight=1; 
											server   192.168.99.100:42001 weight=2;  
										}
									3）最少链接数，把请求分配到连接数最少的server
										如：
										upstream  1xuepai.com {   
											least_conn;
											server   192.168.99.100:42000; 
											server   192.168.99.100:42001;  
										}
									4）IP_HASH一致性哈希，每个请求会按照访问ip的hash值分配，这样同一客户端连续的Web请求都会被分发到同一server进行处理，可以解决session共享的问题。如果server挂掉，能自动剔除
										如：
										upstream  1xuepai.com {   
											ip_hash;
											server   192.168.99.100:42000; 
											server   192.168.99.100:42001;  
										}
							位置：upstream配置在http段内，server段外；proxy_pass配置在server段内的location端里，即：server段与upstream端平级
							
							示例：
								#这里域名要和下面proxy_pass的一样，且不能使用下划线，timeMachine不能写成time_machine
								#负载均衡池
								upstream  timeMachine.com {
									#fail_timeout：当该时间内服务器没响应，则认为服务器失效，默认10s
									#max_fails：允许连接失败次数，默认为1
									server    10.240.35.113:8081 weight=1 fail_timeout=3s max_fails=3;
									server    10.240.35.113:8082  weight=2 backup; # 备机
									server    10.240.35.113:8084 down; # down主机暂停服务
								}
								 
								server { 								
									#keepalive_requests 120; # 单连接请求上限次数
									listen       8083; # 监听端口
									#监听地址，写ip地址或主机名、域名都可 
									server_name  10.240.35.113;
								 
									#location块，请求的url过滤
									location / {   
										proxy_pass http://timeMachine.com;
										proxy_redirect default;
										#proxy_connect_timeout：与服务器连接的超时时间，默认60s
										proxy_connect_timeout 3s;
									}
								 
									error_page   500 502 503 504  /50x.html; # 错误页
									location = /50x.html {
										root   html;
									}
									
								}
								
								结论：等待时间 = proxy_connect_timeout + fail_timeout * max_fails
					
					Nginx图片服务器：
						目的：为了缓存web服务器的访问压力，可以单独搭建文件服务器[图片、视频等]
						使用：
							在server段添加配置，如：
							location /images/ {
								root /var/www/nginx_imgs/	                #图片存放位置
							}
							
	三、nginx与keepalived实现HA，可参考：https://www.jb51.net/article/142443.htm
			目的：高并发情况下为了考虑Nginx的单点故障，真正做到架构高可用性HA，实现nginx的故障转移，同时做好监控报警。
			keepalived定义：
				Keepalived是一个基于VRRP协议[Virtual Router Redundancy Protocol，即 虚拟路由冗余协议，是实现路由器高可用HA的容错协议]来实现的服务高可用方案，可以利用其来避免IP单点故障，
				类似的工具还有heartbeat、corosync、pacemaker。
				但是它一般不会单独出现，而是与其它负载均衡技术（如lvs、haproxy、nginx）一起工作来达到集群的高可用。
			原理流程：			
						keepalived[充当路由角色]										 服务器1
				客户端 ----------------------------> nginx[master] --------------------> 服务器2
						访问公共IP[虚拟IP]			 nginx[backup]						 服务器3
						
				注释：nginx[master]和 nginx[backup]都需要与keepalived建立绑定关系，当nginx[master]宕机后，会自动的切换
					  到nginx[backup]使用；当恢复nginx[master]后又重新切换回nginx[master]使用。			
			使用：
				示例：环境准备
					2台nginx[linux]服务器（如：192.168.1.129与192.168.1.130，nginx端口默认80）都安装好keepalived服务
					一个虚拟IP[公共IP] 192.168.1.131
					安装keepalived服务
						#准备下载好的keepalived安装包文件
						#解压并进入解压目录
						tar -zxvf keepalived-1.2.18.tar.gz
						cd keepalived-1.2.18
						#指定安装目录并安装
						./configure --prefix=/opt/keepalived
						make && make install
					将keepalived安装成Linux系统服务
						mkdir /etc/keepalived/
						cp /opt/keepalived/etc/rc.d/init.d/keepalived /etc/init.d/
						cp /opt/keepalived/etc/sysconfig/keepalived /etc/sysconfig/
						ln -s /opt/sbin/keepalived /usr/sbin/
						ln -s /opt/keepalived/sbin/keepalived /sbin/
				    设置keepalived服务开机启动
						chkconfig keepalived on
					  
					keepalived目录结构：
						安装目录下有：
							bin		-genhash
							etc		-keepalived
												 -keepalived.conf[重点]
												 -samples
									-rc.d
												 -init.d
									-sysconfig
												 -keepalived
							sbin
							share
					  
					同时修改安装路径下的keepalived.conf的配置与/etc/keepalived/keepalived.conf的配置[2台服务都要配置]
					配置信息如下：
						! Configuration File for keepalived (!、#都是注释)
					　　global_defs { #全局配置
					　　notification_email { #通知邮件，接收邮件
					　　　　acassen@firewall.loc
					　　　　failover@firewall.loc
					　　　　sysadmin@firewall.loc
					　　}
					　　notification_email_from Alexandre.Cassen@firewall.loc #发送邮件
					　　smtp_server 192.168.200.1 #发送邮件服务器IP
					　　smtp_connect_timeout 30 #发送邮件超时时间
					　　router_id LVS_01 #这个配置要唯一，一般配置成Linux的主机名hostname，可以在/etc/hosts里添加设置
					　　}　

					　　vrrp_script chk_nginx {
					　　　　script "/etc/keepalived/nginx_check.sh" ## 检测 nginx 状态的脚本路径
					　　　　interval 2 ## 检测时间间隔
					　　　　weight -20 ## 如果条件成立，权重-20
					　　}　

					　　vrrp_instance VI_1 { #实例 VI_1 名字可以随意 但是不建议修改
					　　　　state MASTER # 主服务器MASTER 从服务器 BACKUP
					　　　　interface em1 # em1 网卡，查看网卡：ifconfig 或 ip addr
					　　　　virtual_router_id 129 #virtual_router_id 主备要不一致，要与当前的机器IP保持一致
					　　　　mcast_src_ip 192.168.1.129 		#本机IP
							nopreempt 		#优先级高的异常恢复后抢占问题
							priority 100 　　# 优先级 数字越大优先级越高 priority 的值 主服务器要大于从服务器
					　　　　advert_int 1　　#设定MASTER与BACKUP负载均衡器之间同步检查的时间间隔，单位是秒
					　　　　authentication { # 主从通信验证类型及密码 
					　　　　　　auth_type PASS　　#设置vrrp验证类型，主要有PASS和AH两种
					　　　　　　auth_pass 1111　　#设置vrrp验证密码，在同一个vrrp_instance下，MASTER与BACKUP必须使用相同的密码才能正常通信
					　　　　}　

					　　　　## 将track_script块加入instance配置块
					　　　　track_script {
					　　　　　　chk_nginx ## 执行 Nginx 监控的服务
					　　　　}

							## 虚拟IP[VIP]池
					　　　　virtual_ipaddress {
					　　　　192.168.1.131/135 #VRRP HA 虚拟IP地址 如果有多个VIP，继续换行填写
					　　　　}
					　　}　

					编写Nginx状态检测脚本：vim /etc/keepalived/nginx_check.sh
					内容如下：
						#!/bin/bash
					　　A=`ps -C nginx –no-header |wc -l`
					　　if [ $A -eq 0 ];then
					　　　　/opt/nginx/sbin/nginx				#nginx安装目录
					　　　　sleep 2
					　　　　if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then

					　　　　　　killall keepalived
					　　　　fi
					　　fi
					保存后，给脚本赋执行权限：chmod +x/etc/keepalived/nginx_check.sh
					注意点：Keepalived主从配置文件不同点
					　　1）router_id不一致
					　　2）state 主服务器是MASTER，从服务器是BACKUP
					　　3）priority 主服务器大于从服务器
					keepalived使用：
					　　启动： service keepalived start
					　　停止： service keepalived stop
					　　重启： service keepalived restart						
					测试：开启2台服务的nginx和keepalived服务，然后关闭任意一个nginx观察访问的
						  虚拟IP：192.168.1.131 所使用的的nginx服务是129的？还是130的？
						  
----------------------------------------------FastDfs文件存储技术篇----------------------------------------------------------------------------------	
		技术支持：参考https://blog.csdn.net/kamroselee/article/details/80334621
	一、简介
		FastDFS是一款类Google FS开源的轻量级分布式文件系统，用纯C语言实现，支持UNIX系统。功能：文件存储、文件同步[组内物理节点]、文件访问（文件上传、文件下载）等，
		解决了大容量存储和负载均衡的问题。
		特别适合以文件（建议范围：4KB < file_size <500MB）为载体的在线服务，如相册网站、视频网站等等。
		术语：
			Tracker Server：跟踪服务器，与client通信，在Http访问上配合nginx实现起负载均衡/调度[集群]的作用。
			Storage Server：存储服务器，保存文件和文件的meta data（元数据），可以配置集群。
			Group：FastDFS采用了分组存储方式，组内的Storage server之间是平等关系，不同组的Storageserver之间不会相互通信，组内的Storage server之间会相互连接进行文件同步！
				   增加组来扩充存储容量（横向扩容），组内增加存储服务器来扩充服务能力（纵向扩容）。
			Storage State：状态收集，Storage server会连接集群中所有的Tracker server，定时向他们报告自己的状态，包括磁盘剩余空间、文件同步状况、文件上传下载次数等统计信息。
		文件上传流程：
			状态收集------>客户端上传请求------>tracker查询可用的storage（检测同步状态）------>返回信息(storage的IP与端口)给客户端------>客户端上传文件（file_content与metadata）------>storage生成file_id并写入磁盘
					------>storage返回file_id（路径信息与文件名）给客户端------>客户端存储文件信息
			客户端得到的形如这种格式fild_id：group1/M00/02/44/wKhlBVVY2M-AM_9DAAAT7-0xdqM485_big.png
			文件解析：
				group1:组名
				M00：虚拟磁盘路径，磁盘选项中store_path*[存储服务器]对应，如果配置了store_path0则是M00，如果配置了store_path1则是M01；内部其实是通过软连接实现的；
				02/44：数据两级目录，256*256个目录
				wKhlBVVY2M-AM_9DAAAT7-0xdqM485_big.png：文件名，文件名包含：源存储服务器IP地址、文件创建时间戳、文件大小、随机数和文件拓展名等信息。
		文件下载流程：
			状态收集------>客户端下载链接请求------>tracker查询可用的storage（检测同步状态）------>返回信息(storage的IP与端口)给客户端------>客户端传入file_id（组名，路径，文件名）------>storage查找文件
					------>storage返回file_content给客户端
		安装：
			单节点安装：安装tracker，再安装storage
			主要步骤：
				准备工作：
					1）下载安装包：http://sourceforge.net/projects/FastDFS/或https://github.com/happyfish100/FastDFS（推荐）
					2）系统环境配置：FastDFS编译依赖gcc环境，yum install gcc-c++
					3）安装依赖库[规划安装目录：/usr/local/]：yum -y install libevent；--安装libevent
								   cd /usr/local
								   tar -zxvf libfastcommonV1.0.7.tar.gz
								   cd libfastcommon-1.0.7
								   ./make.sh
								   ./make.sh install --安装libfastcommon，注意：libfastcommon安装好后会自动将库文件拷贝至/usr/lib64下，由于FastDFS程序引用usr/lib目录所以需要将/usr/lib64下的库文件拷贝至/usr/lib下
				
				tracker
					编译安装：[规划安装目录：/usr/local/]
						tar -zxvf FastDFS_v5.05.tar.gz
						cd FastDFS
						./make.sh
						./make.sh install --安装成功将安装目录下的conf下的文件拷贝到目录/etc/fdfs/下，
					修改配置：进入/etc/fdfs/目录，执行：cp tracker.conf.sample tracker.conf，修改配置：vim tracker.conf，base_path=/home/yuqing/FastDFS 改为base_path=/home/FastDFS
					启动：/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf restart
						  或/etc/init.d/fdfs_trackered restart
					设置开机自动启动：vim /etc/rc.d/rc.local，添加一行：/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf restart或/etc/init.d/fdfs_trackered restart
				storage
					编译安装：同tracker，
					修改配置：进入/etc/fdfs/目录，执行：cp storage.conf.sample storage.conf，修改配置：vim storage.conf，
							  group_name=group1，base_path=/home/yuqing/FastDFS改为：base_path=/home/FastDFS，store_path0=/home/yuqing/FastDFS改为：store_path0=/home/FastDFS/fdfs_storage--->对应M00
							  tracker_server=192.168.101.3:22122 #配置tracker服务器的IP，默认端口为22122
							  http_server_port=8888 #配置http服务端口
					启动：/usr/bin/fdfs_storaged /etc/fdfs/storage.conf restart，格式:客户端指令+配置文件+操作指令
						  或/etc/init.d/fdfs_storaged restart
					设置开机自动启动：vim /etc/rc.d/rc.local，添加一行：/usr/bin/fdfs_storaged /etc/fdfs/storage.conf restart或/etc/init.d/fdfs_storaged restart
				上传测试：
					修改配置：进入/etc/fdfs/目录，执行：cp client.conf.sample client.conf，修改配置：vim client.conf，base_path=/home/yuqing/FastDFS 改为base_path=/home/FastDFS
							  tracker_server=192.168.101.3:22122 #配置tracker服务器的IP
					测试：将/home下的图片1.png上传到FastDFS中，
						  执行指令：/usr/bin/fdfs_test /etc/fdfs/client.conf upload /home/1.png -->执行结果：192.168.101.3/group1/M00/00/00/wKhlBVVY2M-AM_9DAAAT7-0xdqM485_big.png
									对应服务器位置：/home/fastdfs/fdfs_storage/data/group1/00/00/wKhlBVVY2M-AM_9DAAAT7-0xdqM485_big.png
									
		java Client API：略
		FastDFS和nginx整合[主要是存储服务器上]
			在tracker上安装nginx：目的是实现反向代理、负载均衡。
			在Storage上安装nginx：[规划安装目录：/usr/local/]，目的是实现Http方式的上传于下载。
				主要步骤：
					 1）cd /usr/local
						tar -zxvf FastDFS-nginx-module_v1.16.tar.gz
						cd FastDFS-nginx-module/src
						vim ./config --修改config文件将/usr/local/路径改为/usr/
						cp mod_FastDFS.conf /etc/fdfs/ --将FastDFS-nginx-module/src下的mod_FastDFS.conf拷贝至/etc/fdfs/下并修改mod_FastDFS.conf的内容:
							vim /etc/fdfs/mod_FastDFS.conf
							base_path=/home/FastDFS
							tracker_server=192.168.101.3:22122 #多个tracker配置多行
							url_have_group_name=true #url中包含group名称
							store_path0=/home/FastDFS/fdfs_storage #指定文件存储路径
					 2）拷贝文件：cp /usr/lib64/libfdfsclient.so /usr/lib/
					 3）把module添加nginx中，通过设置安装参数方式添加模块：
						/configure \ 
						–prefix=/usr/local/nginx \ 
						–pid-path=/var/run/nginx/nginx.pid \ 
						–lock-path=/var/lock/nginx.lock \ 
						–error-log-path=/var/log/nginx/error.log \ 
						–http-log-path=/var/log/nginx/access.log \ 
						–with-http_gzip_static_module \ 
						–http-client-body-temp-path=/var/temp/nginx/client \ 
						–http-proxy-temp-path=/var/temp/nginx/proxy \ 
						–http-fastcgi-temp-path=/var/temp/nginx/fastcgi \ 
						–http-uwsgi-temp-path=/var/temp/nginx/uwsgi \ 
						–http-scgi-temp-path=/var/temp/nginx/scgi \ 
						–add-module=/usr/local/Fastdfs-nginx-module/src
					 4）编译安装nginx：make; make install 
					 5）nginx添加服务端：
						server {
					        listen       8888; #对应storage.conf中配置的服务地址
					        server_name  192.168.101.3;					 
					        location /group1/M00/{ #也可以使用正则，~/group[0-9]/M00
					                #root /home/FastDFS/fdfs_storage/data;
					                ngx_fastdfs_module;
					        }
						}
					 6）访问测试：http://192.168.101.3:8888/group1/M00/00/00/wKhlBVVY2M-AM_9DAAAT7-0xdqM485_big.png
				
		FastDFS集群环境搭建:
			前提准备：准备6台服务器[物理节点]，如：192.168.1.173-178
			架构规划：173是tracker1[对应的storage是175、176，group1]、174是tracker2[对应的storage是177、178，group2]
			步骤：
				1）、公共部分操作，安装gcc依赖环境、安装libfastcommon公共依赖包、安装FastDFS；
				2）、配置173、174tracker追踪服务器；
					 在/etc/fdfs/目录下，[cp tracker.conf.sample tracker.conf]修改配置文件：vim tracker.conf，修改内容:base_path=/home/FastDFS，在配置文件中可以设置store_lookup=0[设置负载均衡策略，可选值：0、1、2]
					 启动服务器：/etc/init.d/fdfs_trackered restart
			    3）、配置175、176、177、178storage存储服务器；
					 175、176为group1
					 177、178为group2				 
					 在/etc/fdfs/目录下，[cp storage.conf.sample storage.conf]修改配置文件：vim storage.conf，修改内容:
					 核心内容：group_name=group1 #175、176为group1，177、178为group2
							   tracker_server=192.168.1.173：22122
							   tracker_server=192.168.1.174：22122
					 启动服务器：/etc/init.d/fdfs_storaged restart
					 观察结论：追踪服务器集群采用的是选举算法，选择Leader来连接，符合主从规则；
					 监控集群指令：/usr/bin/fdfs_monitor /etc/fdfs/storage.conf
				4）、客户端测试上传数据
					 在/etc/fdfs/目录，执行：cp client.conf.sample client.conf，修改配置：vim client.conf，base_path=/home/yuqing/FastDFS 改为base_path=/home/FastDFS
							   tracker_server=192.168.1.173:22122 #配置tracker服务器的IP
							   tracker_server=192.168.1.174:22122
					 测试：	/usr/bin/fdfs_test /etc/fdfs/client.conf upload /home/1.png	 或 /usr/bin/fdfs_unload_file /etc/fdfs/client.conf /home/1.png
					 结果：文件存储按上面追踪服务器指定的策略[参数：store_lookup]来存储，且同组下的数据同步；
				
				5）、整合nginx模块[存储服务器上]，便于http方式访问
					 前提准备：在175、176、177、178四个物理节点上都安装nginx模块，同单机版；
					 配置文件：vim /etc/fdfs/mod_FastDFS.conf，主要修改内容：同单机版，此外有group_name=group1/2，group_count=2；
					 nginx配置同单机版；
					 访问测试：http://192.168.11.175:8888/group1/M00/00/00/wKhlBVVY2M-AM_9DAAAT7-0xdqM485_big.png
				6）、整合nginx缓存模块[追踪服务器上]，作反向代理负载均衡，利用缓存，代理存储服务器
					 在173、174上，解压安装ngx_cache_purge-2.3模块，安装nginx[安装相关Lib依赖和缓存模块./configure --add-module=../ngx_cache_purge-2.3]
					 安装完成后，修改nginx.conf文件信息，主要修改：缓存配置以及负载均衡的配置信息	
					 上传测试；http://192.168.11.173:8000/group1/M00/00/00/wKhlBVVY2M-AM_9DAAAT7-0xdqM485_big.png或http://192.168.11.174:8000/group1/M00/00/00/wKhlBVVY2M-AM_9DAAAT7-0xdqM485_big.png
				     
				7）、整合keepalived，提供一个VIP实现整体的访问流程；					
					 
----------------------------------------------大数据定制技术篇----------------------------------------------------------------------------------	
	一、大数据：
		概念：Big Data，指的是一段时间范围内内无法使用常规的工具[JavaEE]处理数据集合，需要新的处理模式来处理海量、高增长率、多样化的信息。主要解决的是海量的数据存储与海量的数据分析计算问题。
		数据的存储单位：
			bit、Byte、KB、MB、GB、TB、PB、EB、ZB、YB、BB、NB、DB 
			转化：除了1Byte=8bit，其他都是间隔1024
		特点：4V + 4高
			4V：Volume[海量]：人类的数据总量达到EB级别
				Velocity[实时/高速]：如每年天猫双十一
				Variety[多样]：结构化[数据库/文本]与非结构化[网络日志、音视频、地理位置]数据
				Value[价值密度]：低价值密度
			4高：
				高可靠[高性能]：多个数据副本
				高可扩[高扩展]：集群下任意扩展节点
				高效率[高并发]：并行工作
				高容错：
				
		运用场景：
			物流仓储[如京东]、零售[分析用户行为]、旅游、商品的广告推荐、金融、保险、房产、人工智能AI...
		发展前景：
			政策支持、人才缺口、工资高
		大数据部门的业务流程：
			产品经理[人员]提要求[统计指标]	-------------->数据部门搭建数据平台、分析数据 ----------->数据可视化[JavaEE]
		大数据部门的组织结构[适用于大中型企业]：
			平台组：[技术] 															--平台搭建[hadoop、Flume[日志收集]、Spark[数据挖掘、分析]、Kafka[消息队列]、Hbase[数据存储]]、集群监控、集群调优
			数据仓库组：[业务]													    --ETL工程师[抽取、转化、加载]：数据清洗；Hive[数据查询]工程师：数据分析、数据仓库建模
			数据挖掘组：														    --算法、推荐系统、用户头像工程师
			报表开发组：JavaEE
		大数据技术生态圈体系
			数据来源层：结构化数据[数据库]、半结构化数据[文件日志]、非结构化数据[音视频]
			数据传输层[DTL]：Sqoop数据传递、Flume日志收集
				Sqoop是一款开源的工具，主要用于在Hadoop、Hive(数据查询)与传统的数据库(MySql)间进行数据的传递，可以将一个关系型数据库中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中
				Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力
			数据存储层：HDFS文件存储、HBase非关系型数据库、Kafka消息队列
				Kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性：
				（1）通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。
				（2）高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息。
				（3）支持通过Kafka服务器和消费集群来分区消息。
				（4）支持Hadoop并行数据加载。
				HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库
			资源管理层：Yarn资源管理
			数据计算层：离线计算、内存计算、实时计算
				离线计算：MapReduce[Hive数据查询、Mahout数据挖掘]
					Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。 
				        其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析
					Apache Mahout是个可扩展的机器学习和数据挖掘库
				内存计算：Spark[Spark Milib数据挖掘、Spark R数据分析、Spark SQL数据查询。Spark Streaming实时计算]
					Spark是当前最流行的开源大数据内存计算框架，可以基于Hadoop上存储的大数据进行计算。
					R是用于统计分析、绘图的语言和操作环境。R是属于GNU系统的一个自由、免费、源代码开放的软件，它是一个用于统计计算和统计制图的优秀工具。
				实时计算：Stream
					Storm用于“连续计算”，对数据流做连续查询，在计算时就将结果以流的形式输出给用户
			任务调度层：Oozie任务调度、AzKaban任务调度			
				Oozie是一个管理Hdoop作业（job）的工作流程调度管理系统
			业务模型层[JavaEE]：业务模型、数据可视化、业务运用
			数据平台的调度与配置：Zookeeper
				Zookeeper是Google的Chubby一个开源的实现。它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、 分布式同步、组服务等。
				ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户
			
	二、Hadoop
			含义：Hadoop是一个由Apache基金会所开发的分布式系统基础架构，主要解决的是海量数据的存储和海量数据的分析计算问题。
				  广义上来说，HADOOP通常是指一个更广泛的概念——HADOOP生态圈。
			发展历史：Lucene ->Nutch -> Hadoop
				1）Lucene--Doug Cutting开创的开源软件，用java书写代码，实现与Google类似的全文搜索功能，它提供了全文检索引擎的架构，包括完整的查询引擎和索引引擎 
				2）2001年年底成为apache基金会的一个子项目			
				3）对于大数量的场景，Lucene面对与Google同样的困难，存储数据困难，检索数据慢。			  
				4）学习和模仿Google解决这些问题的办法 ：微型版Nutch				  
				5）可以说Google是hadoop的思想之源
					GFS --->HDFS
					Map-Reduce --->MR
					BigTable --->Hbase				  
				6）2003-2004年，Google公开了部分GFS和MapReduce思想的细节，以此为基础Doug Cutting等人用了2年业余时间实现了HDFS和MapReduce机制，使Nutch性能飙升 				  
				7）2005 年Hadoop作为Lucene的子项目Nutch的一部分正式引入Apache基金会。2006 年 3 月份，MapReduce和Nutch Distributed File System (NDFS) 分别被纳入称为 Hadoop 的项目中 				  
				9）Hadoop就此诞生并迅速发展，标志这云计算时代来临
			版本：
				Apache、Cloudera、Hortonworks
				Apache：最原始（最基础）的版本，对于入门学习最好
				Cloudera：在大型互联网企业中用的较多，收费
				Hortonworks：文档较好
			组成：
				Hadoop1.x与Hadoop2.x区别：
					Hadoop1.x：MapReduce（计算+资源调度）、HDFS（数据存储）、Common（辅助工具）
					Hadoop2.x：MapReduce（计/运算）Yarn（资源调度）、HDFS（数据存储）、Common（辅助工具）
				HDFS：是一个高可靠、高吞吐量的分布式文件系统。构成：
					NameNode[目录]：存储文件的元数据，如：文件名、文件目录名、文件属性...
					DataNode[资源]：数据
					Secondary NameNode：监控HDFS后台服务
				Yarn：
					构成：
						1）ResourceManager(rm)：处理客户端请求、启动/监控ApplicationMaster、监控NodeManager、资源分配与调度；
						2）NodeManager(nm)：单个节点上的资源管理、处理来自ResourceManager的命令、处理来自ApplicationMaster的命令；
						3）ApplicationMaster：数据切分、为应用程序申请资源(CPU、硬盘...)，并分配给内部任务、任务监控与容错;
						4）Container：对任务运行环境的抽象，封装了CPU、内存等多维资源以及环境变量、启动命令等任务运行相关的信息
				MapReduce：
					构成：MapReduce将计算过程分为两个阶段：Map和Reduce
						  1）Map阶段并行处理输入数据
					      2）Reduce阶段对Map结果进行汇总
			环境搭建：
				环境准备：
					安装JDK、安装Hadoop[可以配置环境变量]
			目录结构：
				（1）bin目录：存放对Hadoop相关服务（HDFS，YARN）进行操作的脚本
				（2）etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件
				（3）lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能）
				（4）sbin目录：存放启动或停止Hadoop相关服务的脚本
				（5）share目录：存放Hadoop的依赖jar包、文档、和官方案例
			运行模式：
				本地模式、伪分布式模式以及完全分布式模式
				本地运行模式：不需要启用单独进程，直接可以运行，测试和开发时使用。
					官方示例：
					安装路径：opt/module/hadoop-2.7.2/
						Grep案例：
							1）在安装路径下创建一个input文件夹，mkdir input
							2）将Hadoop的xml配置文件复制到input，cp ./etc/hadoop/*.xml input
							3）执行share目录下的MapReduce程序，./bin/hadoop jar
															   share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep ./input/ output 'dfs[a-z.]+'
							4）查看输出结果，cat ./output/*	
						WordCount案例：
							1）在安装路径下创建一个wcinput文件夹，mkdir wcinput
							2）在wcinput文件夹下创建文件wc.iput并输入内容保存， touch wc.input
								内容如：zhangsan lisi wangwu lisi zhaoliu 
							3）执行share目录下的MapReduce程序，hadoop jar
																share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount ./wcinput/ wcoutput
							4）查看输出结果，cat wcoutput/part-r-00000，即可查看统计内容出现的次数
				
				伪分布式运行模式：等同于完全分布式，只有一个节点。
					启动HDFS并运行MapReduce程序：
						环境准备：
							准备1台客户机[hadoop101]、安装jdk并配置环境变量、安装hadoop并配置环境变量、配置集群、
							启动、测试集群增、删、查、执行wordcount案例
						步骤：
							1）配置集群
								配置：hadoop-env.sh <!-- 修改JAVA_HOME 路径 -->
										Linux系统中获取JDK的安装路径：echo $JAVA_HOME   ->/opt/module/jdk1.8.0_144									
										修改JAVA_HOME 路径：export JAVA_HOME=/opt/module/jdk1.8.0_144
								      core-site.xml <!--Hadoop公用配置-->
										<!-- 指定HDFS中NameNode的地址 -->
										<property>
											<name>fs.defaultFS</name>
											<value>hdfs://hadoop101:9000</value>
										</property>
										<!-- 指定Hadoop运行时产生文件的存储目录 -->
										<property>
											<name>hadoop.tmp.dir</name>
											<value>/opt/module/hadoop-2.7.2/data/tmp</value>
										</property>
									  hdfs-site.xml hdfs自定义配置
										<!-- 指定HDFS副本的数量 -->
										<property>
											<name>dfs.replication</name>
											<value>1</value>
										</property>
							2）启动集群
									格式化NameNode：bin/hdfs namenode -format 注意：初次启动时格式化，以后就不要总格式化							 
									启动NameNode：sbin/hadoop-daemon.sh start namenode									 
									启动DataNode：sbin/hadoop-daemon.sh start datanode
						
							3）查看集群
									查看是否启动成功：jps，结果如下：[注意：jps是JDK中的命令，不是Linux命令。]
									13586 NameNode
									13668 DataNode
									13786 Jps
									web端查看HDFS文件系统：http://hadoop101:50070/dfshealth.html#tab-overview
								    查看产生的Log日志：
										当前目录路径下会生成logs文件夹：/opt/module/hadoop-2.7.2/logs
									思考：为什么不能一直格式化NameNode，格式化NameNode，要注意什么？？？
										在运行的存储临时目录下：data/tmp/dfs/name/current/或data/tmp/dfs/data/current/中产生VERSION文件存储了clusterID是相同的。
										结论：格式化NameNode，会产生新的clusterID,导致NameNode和DataNode的clusterID不一致，集群找不到已往数据。
											  所以格式NameNode时，一定要先删除data数据和log日志，然后再格式化NameNode。
							4）操作集群[执行wordcount案例]
									在HDFS文件系统上创建一个input文件夹：bin/hdfs dfs -mkdir -p /user/atguigu/input
								    将测试文件内容上传到文件系统上：bin/hdfs dfs -put wcinput/wc.input /user/atguigu/input/
									查看上传的文件是否正确：bin/hdfs dfs -ls  /user/atguigu/input/ 或 bin/hdfs dfs -cat /user/atguigu/input/wc.input
									运行MapReduce程序：bin/hadoop jar
													   share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/input/ /user/atguigu/output
									查看输出结果：bin/hdfs dfs -cat /user/atguigu/output/*
									将测试文件内容下载到本地：bin/hdfs dfs -get /user/atguigu/output/part-r-00000 ./wcoutput/
									删除输出结果：hdfs dfs -rm -r /user/atguigu/output	
									
					启动YARN并运行MapReduce程序:
						环境准备：
							准备1台客户机、安装jdk并配置环境变量、安装hadoop并配置环境变量、配置集群在YARN上运行MR、
							启动、测试集群增、删、查、在YARN上执行WordCount案例
						步骤：
							1）配置集群
								配置：yarn-env.sh 修改JAVA_HOME 路径
										Linux系统中获取JDK的安装路径：echo $JAVA_HOME   ->/opt/module/jdk1.8.0_144									
										修改JAVA_HOME 路径：export JAVA_HOME=/opt/module/jdk1.8.0_144
									  yarn-site.xml <!-- yarn自定义配置 -->
										<!-- Reducer获取数据的方式 -->
										<property>
												<name>yarn.nodemanager.aux-services</name>
												<value>mapreduce_shuffle</value>
										</property>
										<!-- 指定YARN的ResourceManager的地址 -->
										<property>
											<name>yarn.resourcemanager.hostname</name>
											<value>hadoop101</value>
										</property>
									  mapred-env.sh 修改JAVA_HOME 路径
									    Linux系统中获取JDK的安装路径：echo $JAVA_HOME   ->/opt/module/jdk1.8.0_144									
										修改JAVA_HOME 路径：export JAVA_HOME=/opt/module/jdk1.8.0_144
									  mapred-site.xml <!-- mapreduce自定义配置 -->
										重命名：mv mapred-site.xml.template mapred-site.xml 
										<!-- 指定MR运行在YARN上 -->
										<property>
												<name>mapreduce.framework.name</name>
												<value>yarn</value>
										</property>
							2）启动集群
									启动前必须保证NameNode和DataNode已经启动[HDFS服务启动]
								    启动ResourceManager：sbin/yarn-daemon.sh start resourcemanager
									启动NodeManager：sbin/yarn-daemon.sh start nodemanager
							3）集群操作
									YARN的浏览器页面查看：http://hadoop101:8088/cluster
									删除文件系统上的output文件：bin/hdfs dfs -rm -R /user/atguigu/output
									执行MapReduce程序：bin/hadoop jar
													   share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/input  /user/atguigu/output
									查看运行结果：bin/hdfs dfs -cat /user/atguigu/output/*
					
					配置历史服务器MR：为了查看程序的历史运行情况，需要配置一下历史服务器
						配置：mapred-site.xml <!-- mapreduce自定义配置-->
							<!-- 历史服务器端地址 -->
							<property>
								<name>mapreduce.jobhistory.address</name>
								<value>hadoop101:10020</value>
							</property>
							<!-- 历史服务器web端地址 -->
							<property>
								<name>mapreduce.jobhistory.webapp.address</name>
								<value>hadoop101:19888</value>
							</property>
						启动历史服务器：sbin/mr-jobhistory-daemon.sh start historyserver
						查看历史服务器是否启动：jps
						查看JobHistory：http://hadoop101:19888/jobhistory
					
					配置日志的聚集[YARN中配置]
						日志聚集概念：应用运行完成以后，将程序运行日志信息上传到HDFS系统上，可以方便的查看到程序运行详情，方便开发调试。
						注意：开启日志聚集功能，需要重新启动NodeManager 、ResourceManager和HistoryManager。
						步骤：
							配置：yarn-site.xml 
								<!-- 日志聚集功能使能 -->
								<property>
									<name>yarn.log-aggregation-enable</name>
									<value>true</value>
								</property>
								<!-- 日志保留时间设置7天 -->
								<property>
									<name>yarn.log-aggregation.retain-seconds</name>
									<value>604800</value>
								</property>
							关闭NodeManager 、ResourceManager和HistoryManager：
								sbin/yarn-daemon.sh stop resourcemanager
								sbin/yarn-daemon.sh stop nodemanager
								sbin/mr-jobhistory-daemon.sh stop historyserver
							启动NodeManager 、ResourceManager和HistoryManager：
								sbin/yarn-daemon.sh start resourcemanager
								sbin/yarn-daemon.sh start nodemanager
								sbin/mr-jobhistory-daemon.sh start historyserver
							删除HDFS上已经存在的输出文件：bin/hdfs dfs -rm -R /user/atguigu/output
							执行WordCount程序：hadoop jar
											   share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/input /user/atguigu/output	
							查看日志：http://hadoop101:19888/jobhistory
				
				配置文件说明：Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值
					默认配置文件：存放在hadoop相应的jar包中
					自定义配置文件：core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。

				完全分布式运行模式[重点]：多个节点一起运行。	
					环境准备：
						准备3台客户机（关闭防火墙、静态ip、主机名称，分别为：102、103、104）、安装jdk并配置环境变量、安装hadoop并配置环境变量、
						配置集群、单点启动、配置ssh、群起并测试集群
							注：[学习阶段]可以从已安装好的Linux客户机copy三份来使用，主要修改的配置有：
							vim /etc/udev/rules.d/70-persistent-net.rules                   -获取address地址
							vim /etc/sysconfig/network-scripts/ifcfg-eth0					-修改address地址和IP地址
							vim /etc/sysconfig/network										-添加主机名称
							vim /etc/hosts													-添加映射
					集群分发脚本xsync：
						前提准备：
							scp（secure copy）安全拷贝：
								含义：scp可以实现服务器与服务器之间的数据拷贝[from server1 to server2]。
								基本语法:
								scp    -r          $pdir/$fname              $user@hadoop$host:$pdir/$fname
								命令   递归       要拷贝的文件路径/名称    目的用户@主机:目的路径/名称
							步骤：[hadoop101是实现准备好的客户机]								
								在hadoop101上，将hadoop101中/opt/module目录下的软件拷贝到hadoop102上
									scp -r /opt/module  root@hadoop102:/opt/module
								在hadoop103上，将hadoop101服务器上的/opt/module目录下的软件拷贝到hadoop103上
									sudo scp -r atguigu@hadoop101:/opt/module root@hadoop103:/opt/module
								在hadoop103上操作将hadoop101中/opt/module目录下的软件拷贝到hadoop104上
									scp -r atguigu@hadoop101:/opt/module root@hadoop104:/opt/module
								注意：拷贝过来的/opt/module目录，别忘了在hadoop102、hadoop103、hadoop104上修改所有文件的所有者和所有者组。
									  使用：sudo chown atguigu:atguigu -R /opt/module
								将hadoop101中/etc/profile文件拷贝到hadoop102、hadoop103、hadoop104的/etc/profile上
									sudo scp /etc/profile root@hadoop102:/etc/profile
									sudo scp /etc/profile root@hadoop103:/etc/profile
									sudo scp /etc/profile root@hadoop104:/etc/profile
								在hadoop102、hadoop103、hadoop104 的客户机上分别执行：source /etc/profile 
							
							rsync 远程同步工具
								含义：主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。
								rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。
								基本语法：
									rsync    -rvl       $pdir/$fname              $user@hadoop$host:$pdir/$fname
									命令   选项参数   要拷贝的文件路径/名称    目的用户@主机:目的路径/名称
									参数说明：-r：递归；-v：显示复制过程；-l：拷贝符号链接
									如：rsync -rvl /opt/software/ root@hadoop102:/opt/software
						集群分发脚本：
							1）在当前用户的家目录下新建脚本，如：/home/atguigu/bin，注意：：如果将xsync放到/home/atguigu/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下或添加到系统的PATH变量里去。
								touch xsync
							2）编辑内容，格式如下：
								#!/bin/bash
								#1 获取输入参数个数，如果没有参数，直接退出
								pcount=$#
								if((pcount==0)); then
								echo no args;
								exit;
								fi

								#2 获取文件名称
								p1=$1
								fname=`basename $p1`
								echo fname=$fname

								#3 获取上级目录到绝对路径
								pdir=`cd -P $(dirname $p1); pwd`
								echo pdir=$pdir

								#4 获取当前用户名称
								user=`whoami`

								#5 循环
								for((host=103; host<105; host++)); do
										echo ------------------- hadoop$host --------------
										rsync -rvl $pdir/$fname $user@hadoop$host:$pdir
								done
							3）修改脚本 xsync 具有执行权限：chmod 777 xsync
							4）调用脚本形式：xsync 文件名称
					集群配置：
						集群部署规划：HDFS YARN
							hadoop102 ：NameNode DataNode NodeManager		
							hadoop103 ：DataNode ResourceManager NodeManager
							hadoop104 :	SecondaryNameNode DataNode NodeManager
							重点解释：hadoop102 配置 NameNode
									  hadoop103 配置 ResourceManager
									  hadoop104 配置 SecondaryNameNode
								这三点分别配置在不同的客户机上
						配置集群[先配置好一台服务器，如：hadoop102，再集群分发同步过去]：
							1）配置core-site.xml <!-- 公共配置 -->
								<!-- 指定HDFS中NameNode的地址，namenode常用的端口：9000、50070、8088、50090、19888 -->
								<property>
										<name>fs.defaultFS</name>
									  <value>hdfs://hadoop102:9000</value>
								</property>
								<!-- 指定Hadoop运行时产生文件的存储目录 -->
								<property>
										<name>hadoop.tmp.dir</name>
										<value>/opt/module/hadoop-2.7.2/data/tmp</value>
								</property>
							2）配置HDFS配置文件
							   配置hadoop-env.sh  export JAVA_HOME=/opt/module/jdk1.8.0_144
							   配置hdfs-site.xml <!-- hdfs的配置 -->
							   <property>
										<name>dfs.replication</name>
										<value>3</value>
								</property>
								<!-- 指定Hadoop辅助名称节点主机配置 -->
								<property>
									  <name>dfs.namenode.secondary.http-address</name>
									  <value>hadoop104:50090</value>
								</property>
							3）配置YARN配置文件
							   配置yarn-env.sh export JAVA_HOME=/opt/module/jdk1.8.0_144
							   配置yarn-site.xml <!-- yarn的配置 -->
							   !-- Reducer获取数据的方式 -->
								<property>
										<name>yarn.nodemanager.aux-services</name>
										<value>mapreduce_shuffle</value>
								</property>
								<!-- 指定YARN的ResourceManager的地址 -->
								<property>
										<name>yarn.resourcemanager.hostname</name>
										<value>hadoop103</value>
								</property>
							4）MapReduce配置文件
							   配置mapred-env.sh export JAVA_HOME=/opt/module/jdk1.8.0_144
							   配置mapred-site.xml <!-- mr的配置 -->
							   重命名：cp mapred-site.xml.template mapred-site.xml
							   <!-- 指定MR运行在Yarn上 -->
								<property>
										<name>mapreduce.framework.name</name>
										<value>yarn</value>
								</property>
						集群分发：
							在hadoop102上执行：xsync /opt/module/hadoop-2.7.2/
						查看文件分发情况：
							如在hadoop103上面执行：cat /opt/module/hadoop-2.7.2/etc/hadoop/core-site.xml 看看文件是否与hadoop102同步
					
					集群单点启动
						1）如果集群是第一次启动，需要格式化NameNode
							[atguigu@hadoop102 hadoop-2.7.2]$ hadoop namenode -format 或 bin/hdfs namenode -format 
						2）在hadoop102上启动NameNode
							[atguigu@hadoop102 hadoop-2.7.2]$ hadoop-daemon.sh start namenode
							[atguigu@hadoop102 hadoop-2.7.2]$ jps
							3461 NameNode
						3）在hadoop102、hadoop103以及hadoop104上分别启动DataNode
							[atguigu@hadoop102 hadoop-2.7.2]$ hadoop-daemon.sh start datanode
							[atguigu@hadoop102 hadoop-2.7.2]$ jps
							[atguigu@hadoop103 hadoop-2.7.2]$ hadoop-daemon.sh start datanode
							[atguigu@hadoop103 hadoop-2.7.2]$ jps
							[atguigu@hadoop104 hadoop-2.7.2]$ hadoop-daemon.sh start datanode
							[atguigu@hadoop104 hadoop-2.7.2]$ jps
						问题：每次都一个一个节点启动，效率低下
					
					SSH无密登录配置
						原理：
										ssh访问B（数据用私钥A加密）			（B接收到数据用公钥A解密）
						A服务器		------------------------------------------>B服务器
				（ssh-key-gen/生成密钥对[公/私钥A]）						  （公钥A存储在Authorized_key）
									<------------------------------------------
				（用私钥A解密返回的数据）		采用公钥A加密数据返回A
				
						语法：ssh 另一台电脑的ip地址/域名
						
						生成公钥/私钥：在家目录的.ssh文件夹下执行：ssh-keygen -t rsa 回车三次，就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）
						将公钥拷贝到要免密登录的目标机器上，如：
							ssh-copy-id hadoop102
							ssh-copy-id hadoop103
							ssh-copy-id hadoop104
						注意：
							还需要在hadoop102上采用root账号，配置一下无密登录到hadoop102、hadoop103、hadoop104；
							还需要在hadoop103上采用atguigu账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。
						
						.ssh文件夹下文件解释：
							known_hosts	记录ssh访问过计算机的公钥(public key)
							id_rsa	生成的私钥
							id_rsa.pub	生成的公钥
							authorized_keys	存放授权过得无密登录服务器公钥
					
					群起集群
						配置slaves
						路径：/opt/module/hadoop-2.7.2/etc/hadoop/slaves下添加内容：
							hadoop102
							hadoop103
							hadoop104
						注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。
						同步所有节点配置文件，[atguigu@hadoop102 hadoop]$ xsync slaves
					启动集群
						1）如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）
							[atguigu@hadoop102 hadoop-2.7.2]$ bin/hdfs namenode -format
						2）启动HDFS
							[atguigu@hadoop102 hadoop-2.7.2]$ sbin/start-dfs.sh
							[atguigu@hadoop102 hadoop-2.7.2]$ jps
							4166 NameNode
							4482 Jps
							4263 DataNode
							[atguigu@hadoop103 hadoop-2.7.2]$ jps
							3218 DataNode
							3288 Jps
							[atguigu@hadoop104 hadoop-2.7.2]$ jps
							3221 DataNode
							3283 SecondaryNameNode
							3364 Jps
						3）启动YARN
							[atguigu@hadoop103 hadoop-2.7.2]$ sbin/start-yarn.sh
							注意：NameNode和ResourceManger如果不是同一台机器，不能在NameNode上启动 YARN，应该在ResouceManager所在的机器上启动YARN。
						4）Web端查看SecondaryNameNode，浏览器中输入：http://hadoop104:50090/status.html
					
					集群基本测试
						1）上传文件到集群
							上传小文件
							[atguigu@hadoop102 hadoop-2.7.2]$ hdfs dfs -mkdir -p /user/atguigu/input
							[atguigu@hadoop102 hadoop-2.7.2]$ hdfs dfs -put wcinput/wc.input /user/atguigu/input
							上传大文件
							[atguigu@hadoop102 hadoop-2.7.2]$ bin/hadoop fs -put /opt/software/hadoop-2.7.2.tar.gz  /user/atguigu/input
						2）上传文件后查看文件存放在什么位置
						   查看HDFS文件存储路径
						   [atguigu@hadoop102 subdir0]$ pwd
						   /opt/module/hadoop-2.7.2/data/tmp/dfs/data/current/BP-938951106-192.168.10.107-1495462844069/current/finalized/subdir0/subdir0
					
					集群启动/停止方式总结
						1.	各个服务组件逐一启动/停止
							（1）分别启动/停止HDFS组件
								hadoop-daemon.sh  start / stop  namenode / datanode / secondarynamenode
							（2）启动/停止YARN
								yarn-daemon.sh  start / stop  resourcemanager / nodemanager
						2.	各个模块分开启动/停止（配置ssh是前提）常用
							（1）整体启动/停止HDFS
								start-dfs.sh   /  stop-dfs.sh
							（2）整体启动/停止YARN
								start-yarn.sh  /  stop-yarn.sh
					集群时间同步
						
						   
	三、Zookeeper
		简介：
		
	四、Kafka
		简介：
		
----------------------------------------------Java高级运用技术篇----------------------------------------------------------------------------------		
	java特性：
		封装性：为了数据的安全，避免用户直接接触到数据，增加程序的安全性。封装隐藏类的内部属性，并且对用户隐藏了数据的访问方式，这样可以保护类的内部状态。封装可以防止类中的方法访问属性，防止对象间的交互，提高Java程序的安全性。
		继承性：继承可以减少代码量，方法重写。
		多态性：三个必要条件是存在继承、重写、父类对象引用子类对象，如：Animal animal = new Cat()。
	
	一、多线程JDK1.5以前版本，参考：https://www.runoob.com/java/java-multithreading.html
		基本概念：
			进程：一个进程包括由操作系统分配的内存空间，包含一个或多个线程。线程不能独立的存在，它必须是进程的一部分。一个进程一直运行，直到所有的非守护线程都结束运行后才能结束，多线程-多任务并发执行；
		作用：多线程能满足高效率的程序来达到充分利用 CPU 的目的
		生命周期：线程是一个动态执行的过程，它也有一个从产生到死亡的过程
		
- ->使用new关键字和Thread类或其子类建立一个线程对象后	                                                                                  ---->执行run()方法					-->运行状态的线程最为复杂，它可以变为阻塞状态、就绪状态和死亡状态			
		---------------------------------------------->	新建状态 ----------------------------------------------------------->就绪状态 -------------------------------->运行状态 -------------------------------------------------------------------> 死亡状态
																 -->执行start()方法，就绪队列中，要等待JVM里线程调度器的调度		-->就绪状态的线程成功获取 CPU 资源			-->调用stop()或destory()函数强制终止
		
		名词解释：
			阻塞状态:如果一个线程执行了sleep（睡眠）、suspend（挂起）等方法，失去所占用CPU资源之后，该线程就从运行状态进入阻塞状态。可以分为三种：
				等待阻塞：运行状态中的线程执行 wait() 方法，使线程进入到等待阻塞状态
				同步阻塞：线程在获取synchronized同步锁失败(因为同步锁被其他线程占用)
				其他阻塞：通过调用线程的 sleep() 或 join() 发出了 I/O 请求时，线程就会进入到阻塞状态，当sleep() 状态超时，join() 等待线程终止或超时，或者 I/O 处理完毕，线程重新转入就绪状态
			死亡状态:一个运行状态的线程完成任务或者其他终止条件发生时，该线程就切换到终止状态
		
		优先级：线程的优先级是一个整数，其取值范围是 1 （Thread.MIN_PRIORITY ） - 10 （Thread.MAX_PRIORITY ）
		创建线程的方法[4种]：
			通过继承 Thread 类本身，重写Run()方法，新建实例调用它的 start() 方法
			实例：
			class ThreadDemo1 extends Thread {
			   //关联关系，关联其他对象
			   public void run() {
					//业务逻辑
			   }			  
			}
			//使用
			new ThreadDemo1( "Thread-1").start();
			通过实现 Runnable 接口，重写Run()方法，新建实例调用它的 start() 方法
			实例：
			class ThreadDemo2 implements Runnable  {
			   //关联关系，关联其他对象
			   public void run() {
					//业务逻辑
			   }			  
			}
			//使用
			new ThreadDemo2( "Thread-2").start();
			通过 Callable 和 Future 创建线程，实现Callable接口，重写 call() 方法，创建 Callable 实现类的实例，使用 FutureTask 类来包装 Callable 对象，新建Thread实例（传入FutureTask对象）调用它的 start() 方法，注意与实现Runable的区别：多了一个接收的结果。
			案列说明：
			如：public class TestCallable {
					public static void main(String[] args) {
						ThreadDemo td = new ThreadDemo();		
						//1.执行 Callable 方式，需要 FutureTask 实现类的支持，用于接收运算结果。
						FutureTask<Integer> result = new FutureTask<>(td);		
						new Thread(result).start();		
						//2.接收线程运算后的结果
						try {
							Integer sum = result.get();  //FutureTask 可用于闭锁
							System.out.println(sum);
							System.out.println("------------------------------------");
						} catch (InterruptedException | ExecutionException e) {
							e.printStackTrace();
						}
					}
				}
				class ThreadDemo implements Callable<Integer>{
					@Override
					public Integer call() throws Exception {
						int sum = 0;		
						for (int i = 0; i <= 100000; i++) {
							sum += i;
						}		
						return sum;
					}	
				}	
			通过线程池来创建
			案列说明：
			public class TestThreadPool {				
					public static void main(String[] args) throws Exception {
						//1. 创建线程池，固定5个线程
						ExecutorService pool = Executors.newFixedThreadPool(5);						
						List<Future<Integer>> list = new ArrayList<>();						
						for (int i = 0; i < 10; i++) {
							Future<Integer> future = pool.submit(new Callable<Integer>(){
								@Override
								public Integer call() throws Exception {
									int sum = 0;									
									for (int i = 0; i <= 100; i++) {
										sum += i;
									}									
									return sum;
								}								
							});
							list.add(future);
						}
						//关闭线程池
						pool.shutdown();						
						for (Future<Integer> future : list) {
							System.out.println(future.get());//查看结果
						}																		
						/*ThreadPoolDemo tpd = new ThreadPoolDemo();						
						//2. 为线程池中的线程分配任务
						for (int i = 0; i < 10; i++) {
							pool.submit(tpd);
						}						
						//3. 关闭线程池
						pool.shutdown();*/
					}					
				//	new Thread(tpd).start();
				//	new Thread(tpd).start();
				}
				class ThreadPoolDemo implements Runnable{
					private int i = 0;					
					@Override
					public void run() {
						while(i <= 100){
							System.out.println(Thread.currentThread().getName() + " : " + i++);
						}
					}					
				}	
				public class TestScheduledThreadPool {
					public static void main(String[] args) throws Exception {
						ScheduledExecutorService pool = Executors.newScheduledThreadPool(5);						
						for (int i = 0; i < 5; i++) {
							Future<Integer> result = pool.schedule(new Callable<Integer>(){
								@Override
								public Integer call() throws Exception {
									int num = new Random().nextInt(100);//生成随机数
									System.out.println(Thread.currentThread().getName() + " : " + num);
									return num;
								}								
							}, 1, TimeUnit.SECONDS);							
							System.out.println(result.get());
						}
						//关闭线程池
						pool.shutdown();
					}					
				}			
		关键类：Thread
		接口：Runable
		主要方法：start()，run()，sleep()，destory()，setName()，setPriority()，setDaemon(true)，yield()（暂停）...
		关键字：synchronized，同步代码块，同步是一种高开销的操作，因此应该尽量减少同步的内容    
		
	二、JUC[java.utils.current]多线程高级JDK1.5以后版本
		内存可见性：
			含义：当多个线程共享内存数据时，彼此不可见。
			解决办法：
				1、同步锁，使用synchronized关键字。但是缺点是效率低，加锁每次线程进来需要先判断锁的状态。
				2、使用volatile关键字。即当多个线程操作共享内存数据时，保证内存中的数据可见，相对于synchronized较为轻量级的同步策略。
				   但是它不能保证"互斥性"以及变量的"原子性"。
		
			JVM线程原理：
													1线程一[main线程]、JVM分配一些缓存；读的是FLAG=false[变量不同步]
				假设主存[堆]一变量FLAG=false	--------------->
													1线程二、JVM分配一些缓存；写主存中的变量FLAG=true[在缓存中进行]
											<-------------------	
													2改主存变量值
				解决办法：
					加锁：synchronized锁，即每次线程进来需要先判断锁的状态是否符合条件，当符合条件才能拿到FLAG=true的值
					使用volatile关键字，原理大意如下：
													线程一[main线程]；读的是FLAG=true
				假设主存[堆]一变量FLAG=false	--------------->
													线程二；写主存中的变量FLAG=true[在主存中进行，实时刷新主存变量值]
													
				如：public class TestVolatile {	
						public static void main(String[] args) {
							ThreadDemo td = new ThreadDemo();
							new Thread(td).start();							
							while(true){//JVM底层支持优化
								if(td.isFlag()){
									System.out.println("------------------");
									break;
								}
							}							
						}
					}
					class ThreadDemo implements Runnable {
						private volatile boolean flag = false;
						@Override
						public void run() {							
							try {
								Thread.sleep(200);
							} catch (InterruptedException e) {
							}
							flag = true;							
							System.out.println("flag=" + isFlag());
						}
						public boolean isFlag() {
							return flag;
						}
						public void setFlag(boolean flag) {
							this.flag = flag;
						}
					}
		原子性问题：
			i++的操作在JVM底层实际上分三步“读-改-写”操作；这样多线程无法保证原子性问题；
			原子变量：JDK1.5后，java.utils.concurrent.atomic包下提供了常用的原子变量，如：AtomicInteger、AtomicBoolean等
					  特点：一、保证了内存可见性[volatile];二、CAS（Compare and Swap）算法保证了原子性；
					  CAS算法：硬件对并发操作共享数据的支持，包含三个操作数：
							   内存值V
							   预估值A
							   更新至B
							   当且仅当V==A，V=B，否则不进行任何操作；
			如：public class TestAtomicDemo {
					public static void main(String[] args) {
						AtomicDemo ad = new AtomicDemo();						
						for (int i = 0; i < 10; i++) {
							new Thread(ad).start();
						}
					}					
				}
				class AtomicDemo implements Runnable{					
				//	private volatile int serialNumber = 0;					
					private AtomicInteger serialNumber = new AtomicInteger(0);
					@Override
					public void run() {						
						try {
							Thread.sleep(200);
						} catch (InterruptedException e) {
						}						
						System.out.println(getSerialNumber());
					}					
					public int getSerialNumber(){
						return serialNumber.getAndIncrement();
					}										
				}
		ConcurrentHashMap：
			JDK1.5版本以前，主要容器类HashMap[是非synchronized，是线程不安全的]与HashTable[是synchronized，是线程安全的，表锁，多个线程可以共享一个Hashtable，效率低，串行]
			JDK1.5版本以后，提供了多种容器类，如：ConcurrentHashMap采用的是“锁分段”机制[concurrentLevel->Segment->链表，并行，是HashTable的替代]			
		CopyOnWriteArrayList/CopyOnWriteArraySet写入并复制，注意：添加操作多时，效率低，因为每次添加后都需要复制Copy，但适用于并发迭代效率高；
			如：public class TestCopyOnWriteArrayList {
					public static void main(String[] args) {
						HelloThread ht = new HelloThread();						
						for (int i = 0; i < 10; i++) {
							new Thread(ht).start();
						}
					}					
				}
				class HelloThread implements Runnable{					
				//	private static List<String> list = Collections.synchronizedList(new ArrayList<String>());					
					private static CopyOnWriteArrayList<String> list = new CopyOnWriteArrayList<>();					
					static{
						list.add("AA");
						list.add("BB");
						list.add("CC");
					}
					@Override
					public void run() {						
						Iterator<String> it = list.iterator();						
						while(it.hasNext()){
							System.out.println(it.next());							
							list.add("AA");
						}						
					}					
				}
		CountDownLatch[倒时计数思想]：闭锁-在完成某些运算时，只有当其他所有线程的运算全部完成时，当前运算才继续执行；主要方法有：countDown()、wait()
			如：public class TestCountDownLatch {
					public static void main(String[] args) {
						final CountDownLatch latch = new CountDownLatch(50);
						LatchDemo ld = new LatchDemo(latch);
						long start = System.currentTimeMillis();
						for (int i = 0; i < 50; i++) {
							new Thread(ld).start();
						}
						try {
							latch.await();
						} catch (InterruptedException e) {
						}
						long end = System.currentTimeMillis();
						System.out.println("耗费时间为：" + (end - start));
					}
				}
				class LatchDemo implements Runnable {
					//利用UML类图的聚合关系
					private CountDownLatch latch;
					public LatchDemo(CountDownLatch latch) {
						this.latch = latch;
					}
					@Override
					public void run() {
						try {
							for (int i = 0; i < 50000; i++) {
								if (i % 2 == 0) {
									System.out.println(i);
								}
							}
						} finally {
							latch.countDown();
						}
					}
				}
		Callable与FutureTask结合创建线程的方式：
			结论：FutureTask也可用于闭锁
			如：public class TestCallable {
					public static void main(String[] args) {
						ThreadDemo td = new ThreadDemo();		
						//1.执行 Callable 方式，需要 FutureTask 实现类的支持，用于接收运算结果。
						FutureTask<Integer> result = new FutureTask<>(td);		
						new Thread(result).start();		
						//2.接收线程运算后的结果
						try {
							Integer sum = result.get();  //FutureTask 可用于闭锁
							System.out.println(sum);
							System.out.println("------------------------------------");
						} catch (InterruptedException | ExecutionException e) {
							e.printStackTrace();
						}
					}
				}
				class ThreadDemo implements Callable<Integer>{
					@Override
					public Integer call() throws Exception {
						int sum = 0;		
						for (int i = 0; i <= 100000; i++) {
							sum += i;
						}		
						return sum;
					}	
				}			
		同步锁Lock:
			解决线程安全的方法：3种
				1）同步代码块，使用synchronized关键字，隐式锁
				2）同步方法，使用synchronized关键字，隐式锁
				3）JDK1.5以后使用同步锁Lock[ReenTrantLock]，显式锁，使用lock()上锁,unlock()释放锁[为确保这步执行，放在finally块执行]
			如：public class TestLock {
					public static void main(String[] args) {
						Ticket ticket = new Ticket();		
						new Thread(ticket, "1号窗口").start();
						new Thread(ticket, "2号窗口").start();
						new Thread(ticket, "3号窗口").start();
					}
				}
				class Ticket implements Runnable{	
					private int tick = 100;	
					private Lock lock = new ReentrantLock();
					@Override
					public void run() {
						while(true){							
							lock.lock(); //上锁							
							try{
								if(tick > 0){
									try {
										Thread.sleep(200);
									} catch (InterruptedException e) {
									}
									
									System.out.println(Thread.currentThread().getName() + " 完成售票，余票为：" + --tick);
								}
							}finally{
								lock.unlock(); //释放锁
							}
						}
					}					
				}
		“等待（wait）-唤醒（notifyAll）”机制：经典的生成者-消费者（PC）案例
			方式一：使用synchronized关键字实现，（Object）核心方法：this.wait()[注：为避免存在虚假唤醒问题，需要将此方法放在while循环语句内，JDK规定的]、this.notifyAll()
			如：public class TestProductorAndConsumer {
					public static void main(String[] args) {
						Clerk clerk = new Clerk();						
						Productor pro = new Productor(clerk);
						Consumer cus = new Consumer(clerk);						
						new Thread(pro, "生产者 A").start();
						new Thread(cus, "消费者 B").start();						
						new Thread(pro, "生产者 C").start();
						new Thread(cus, "消费者 D").start();
					}					
				}
				//店员
				class Clerk{
					private int product = 0;					
					//进货
					public synchronized void get(){//循环次数：0
						while(product >= 1){//为了避免虚假唤醒问题，应该总是使用在循环中
							System.out.println("产品已满！");							
							try {
								this.wait();//等待
							} catch (InterruptedException e) {
							}							
						}						
						System.out.println(Thread.currentThread().getName() + " : " + ++product);
						this.notifyAll();//唤醒
					}					
					//卖货
					public synchronized void sale(){//product = 0; 循环次数：0
						while(product <= 0){
							System.out.println("缺货！");							
							try {
								this.wait();//等待
							} catch (InterruptedException e) {
							}
						}						
						System.out.println(Thread.currentThread().getName() + " : " + --product);
						this.notifyAll();//唤醒
					}
				}
				//生产者
				class Productor implements Runnable{
					//使用UML类图的聚合关系
					private Clerk clerk;
					public Productor(Clerk clerk) {
						this.clerk = clerk;
					}
					@Override
					public void run() {
						for (int i = 0; i < 20; i++) {
							try {
								Thread.sleep(200);
							} catch (InterruptedException e) {
							}						
							clerk.get();
						}
					}
				}
				//消费者
				class Consumer implements Runnable{
					private Clerk clerk;
					public Consumer(Clerk clerk) {
						this.clerk = clerk;
					}
					@Override
					public void run() {
						for (int i = 0; i < 20; i++) {
							clerk.sale();
						}
					}
				}
			方式二：使用同步锁Lock利用Condition线程通讯，核心方法：condition.await()、condition.signalAll()
				如：public class TestProductorAndConsumerForLock {
						public static void main(String[] args) {
							Clerk clerk = new Clerk();
							Productor pro = new Productor(clerk);
							Consumer con = new Consumer(clerk);
							new Thread(pro, "生产者 A").start();
							new Thread(con, "消费者 B").start();
					//		 new Thread(pro, "生产者 C").start();
					//		 new Thread(con, "消费者 D").start();
						}
					}
					class Clerk {
						private int product = 0;
						private Lock lock = new ReentrantLock();//同步锁，闭锁
						private Condition condition = lock.newCondition();
						// 进货
						public void get() {
							lock.lock();//加锁
							try {
								if (product >= 1) {
									System.out.println("产品已满！");
									try {
										condition.await();
									} catch (InterruptedException e) {
									}
								}
								System.out.println(Thread.currentThread().getName() + " : "
										+ ++product);
								condition.signalAll();
							} finally {
								lock.unlock();//释放锁
							}
						}
						// 卖货
						public void sale() {
							lock.lock();
							try {
								if (product <= 0) {
									System.out.println("缺货！");
									try {
										condition.await();
									} catch (InterruptedException e) {
									}
								}
								System.out.println(Thread.currentThread().getName() + " : "
										+ --product);
								condition.signalAll();
							} finally {
								lock.unlock();
							}
						}
					}
					// 生产者
					class Productor implements Runnable {
						private Clerk clerk;
						public Productor(Clerk clerk) {
							this.clerk = clerk;
						}
						@Override
						public void run() {
							for (int i = 0; i < 20; i++) {
								try {
									Thread.sleep(200);
								} catch (InterruptedException e) {
									e.printStackTrace();
								}
								clerk.get();
							}
						}
					}
					// 消费者
					class Consumer implements Runnable {
						private Clerk clerk;
						public Consumer(Clerk clerk) {
							this.clerk = clerk;
						}
						@Override
						public void run() {
							for (int i = 0; i < 20; i++) {
								clerk.sale();
							}
						}
					}
		线程按序交替[案例]，技术点：使用的是同步锁Lock利用Condition线程通讯技术，
			需求：编写一个程序，开启 3 个线程，这三个线程的 ID 分别为 A、B、C，每个线程将自己的 ID 在屏幕上打印 10 遍，要求输出的结果必须按顺序显示。如：ABCABCABC…… 依次递归
			public class TestABCAlternate {				
				public static void main(String[] args) {
					AlternateDemo ad = new AlternateDemo();					
					new Thread(new Runnable() {
						@Override
						public void run() {						
							for (int i = 1; i <= 20; i++) {
								ad.loopA(i);
							}							
						}
					}, "A").start();					
					new Thread(new Runnable() {
						@Override
						public void run() {							
							for (int i = 1; i <= 20; i++) {
								ad.loopB(i);
							}							
						}
					}, "B").start();					
					new Thread(new Runnable() {
						@Override
						public void run() {							
							for (int i = 1; i <= 20; i++) {
								ad.loopC(i);								
								System.out.println("-----------------------------------");
							}							
						}
					}, "C").start();
				}
			}
			class AlternateDemo{				
				private int number = 1; //当前正在执行线程的标记				
				private Lock lock = new ReentrantLock();
				private Condition condition1 = lock.newCondition();
				private Condition condition2 = lock.newCondition();
				private Condition condition3 = lock.newCondition();				
				/**
				 * @param totalLoop : 循环第几轮
				 */
				public void loopA(int totalLoop){
					lock.lock();					
					try {
						//1. 判断
						if(number != 1){
							condition1.await();
						}						
						//2. 打印
						for (int i = 1; i <= 1; i++) {
							System.out.println(Thread.currentThread().getName() + "\t" + i + "\t" + totalLoop);
						}						
						//3. 唤醒
						number = 2;
						condition2.signal();
					} catch (Exception e) {
						e.printStackTrace();
					} finally {
						lock.unlock();
					}
				}				
				public void loopB(int totalLoop){
					lock.lock();					
					try {
						//1. 判断
						if(number != 2){
							condition2.await();
						}						
						//2. 打印
						for (int i = 1; i <= 1; i++) {
							System.out.println(Thread.currentThread().getName() + "\t" + i + "\t" + totalLoop);
						}						
						//3. 唤醒
						number = 3;
						condition3.signal();
					} catch (Exception e) {
						e.printStackTrace();
					} finally {
						lock.unlock();
					}
				}				
				public void loopC(int totalLoop){
					lock.lock();					
					try {
						//1. 判断
						if(number != 3){
							condition3.await();
						}						
						//2. 打印
						for (int i = 1; i <= 1; i++) {
							System.out.println(Thread.currentThread().getName() + "\t" + i + "\t" + totalLoop);
						}						
						//3. 唤醒
						number = 1;
						condition1.signal();
					} catch (Exception e) {
						e.printStackTrace();
					} finally {
						lock.unlock();
					}
				}				
			}
		ReadWriteLock[ReenTrantReadWriteLock]读写锁[相对JDK1.5以前的独占锁]：
			读写/写写：互斥，一个线程操作
			读读：不互斥，多个线程共享并发操作
			核心方法：reenTrantReadWriteLock.readLock()、reenTrantReadWriteLock.writeLock()
			如：public class TestReadWriteLock {
					public static void main(String[] args) {
						ReadWriteLockDemo rw = new ReadWriteLockDemo();						
						new Thread(new Runnable() {							
							@Override
							public void run() {
								rw.set((int)(Math.random() * 101));
							}
						}, "Write:").start();												
						for (int i = 0; i < 100; i++) {
							new Thread(new Runnable() {								
								@Override
								public void run() {
									rw.get();
								}
							}, "Read:").start();
						}
					}					
				}
				class ReadWriteLockDemo{					
					private int number = 0;					
					private ReadWriteLock lock = new ReentrantReadWriteLock();					
					//读
					public void get(){
						lock.readLock().lock(); //上锁						
						try{
							System.out.println(Thread.currentThread().getName() + " : " + number);
						}finally{
							lock.readLock().unlock(); //释放锁
						}
					}					
					//写
					public void set(int number){
						lock.writeLock().lock();						
						try{
							System.out.println(Thread.currentThread().getName());
							this.number = number;
						}finally{
							lock.writeLock().unlock();
						}
					}
				}
		线程八锁：
			核心：非静态方法的锁默认为this，静态方法的锁为对应的Class实例
				  某一时刻内，只能拥有一个线程持有锁，无论几个方法
		线程池：
			目的：为了避免频繁的创建和销毁线程是比较耗CPU资源的[参考数据库连接池]，提高了响应的速度。它提供了一个线程队列，队列中保留着所有等待[wait]状态中的线程。
			体系结构：
				java.utils.concurrent.Executor：负责线程的使用与调度的根接口
					|-- ExecutorService 子接口：线程池的主要接口
						|-- ThreadPoolExecutor：线程池的实现类
						|-- ScheduledExecutorService：负责线程的调度 子接口
							|-- ScheduledThreadPoolExecutor：继承了ThreadPoolExecutor，实现了ScheduledExecutorService
			工具类：Executors
				ExecutorService newFixedThreadPool()：创建固定大小的线程池
				ExecutorService newCachedThreadPool()：缓存线程池，线程池的数量不固定，可以根据需求自动更改数量。
				ExecutorService newSingleThreadExecutor()：创建单个线程池。线程池中只有一个线程
				ScheduledExecutorService newScheduledThreadPool()：创建固定大小的线程池，也可以延迟或定时执行任务。
			使用：1、创建线程池；2、为线程池中的线程分配任务（submit）；3、关闭线程池
			如：public class TestThreadPool {				
					public static void main(String[] args) throws Exception {
						//1. 创建线程池
						ExecutorService pool = Executors.newFixedThreadPool(5);						
						List<Future<Integer>> list = new ArrayList<>();						
						for (int i = 0; i < 10; i++) {
							Future<Integer> future = pool.submit(new Callable<Integer>(){
								@Override
								public Integer call() throws Exception {
									int sum = 0;									
									for (int i = 0; i <= 100; i++) {
										sum += i;
									}									
									return sum;
								}								
							});
							list.add(future);
						}						
						pool.shutdown();//关闭线程池						
						for (Future<Integer> future : list) {
							System.out.println(future.get());
						}																		
						/*ThreadPoolDemo tpd = new ThreadPoolDemo();						
						//2. 为线程池中的线程分配任务
						for (int i = 0; i < 10; i++) {
							pool.submit(tpd);
						}						
						//3. 关闭线程池
						pool.shutdown();*/
					}					
				//	new Thread(tpd).start();
				//	new Thread(tpd).start();
				}
				class ThreadPoolDemo implements Runnable{
					private int i = 0;					
					@Override
					public void run() {
						while(i <= 100){
							System.out.println(Thread.currentThread().getName() + " : " + i++);
						}
					}					
				}
				//线程池测试	
				public class TestScheduledThreadPool {
					public static void main(String[] args) throws Exception {
						ScheduledExecutorService pool = Executors.newScheduledThreadPool(5);						
						for (int i = 0; i < 5; i++) {
							Future<Integer> result = pool.schedule(new Callable<Integer>(){
								@Override
								public Integer call() throws Exception {
									int num = new Random().nextInt(100);//生成随机数
									System.out.println(Thread.currentThread().getName() + " : " + num);
									return num;
								}								
							}, 1, TimeUnit.SECONDS);							
							System.out.println(result.get());
						}						
						pool.shutdown();
					}					
				}
		ForkJoinPool分支/合并框架[工作窃取]：JDK1.7出现的
			思想：将一个大任务，拆分[fork]成若干个不可再拆分的小任务，这些小任务由线程队列并发的去执行[采用工作窃取模式]，最终将执行的结果进行汇总[join]
			JDK1.8新特性对ForkJoinPool框架进行了改进!
			如：public class TestForkJoinPool {					
					public static void main(String[] args) {
						Instant start = Instant.now();
						//JDK1.7出现的						
						ForkJoinPool pool = new ForkJoinPool();						
						ForkJoinTask<Long> task = new ForkJoinSumCalculate(0L, 50000000000L);						
						Long sum = pool.invoke(task);						
						System.out.println(sum);						
						Instant end = Instant.now();						
						System.out.println("耗费时间为：" + Duration.between(start, end).toMillis());//166-1996-10590
					}					
					@Test
					public void test1(){
						Instant start = Instant.now();						
						long sum = 0L;						
						for (long i = 0L; i <= 50000000000L; i++) {
							sum += i;
						}						
						System.out.println(sum);						
						Instant end = Instant.now();						
						System.out.println("耗费时间为：" + Duration.between(start, end).toMillis());//35-3142-15704
					}					
					//java8 新特性
					@Test
					public void test2(){
						Instant start = Instant.now();						
						Long sum = LongStream.rangeClosed(0L, 50000000000L)
											 .parallel()
											 .reduce(0L, Long::sum);						
						System.out.println(sum);						
						Instant end = Instant.now();						
						System.out.println("耗费时间为：" + Duration.between(start, end).toMillis());//1536-8118
					}
				}
				//计算类
				class ForkJoinSumCalculate extends RecursiveTask<Long>{
					private static final long serialVersionUID = -259195479995561737L;					
					private long start;
					private long end;					
					private static final long THURSHOLD = 10000L;  //临界值					
					public ForkJoinSumCalculate(long start, long end) {
						this.start = start;
						this.end = end;
					}
					@Override
					protected Long compute() {
						long length = end - start;						
						if(length <= THURSHOLD){
							long sum = 0L;							
							for (long i = start; i <= end; i++) {
								sum += i;
							}							
							return sum;
						}else{
							long middle = (start + end) / 2;							
							ForkJoinSumCalculate left = new ForkJoinSumCalculate(start, middle); 
							left.fork(); //进行拆分，同时压入线程队列							
							ForkJoinSumCalculate right = new ForkJoinSumCalculate(middle+1, end);
							right.fork(); //							
							return left.join() + right.join();
						}
					}					
				}		
	三、泛型，参考：https://blog.csdn.net/tyrroo/article/details/80930938
		含义：
			泛型，即“参数化类型”。顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。
				  这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。在面向对象编程及各种设计模式中有非常广泛的应用。
		特性：
			泛型只在编译阶段有效，在编译过程中，正确检验泛型结果后，会将泛型的相关信息给出，并且在对象进入和离开方法的边界处添加类型检查和类型转换的方法。
			也就是说，泛型信息不会进入到运行时阶段。对此总结成一句话：泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型。
		使用：
			三种使用方式，分别为：泛型类、泛型接口、泛型方法
			1）泛型类-泛型类用于类的定义中，被称为泛型类。最典型的就是各种容器类，如：List、Set、Map。
			   基本语法：				
					class 类名称 <泛型标识：可以随便写任意标识号，指定泛型类型>{
						private 泛型标识 /*（成员变量类型）*/ var; 
						.....				 
						}
					}
				举例：
					//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型，在实例化泛型类时，必须指定T的具体类型
					public class Generic<T>{ 
						//key这个成员变量的类型为T,T的类型由外部指定  
						private T key;
						//泛型构造方法形参key的类型也为T，T的类型由外部指定
						public Generic(T key) { 
							this.key = key;
						}
						//泛型方法getKey的返回值类型为T，T的类型由外部指定
						public T getKey(){ 
							return key;
						}
					}
					
					调用：
					//传入的实参类型需与泛型的类型参数类型相同，即为Integer.泛型的类型参数只能是类类型（包括自定义类），不能是简单类型
					Generic<Integer> genericInteger = new Generic<Integer>(123456);					 					
					Generic<String> genericString = new Generic<String>("key_vlaue");
					Log.d("泛型测试","key is " + genericInteger.getKey());
					Log.d("泛型测试","key is " + genericString.getKey());
					思考：定义的泛型类，就一定要传入泛型类型实参么？在使用泛型的时候如果传入泛型实参，则会根据传入的泛型实参做相应的限制，此时泛型才会起到限制作用。
					      如果不传入泛型类型实参的话，在泛型类中使用泛型的方法或成员变量定义的类型可以为任何的类型。如：
						  Generic generic1 = new Generic("111111");
						  Generic generic2 = new Generic(4444);
						  Log.d("泛型测试","key is " + generic1.getKey());
						  Log.d("泛型测试","key is " + generic2.getKey());
					结论：泛型的类型参数只能是类类型，不能是简单类型；不能对确切的泛型类型使用instanceof操作，编译时会出错；如：
						  if(ex_num instanceof Generic<Number>){   
						  } 
			2）泛型接口-泛型接口与泛型类的定义及使用基本相同。泛型接口常被用在各种类的生产器中
					举例：
					//定义一个泛型接口
					public interface Generator<T> {
						public T next();
					}
					当实现泛型接口的类，未传入泛型实参时：
					/**
					 * 未传入泛型实参时，与泛型类的定义相同，在声明类的时候，需将泛型的声明也一起加到类中
					 * 即：class FruitGenerator<T> implements Generator<T>{
					 * 如果不声明泛型，如：class FruitGenerator implements Generator<T>，编译器会报错："Unknown class"
					 */
					class FruitGenerator<T> implements Generator<T>{
						@Override
						public T next() {
							return null;
						}
					}
					//当实现泛型接口的类，传入泛型实参时：
					/**
					 * 传入泛型实参时：
					 * 定义一个生产器实现这个接口,虽然我们只创建了一个泛型接口Generator<T>，但是我们可以为T传入无数个实参，形成无数种类型的Generator接口。
					 * 在实现类实现泛型接口时，如已将泛型类型传入实参类型，则所有使用泛型的地方都要替换成传入的实参类型
					 * 即：Generator<T>，public T next();中的的T都要替换成传入的String类型
					 */
					public class FruitGenerator implements Generator<String> {					 
						private String[] fruits = new String[]{"Apple", "Banana", "Pear"};					 
						@Override
						public String next() {
							Random rand = new Random();
							return fruits[rand.nextInt(3)];
						}
					}
			3）泛型的通配符
					问题的产生？
					我们知道Ingeter是Number的一个子类，Generic<Ingeter>与Generic<Number>实际上是相同的一种基本类型。
					那么问题来了，在使用Generic<Number>作为形参的方法中，能否使用Generic<Ingeter>的实例传入呢？
					在逻辑上类似于Generic<Number>和Generic<Ingeter>是否可以看成具有父子关系的泛型类型呢？
					举例：
					public void showKeyValue(Generic<Number> obj){
						Log.d("泛型测试","key value is " + obj.getKey());
					}
					Generic<Integer> gInteger = new Generic<Integer>(123);
					Generic<Number> gNumber = new Generic<Number>(456);					
					// showKeyValue这个方法编译器会为我们报错：Generic<java.lang.Integer> cannot be applied to Generic<java.lang.Number>
					showKeyValue(gInteger);
					结论：不行，同一种泛型可以对应多个版本（因为参数类型是不确定的），不同版本的泛型类实例是不兼容的。由此类型通配符应运而生。
					改进：
					public void showKeyValue1(Generic<?> obj){
						Log.d("泛型测试","key value is " + obj.getKey());
					}
					注：此处？是类型实参，而不是类型形参，是一种真实的类型。
			4）泛型方法
					泛型类，是在实例化类的时候指明泛型的具体类型；泛型方法，是在调用方法的时候指明泛型的具体类型。
				基本格式：
					/**
					 * @param tClass 传入的泛型实参
					 * @return T 返回值为T类型
					 * 说明：
					 *     1）public 与 返回值中间<T>非常重要，可以理解为声明此方法为泛型方法。
					 *     2）只有声明了<T>的方法才是泛型方法，泛型类中的使用了泛型的成员方法并不是泛型方法。
					 *     3）<T>表明该方法将使用泛型类型T，此时才可以在方法中使用泛型类型T。
					 *     4）与泛型类的定义一样，此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型。
					 */
					public <T> T genericMethod(Class<T> tClass)throws InstantiationException,
					  IllegalAccessException{
							T instance = tClass.newInstance();
							return instance;
					}		
					使用：Object obj = genericMethod(Class.forName("com.test.test"));
				基本用法[示例]：
					public class GenericTest {
					   //这个类是个泛型类，在上面已经介绍过
					   public class Generic<T>{     
							private T key;					 
							public Generic(T key) {
								this.key = key;
							}					 
							//我想说的其实是这个，虽然在方法中使用了泛型，但是这并不是一个泛型方法。
							//这只是类中一个普通的成员方法，只不过他的返回值是在声明泛型类已经声明过的泛型。
							//所以在这个方法中才可以继续使用 T 这个泛型。
							public T getKey(){
								return key;
							}					 
							/**
							 * 这个方法显然是有问题的，在编译器会给我们提示这样的错误信息"cannot reslove symbol E"
							 * 因为在类的声明中并未声明泛型E，所以在使用E做形参和返回值类型时，编译器会无法识别。
							public E setKey(E key){
								 this.key = key
							}
							*/
						}					 
						/** 
						 * 这才是一个真正的泛型方法。
						 * 首先在public与返回值之间的<T>必不可少，这表明这是一个泛型方法，并且声明了一个泛型T
						 * 这个T可以出现在这个泛型方法的任意位置.
						 * 泛型的数量也可以为任意多个 
						 *    如：public <T,K> K showKeyName(Generic<T> container){
						 *        ...
						 *        }
						 */
						public <T> T showKeyName(Generic<T> container){
							System.out.println("container key :" + container.getKey());
							//当然这个例子举的不太合适，只是为了说明泛型方法的特性。
							T test = container.getKey();
							return test;
						}					 
						//这也不是一个泛型方法，这就是一个普通的方法，只是使用了Generic<Number>这个泛型类做形参而已。
						public void showKeyValue1(Generic<Number> obj){
							Log.d("泛型测试","key value is " + obj.getKey());
						}				 
						//这也不是一个泛型方法，这也是一个普通的方法，只不过使用了泛型通配符?
						//?是一种类型实参
						public void showKeyValue2(Generic<?> obj){
							Log.d("泛型测试","key value is " + obj.getKey());
						}					 
						 /**
						 * 这个方法是有问题的，编译器会为我们提示错误信息："UnKnown class 'E' "
						 * 虽然我们声明了<T>,也表明了这是一个可以处理泛型的类型的泛型方法。
						 * 但是只声明了泛型类型T，并未声明泛型类型E，因此编译器并不知道该如何处理E这个类型。
						public <T> T showKeyName(Generic<E> container){
							...
						}  
						*/					 
						/**
						 * 这个方法也是有问题的，编译器会为我们提示错误信息："UnKnown class 'T' "
						 * 对于编译器来说T这个类型并未项目中声明过，因此编译也不知道该如何编译这个类。
						 * 所以这也不是一个正确的泛型方法声明。
						public void showkey(T genericObj){
						}
						*/					 
					}
				结论：泛型方法可以出现在任何地方和任何场景中使用[示例]。
					public class GenericDemo {
						class Fruit{
							@Override
							public String toString() {
								return "fruit";
							}
						}					 
						class Apple extends Fruit{
							@Override
							public String toString() {
								return "apple";
							}
						}				 
						class Person{
							@Override
							public String toString() {
								return "Person";
							}
						}					 
						class GenerateTest<T>{
							public void show_1(T t){
								System.out.println(t.toString());
							}				 
							//在泛型类中声明了一个泛型方法，使用泛型E，这种泛型E可以为任意类型。可以类型与T相同，也可以不同。
							//由于泛型方法在声明的时候会声明泛型<E>，因此即使在泛型类中并未声明泛型，编译器也能够正确识别泛型方法中识别的泛型。
							public <E> void show_2(E t){
								System.out.println(t.toString());
							}					 
							//在泛型类中声明了一个泛型方法，使用泛型T，注意这个T是一种全新的类型，可以与泛型类中声明的T不是同一种类型。
							public <T> void show_3(T t){
								System.out.println(t.toString());
							}
						}					 
						public static void main(String[] args) {
							Apple apple = new Apple();
							Person person = new Person();					 
							GenerateTest<Fruit> generateTest = new GenerateTest<Fruit>();
							//apple是Fruit的子类，所以这里可以
							generateTest.show_1(apple);
							//编译器会报错，因为泛型类型实参指定的是Fruit，而传入的实参类是Person
							//generateTest.show_1(person);					 
							//使用这两个方法都可以成功
							generateTest.show_2(apple);
							generateTest.show_2(person);					 
							//使用这两个方法也都可以成功
							generateTest.show_3(apple);
							generateTest.show_3(person);
						}
					}				
				泛型方法与可变参数[示例]
					public <T> void printMsg(T... args){//T可以同时传入不同类型
						for(T t : args){
							Log.d("泛型测试","t is " + t);
						}
					}
					调用：printMsg("111",222,"aaaa","2323.4",55.55);				
				静态方法与泛型[示例]
					结论：如果静态方法要使用泛型的话，必须将静态方法也定义成泛型方法
					public class StaticGenerator<T> {
						/**
						 * 如果在类中定义使用泛型的静态方法，需要添加额外的泛型声明（将这个方法定义成泛型方法）
						 * 即使静态方法要使用泛型类中已经声明过的泛型也不可以。
						 * 如：public static void show(T t){..},此时编译器会提示错误信息："StaticGenerator cannot be refrenced from static context"						  
						 */
						public static <T> void show(T t){
					 
						}
					}				
				泛型上下边界[示例]
					在使用泛型的时候，我们还可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。
					泛型上边界：即传入的类型实参必须是指定类型的子类型，如：					
						普通方法：
						public void showKeyValue1(Generic<? extends Number> obj){
							Log.d("泛型测试","key value is " + obj.getKey());
						}
						使用：
						Generic<String> generic1 = new Generic<String>("11111");
						Generic<Integer> generic2 = new Generic<Integer>(2222);
						Generic<Float> generic3 = new Generic<Float>(2.4f);
						Generic<Double> generic4 = new Generic<Double>(2.56);

						//showKeyValue1(generic1);//这一行代码编译器会提示错误，因为String类型并不是Number类型的子类						 
						showKeyValue1(generic2);
						showKeyValue1(generic3);
						showKeyValue1(generic4);
						类：
						public class Generic<T extends Number>{
							private T key;
						 
							public Generic(T key) {
								this.key = key;
							}
						 
							public T getKey(){
								return key;
							}
						}
						使用：
						Generic<String> generic1 = new Generic<String>("11111");//这一行代码也会报错，因为String不是Number的子类
						泛型方法：					
						//在泛型方法中添加上下边界限制的时候，必须在权限声明与返回值之间的<T>上添加上下边界，即在泛型声明的时候添加
						//public <T> T showKeyName(Generic<T extends Number> container)，编译器会报错："Unexpected bound"
						public <T extends Number> T showKeyName(Generic<T> container){
							T test = container.getKey();
							return test;
						}				
					
				结论：泛型的上下边界添加，必须与泛型的声明在一起。					
	四、设计模式
		重要性：设计模式不依赖于语言，对普遍存在的各种问题，所提出的解决方案，思想来源于建筑学。
				项目的后期维护扩展，有新需求，都需要设计模式。
				在软件中的运用：面向对象(oo)->功能模块[设计模式+算法/数据结构]->框架[多种设计模式]->架构[服务器集群]
		Java设计模式：23种、七大原则
			目的：为了让软件具有更好的代码重用性[相同的功能，不需要重复编写]、可读性[规范性]、可扩展性[增加新功能非常方便，可维护性]、可靠性[新功能对就功能不会产生影响]，->高内聚、降低耦合性。
			七大原则：是设计模式的基础
				单一职责原则-一个类只负责一项职责，降低类的负责度，提高可读性、可维护性，降低风险。当类方法很少，可以在方法级别实现单一职责原则。				
					//方案一
					public class SingleResponsibility1 {
						public static void main(String[] args) {
							RoadVehicle roadVehicle = new RoadVehicle();
							roadVehicle.run("摩托车");
							roadVehicle.run("汽车");
							
							AirVehicle airVehicle = new AirVehicle();						
							airVehicle.run("飞机");
						}
					}
					//1. 遵守单一职责原则
					//2. 但是这样做的改动很大，即将类分解，同时修改客户端
					//3. 改进：直接修改Vehicle 类，改动的代码会比较少=>方案2
					class RoadVehicle {
						public void run(String vehicle) {
							System.out.println(vehicle + "公路运行");
						}
					}
					class AirVehicle {
						public void run(String vehicle) {
							System.out.println(vehicle + "天空运行");
						}
					}
					class WaterVehicle {
						public void run(String vehicle) {
							System.out.println(vehicle + "水中运行");
						}
					}
					//方案二
					public class SingleResponsibility2 {
							public static void main(String[] args) {
								Vehicle2 vehicle2  = new Vehicle2();
								vehicle2.run("汽车");
								vehicle2.runWater("轮船");
								vehicle2.runAir("飞机");
							}

						}
						//1. 这种修改方法没有对原来的类做大的修改，只是增加方法
						//2. 这里虽然没有在类这个级别上遵守单一职责原则，但是在方法级别上，仍然是遵守单一职责
						class Vehicle2 {
							public void run(String vehicle) {								
								System.out.println(vehicle + " 在公路上运行....");								
							}						
							public void runAir(String vehicle) {
								System.out.println(vehicle + " 在天空上运行....");
							}							
							public void runWater(String vehicle) {
								System.out.println(vehicle + " 在水中行....");
							}							
						}
				接口隔离原则-一个类对另一个类的依赖应建立在最小接口上。
					UML类图：
							 依赖										实现
						A类	------->接口[最小接口，接口拆分多个接口]<------- B类
							 依赖           							实现 
						C类	------->接口[最小接口，接口拆分多个接口]<------- D类
					如：public class Segregation1 {
							public static void main(String[] args) {
								A a = new A();
								a.depend1(new B()); // A类通过接口去依赖B类
								a.depend2(new B());
								a.depend3(new B());

								C c = new C();
								c.depend1(new D()); // C类通过接口去依赖(使用)D类
								c.depend4(new D());
								c.depend5(new D());
							}
						}
						// 接口1
						interface Interface1 {
							void operation1();

						}
						// 接口2
						interface Interface2 {
							void operation2();
							void operation3();
						}
						// 接口3
						interface Interface3 {
							void operation4();
							void operation5();
						}
						class B implements Interface1, Interface2 {
							public void operation1() {
								System.out.println("B 实现了 operation1");
							}
							public void operation2() {
								System.out.println("B 实现了 operation2");
							}
							public void operation3() {
								System.out.println("B 实现了 operation3");
							}

						}
						class D implements Interface1, Interface3 {
							public void operation1() {
								System.out.println("D 实现了 operation1");
							}
							public void operation4() {
								System.out.println("D 实现了 operation4");
							}
							public void operation5() {
								System.out.println("D 实现了 operation5");
							}
						}
						class A { // A 类通过接口Interface1,Interface2 依赖(使用) B类，但是只会用到1,2,3方法
							public void depend1(Interface1 i) {
								i.operation1();
							}
							public void depend2(Interface2 i) {
								i.operation2();
							}
							public void depend3(Interface2 i) {
								i.operation3();
							}
						}
						class C { // C 类通过接口Interface1,Interface3 依赖(使用) D类，但是只会用到1,4,5方法
							public void depend1(Interface1 i) {
								i.operation1();
							}
							public void depend4(Interface3 i) {
								i.operation4();
							}
							public void depend5(Interface3 i) {
								i.operation5();
							}
						}												
				依赖倒转[倒置]原则-核心思想是面向接口编程，使程序有一个缓冲层，抽象不依赖细节，细节依赖抽象，接口或抽象类制定规范，细节交给实现类
					坚持3种传递方式：利用接口、构造器、setter进行依赖传递！注意细节：1，低层模块尽量是接口或抽象类；2，变量尽量使用是接口或抽象类；3，继承了里氏替换原则
					如：public class DependecyInversion {
							public static void main(String[] args) {
								//客户端无需改变
								Person person = new Person();
								person.receive(new Email());								
								person.receive(new WeiXin());
							}
						}
						//定义接口
						interface IReceiver {
							public String getInfo();
						}
						class Email implements IReceiver {
							public String getInfo() {
								return "电子邮件信息: hello,world";
							}
						}
						//增加微信
						class WeiXin implements IReceiver {
							public String getInfo() {
								return "微信信息: hello,ok";
							}
						}
						class Person {							
							public void receive(IReceiver receiver) {//这里我们是对接口的依赖
								System.out.println(receiver.getInfo());
							}
						}
					传递方式：
						public class DependencyPass {
							public static void main(String[] args) {
								//通过接口进行依赖传递
								ChangHong changHong = new ChangHong();
						//		OpenAndClose openAndClose = new OpenAndClose();
						//		openAndClose.open(changHong);								
								//通过构造器进行依赖传递
						//		OpenAndClose openAndClose = new OpenAndClose(changHong);
						//		openAndClose.open();
								//通过setter方法进行依赖传递
								OpenAndClose openAndClose = new OpenAndClose();
								openAndClose.setTv(changHong);
								openAndClose.open();
							}
						}
						// 方式1：通过接口传递，2接口2实现
						// 开关接口
						// interface IOpenAndClose {
						// public void open(ITV tv); //抽象方法,接收接口
						// }
						// interface ITV { //ITV接口
						// public void play();
						// } 
						// class ChangHong implements ITV {
						//	@Override
						//	public void play() {
						//		System.out.println("长虹电视机，打开");
						//	} 
						// }
						// 实现接口
						// class OpenAndClose implements IOpenAndClose{
						// public void open(ITV tv){
						// tv.play();
						// }
						// }
						// 方式2: 通过构造方法，2接口1实现
						// interface IOpenAndClose {
						// public void open(); //抽象方法
						// }
						// interface ITV { //ITV接口
						// public void play();
						// }
						// class OpenAndClose implements IOpenAndClose{
						// public ITV tv; //成员
						// public OpenAndClose(ITV tv){ //构造器
						// this.tv = tv;
						// }
						// public void open(){
						// this.tv.play();
						// }
						// }
						// 方式3 , 通过setter方法传递
						interface IOpenAndClose {
							public void open(); // 抽象方法
							public void setTv(ITV tv);
						}
						interface ITV { // ITV接口
							public void play();
						}
						class OpenAndClose implements IOpenAndClose {
							private ITV tv;
							public void setTv(ITV tv) {
								this.tv = tv;
							}
							public void open() {
								this.tv.play();
							}
						}
						class ChangHong implements ITV {
							@Override
							public void play() {
								System.out.println("长虹电视机，打开");
							}							 
						}
				里氏替换原则-正确使用继承[将父类与子类去继承更基础的类,原有的继承关系被打断]，继承会使耦合性增强，尽量不要去修改父类的方法；在适当的时候可以使用聚合、组合、依赖来解决这一问题！
					如：public class Liskov {
							public static void main(String[] args) {
								A a = new A();
								System.out.println("11-3=" + a.func1(11, 3));
								B b = new B();
								//调用完成的功能就会很明确
								System.out.println("11+3+9=" + b.func2(11, 3));									
								//使用组合仍然可以使用到A类相关方法
								System.out.println("11-3=" + b.func3(11, 3));// 这里本意是求出11-3								
							}
						}
						//创建一个更加基础的基类
						class Base {
							//把更加基础的方法和成员写到Base类
						}
						// A类
						class A extends Base {
							// 返回两个数的差
							public int func1(int num1, int num2) {
								return num1 - num2;
							}
						}
						// 增加了一个新功能：完成两个数相加,然后和9求和
						class B extends Base {
							//如果B需要使用A类的方法,使用组合关系
							private A a = new A();							
							public int func1(int a, int b) {
								return a + b;
							}
							public int func2(int a, int b) {
								return func1(a, b) + 9;
							}							
							//我们仍然想使用A的方法
							public int func3(int a, int b) {
								return this.a.func1(a, b);
							}
						}					
				开闭[ocp]原则-对扩展者开放[提供方]，对修改者关闭[使用者，调用者]，核心！
					如：public class Ocp {
							public static void main(String[] args) {
								GraphicEditor graphicEditor = new GraphicEditor();
								graphicEditor.drawShape(new Rectangle());
								graphicEditor.drawShape(new Circle());
								graphicEditor.drawShape(new Triangle());
								graphicEditor.drawShape(new OtherGraphic());
							}
						}
						//这是一个用于绘图的类 [使用方]
						class GraphicEditor {							
							public void drawShape(Shape s) {//接收Shape对象，调用draw方法
								s.draw();
							}							
						}
						//Shape类，基类
						abstract class Shape {
							int m_type;							
							public abstract void draw();//抽象方法
						}
						//扩展方
						class Rectangle extends Shape {
							Rectangle() {
								super.m_type = 1;
							}
							@Override
							public void draw() {
								System.out.println(" 绘制矩形 ");
							}
						}
						class Circle extends Shape {
							Circle() {
								super.m_type = 2;
							}
							@Override
							public void draw() {
								System.out.println(" 绘制圆形 ");
							}
						}
						//新增画三角形
						class Triangle extends Shape {
							Triangle() {
								super.m_type = 3;
							}
							@Override
							public void draw() {
								System.out.println(" 绘制三角形 ");
							}
						}
						//新增一个图形
						class OtherGraphic extends Shape {
							OtherGraphic() {
								super.m_type = 4;
							}
							@Override
							public void draw() {
								System.out.println(" 绘制其它图形 ");
							}
						}					
				迪米特法则-最少知道原则，只与直接朋友通讯。
					耦合关系：组合、关联、聚合、依赖、泛化、实现。
					直接朋友：a类与b类直接朋友，若a类成员变量、方法参数、方法返回值是b类，两者是直接朋友；而出现在局部变量里的b类则称为陌生的类；						
						如：public class Demeter1 {
								public static void main(String[] args) {
									System.out.println("~~~使用迪米特法则~~");
									//创建了一个 SchoolManager 对象
									SchoolManager schoolManager = new SchoolManager();
									//输出学院的员工id 和  学校总部的员工信息
									schoolManager.printAllEmployee(new CollegeManager());
								}
							}
							//学校总部员工类
							class Employee {
								private String id;
								public void setId(String id) {
									this.id = id;
								}
								public String getId() {
									return id;
								}
							}
							//学院的员工类
							class CollegeEmployee {
								private String id;
								public void setId(String id) {
									this.id = id;
								}
								public String getId() {
									return id;
								}
							}
							//管理学院员工的管理类
							class CollegeManager {
								//返回学院的所有员工
								public List<CollegeEmployee> getAllEmployee() {
									List<CollegeEmployee> list = new ArrayList<CollegeEmployee>();
									for (int i = 0; i < 10; i++) { //这里我们增加了10个员工到 list
										CollegeEmployee emp = new CollegeEmployee();
										emp.setId("学院员工id= " + i);
										list.add(emp);
									}
									return list;
								}								
								//输出学院员工的信息
								public void printEmployee() {
									//获取到学院员工
									List<CollegeEmployee> list1 = getAllEmployee();
									System.out.println("------------学院员工------------");
									for (CollegeEmployee e : list1) {
										System.out.println(e.getId());
									}
								}
							}
							//学校管理类
							class SchoolManager {
								//返回学校总部的员工
								public List<Employee> getAllEmployee() {
									List<Employee> list = new ArrayList<Employee>();									
									for (int i = 0; i < 5; i++) { //这里我们增加了5个员工到 list
										Employee emp = new Employee();
										emp.setId("学校总部员工id= " + i);
										list.add(emp);
									}
									return list;
								}
								//该方法完成输出学校总部和学院员工信息(id)
								void printAllEmployee(CollegeManager sub) {									
									//分析问题
									//1. 将输出学院的员工方法，封装到CollegeManager，符合最少知道原则
									sub.printEmployee();								
									//获取到学校总部员工
									List<Employee> list2 = this.getAllEmployee();
									System.out.println("------------学校总部员工------------");
									for (Employee e : list2) {
										System.out.println(e.getId());
									}
								}
							}						
				合成复用原则-尽量使用合成/聚合的方式[UML类图的关系]，而不是使用继承
				总结:针对接口编程，而不是实现编程；为松耦合而努力；			
			UML类图
				定义：统一建模语言，画图
				符号含义：Note:注释；Class：类，可以添加属性与方法；Interface：接口；Dependency：依赖（使用）；Association：关联；
					      Generalization：泛化（继承）；Realization：实现；Aggregation：聚合；Composite：组合
				分类：类图[核心]、用例图、时序图、活动图
				类图关系：依赖（使用）、关联、泛化（继承）、实现、聚合、组合
					依赖：一个类使用到了其他的类，就存在依赖；
					泛化（继承）:继承关系，依赖关系的特例；
					实现：实现关系，依赖关系的特例；
					关联：关联关系，依赖关系的特例；一对一，一对多[多对一]，多对多关系；具有导航性[单向/双向]
					聚合：表示整体与部分之间的关系，整体与部分可以分开，关联关系的特例；代码中体现：setter方法
					组合：表示整体与部分之间的关系，整体与部分可以不可分开[同生共死]，关联关系的特例；代码中体现：new 关键字；				
			设计模式：
				解决某类问题通用的解决方案
				类型：23种
					创建型模式：[对象的创建]，单例模式、抽象工厂模式、原型模式、建造者模式、工厂模式
					结构型模式：[软件结构]，适配器模式、桥接模式、装饰模式、组合模式、外观模式、享元模式、代理模式
					行为型模式：[方法]，模板方法模式、命令模式、访问者模式、迭代器模式、观察者模式、中介者模式、备忘录模式、解析器模式、状态模式、策略模式、职责链模式（责任链模式）			
			创建型模式：	
				单例模式：
					含义：某个类只存在一个对象实例；通过一个静态方法来获取这个对象实例；
					方式：8种
						饿汉式（静态变量）、饿汉式（静态代码块）-2种[核心思想是在类加载的时候创建类的实例]
						懒汉式（线程不安全）、懒汉式（线程安全，同步方法）、懒汉式（线程安全，同步代码块）-3种
						双重检查
						静态内部类
						枚举
					1、饿汉式（静态变量）：
					如：public class SingletonTest01 {
							public static void main(String[] args) {
								//测试
								Singleton instance1 = Singleton.getInstance();
								Singleton instance2 = Singleton.getInstance();
								System.out.println(instance1 == instance2); // true
								System.out.println("instance1.hashCode=" + instance1.hashCode());
								System.out.println("instance2.hashCode=" + instance2.hashCode());
							}
						}
						//饿汉式(静态变量)
						class Singleton {							
							//1. 构造器私有化, 外部能new
							private Singleton() {								
							}							
							//2.本类内部创建对象实例
							private final static Singleton instance = new Singleton();							
							//3. 提供一个公有的静态方法，返回实例对象
							public static Singleton getInstance() {
								return instance;
							}							
						}
					优点缺点：写法简单，类装载时完成实例化，避免线程同步问题；没有完成lazy loading的效果，如果没用过这个实例，会造成内存浪费；
				    2、饿汉式（静态代码块）：	
					如：public class SingletonTest02 {
							public static void main(String[] args) {
								//测试
								Singleton instance1 = Singleton.getInstance();
								Singleton instance2 = Singleton.getInstance();
								System.out.println(instance1 == instance2); // true
								System.out.println("instance1.hashCode=" + instance1.hashCode());
								System.out.println("instance2.hashCode=" + instance2.hashCode());
							}
						}
						//饿汉式(静态代码块)
						class Singleton {							
							//1. 构造器私有化, 外部能new
							private Singleton() {								
							}							
							//2.本类内部创建对象实例
							private  static Singleton instance;							
							static { // 在静态代码块中，创建单例对象
								instance = new Singleton();
							}							
							//3. 提供一个公有的静态方法，返回实例对象
							public static Singleton getInstance() {
								return instance;
							}
						}
					优点缺点：同饿汉式（静态变量）；
					3、懒汉式（线程不安全）：
					如：public class SingletonTest03 {
							public static void main(String[] args) {
								System.out.println("懒汉式1 ， 线程不安全~");
								Singleton instance1 = Singleton.getInstance();
								Singleton instance2 = Singleton.getInstance();
								System.out.println(instance1 == instance2); // true
								System.out.println("instance1.hashCode=" + instance1.hashCode());
								System.out.println("instance2.hashCode=" + instance2.hashCode());
							}
						}
						class Singleton {
							private static Singleton instance;							
							private Singleton() {}							
							//提供一个静态的公有方法，当使用到该方法时，才去创建 instance，即懒汉式
							public static Singleton getInstance() {
								if(instance == null) {
									instance = new Singleton();
								}
								return instance;
							}
						}
					优点缺点：单线程下起到lazy loading的效果，多线程下线程不安全，不推荐使用；
					4、懒汉式（线程安全，同步方法）：
					如：public class SingletonTest04 {
							public static void main(String[] args) {
								System.out.println("懒汉式2 ， 线程安全~");
								Singleton instance1 = Singleton.getInstance();
								Singleton instance2 = Singleton.getInstance();
								System.out.println(instance1 == instance2); // true
								System.out.println("instance1.hashCode=" + instance1.hashCode());
								System.out.println("instance2.hashCode=" + instance2.hashCode());
							}
						}
						// 懒汉式(线程安全，同步方法)
						class Singleton {
							private static Singleton instance;							
							private Singleton() {}							
							//提供一个静态的公有方法，加入同步处理的代码，解决线程安全问题
							public static synchronized Singleton getInstance() {
								if(instance == null) {
									instance = new Singleton();
								}
								return instance;
							}
						}
					优点缺点：解决线程安全问题，但synchronized关键字的使用效率太低，不推荐使用；
					5、懒汉式（线程安全，同步代码块）：
					如：
					// 懒汉式(线程安全，同步代码块)
						class Singleton {
							private static Singleton instance;							
							private Singleton() {}							
							//提供一个静态的公有方法
							public static Singleton getInstance() {
								//加入同步代码块
								if(instance == null) {
									synchronized(Singleton.class){
										instance = new Singleton();
									}
								}
								return instance;
							}
						}
					优点缺点：不能解决线程安全问题，可能会出现多个实例，不推荐使用；
					6、双重检查：[推荐使用]
					如：public class SingletonTest06 {
							public static void main(String[] args) {
								System.out.println("双重检查");
								Singleton instance1 = Singleton.getInstance();
								Singleton instance2 = Singleton.getInstance();
								System.out.println(instance1 == instance2); // true
								System.out.println("instance1.hashCode=" + instance1.hashCode());
								System.out.println("instance2.hashCode=" + instance2.hashCode());								
							}
						}
						class Singleton {
							private static volatile Singleton instance;//volatile变量可以立即刷新到主存						
							private Singleton() {}						
							//提供一个静态的公有方法，加入双重检查代码							
							public static synchronized Singleton getInstance() {
								if(instance == null) {
									synchronized (Singleton.class) {
										if(instance == null) {
											instance = new Singleton();
										}
									}									
								}
								return instance;
							}
						}
					优点缺点：解决线程安全问题, 同时解决懒加载问题；同时保证了效率, 推荐使用；
					7、静态内部类：[推荐使用]
					如：public class SingletonTest07 {
							public static void main(String[] args) {
								System.out.println("使用静态内部类完成单例模式");
								Singleton instance1 = Singleton.getInstance();
								Singleton instance2 = Singleton.getInstance();
								System.out.println(instance1 == instance2); // true
								System.out.println("instance1.hashCode=" + instance1.hashCode());
								System.out.println("instance2.hashCode=" + instance2.hashCode());								
								}
							}
							// 静态内部类完成， 推荐使用
							class Singleton {
							//构造器私有化
							private Singleton() {}
							//写一个静态内部类,该类中有一个静态属性 Singleton
							private static class SingletonInstance {
							//final在JVM底层可以得到优化
								private static final Singleton INSTANCE = new Singleton(); 
							}
							//提供一个静态的公有方法，直接返回SingletonInstance.INSTANCE
							public static synchronized Singleton getInstance() {//调用时才会类装载SingletonInstance，保证线程安全问题，此时别的线程无法进入；								
								return SingletonInstance.INSTANCE;
								}
							}
					优点缺点：采用类加载机制保证线程安全问题, 同时解决懒加载[延迟加载]问题；同时保证了效率, 推荐使用；
					8、枚举：[推荐使用]
					如：public class SingletonTest08 {
							public static void main(String[] args) {
								Singleton instance1 = Singleton.INSTANCE;
								Singleton instance2 = Singleton.INSTANCE;
								System.out.println(instance1 == instance2);								
								System.out.println(instance1.hashCode());
								System.out.println(instance2.hashCode());							
								instance.sayOK();
							}
						}
						//使用枚举，可以实现单例, 推荐
						enum Singleton {
							INSTANCE; //属性
							public void sayOK() {
								System.out.println("ok~");
							}
						}
					优点缺点：保证线程安全, 同时防止反序列化创建对象，推荐使用；
					JDK1.5运用：java.lang.Runtime类使用单例模式[饿汉式]；
					注意事项：
						保证系统内存只有一个对象，节约资源；通过静态方法获取对象；使用场景：频繁创建销毁的对象，重量级对象[消耗资源过多]，
						工具类、文件类、数据库类对象[session工厂、数据源]等；				
				工厂模式：
					1、简单工厂模式[静态工厂模式]：由一个工厂对象决定创建哪一种产品类的实例；定义一个创建对象的类[工厂类]，由这个类来封装实例化对象的行为；
					如：披萨订购示例：
					//抽象类
					public abstract class Pizza {
						protected String name; //名字						
						public abstract void prepare();	//准备原材料, 不同的披萨不一样，因此，我们做成抽象方法				
						public void bake() {
							System.out.println(name + " baking;");
						}
						public void cut() {
							System.out.println(name + " cutting;");
						}
						//打包
						public void box() {
							System.out.println(name + " boxing;");
						}
						public void setName(String name) {
							this.name = name;
						}
					}
					//实现类
					public class CheesePizza extends Pizza {
						@Override
						public void prepare() {
							System.out.println(" 给制作奶酪披萨 准备原材料 ");
						}
					}
					public class GreekPizza extends Pizza {
						@Override
						public void prepare() {
							System.out.println(" 给希腊披萨 准备原材料 ");
						}
					}
					public class PepperPizza extends Pizza {
						@Override
						public void prepare() {
							System.out.println(" 给胡椒披萨准备原材料 ");
						}
					}
					//订单[使用者]
					public class OrderPizza1 {
						//  传统方法：
						//  构造器
						public OrderPizza1() {
							Pizza pizza = null;
							String orderType; // 订购披萨的类型
							do {
								orderType = getType();
								if (orderType.equals("greek")) {
									pizza = new GreekPizza();
									pizza.setName(" 希腊披萨 ");
								} else if (orderType.equals("cheese")) {
									pizza = new CheesePizza();
									pizza.setName(" 奶酪披萨 ");
								} else if (orderType.equals("pepper")) {
									pizza = new PepperPizza();
									pizza.setName("胡椒披萨");
								} else {
									break;
								}
								//输出pizza制作过程
								pizza.prepare();
								pizza.bake();
								pizza.cut();
								pizza.box();								
							} while (true);
						}
						//定义一个简单工厂对象
						SimpleFactory simpleFactory;
						Pizza pizza = null;						
						//构造器
						public OrderPizza1(SimpleFactory simpleFactory) {
							setFactory(simpleFactory);
						}
						//利用UML类图的聚合关系
						public void setFactory(SimpleFactory simpleFactory) {
							String orderType = ""; //用户输入的							
							this.simpleFactory = simpleFactory; //设置简单工厂对象							
							do {
								orderType = getType(); 
								pizza = this.simpleFactory.createPizza1(orderType);	//接收实例化对象						
								//输出pizza
								if(pizza != null) { //订购成功
									pizza.prepare();
									pizza.bake();
									pizza.cut();
									pizza.box();
								} else {
									System.out.println(" 订购披萨失败 ");
									break;
								}
							}while(true);
						}						
						// 写一个方法，可以获取客户希望订购的披萨种类
						private String getType() {
							try {
								BufferedReader strin = new BufferedReader(new InputStreamReader(System.in));
								System.out.println("input pizza 种类:");
								String str = strin.readLine();
								return str;
							} catch (IOException e) {
								e.printStackTrace();
								return "";
							}
						}
					}
					//订单[使用者]
					public class OrderPizza2 {
						Pizza pizza = null;
						String orderType = "";
						// 构造器
						public OrderPizza2() {							
							do {
								orderType = getType();
								pizza = SimpleFactory.createPizza2(orderType);//调用静态工厂方法
								// 输出pizza
								if (pizza != null) { // 订购成功
									pizza.prepare();
									pizza.bake();
									pizza.cut();
									pizza.box();
								} else {
									System.out.println(" 订购披萨失败 ");
									break;
								}
							} while (true);
						}
						// 写一个方法，可以获取客户希望订购的披萨种类
						private String getType() {
							try {
								BufferedReader strin = new BufferedReader(new InputStreamReader(System.in));
								System.out.println("input pizza 种类:");
								String str = strin.readLine();
								return str;
							} catch (IOException e) {
								e.printStackTrace();
								return "";
							}
						}
					}
					//简单工厂类
					public class SimpleFactory {
						//添加orderType返回对应的Pizza对象，实例化过程交给工厂
						public Pizza createPizza1(String orderType) {
							Pizza pizza = null;
							System.out.println("使用简单工厂模式");
							if (orderType.equals("greek")) {
								pizza = new GreekPizza();
								pizza.setName(" 希腊披萨 ");
							} else if (orderType.equals("cheese")) {
								pizza = new CheesePizza();
								pizza.setName(" 奶酪披萨 ");
							} else if (orderType.equals("pepper")) {
								pizza = new PepperPizza();
								pizza.setName("胡椒披萨");
							}
							
							return pizza;
						}						
						//简单工厂模式也叫静态工厂模式 						
						public static Pizza createPizza2(String orderType) {
							Pizza pizza = null;
							System.out.println("使用简单工厂模式");
							if (orderType.equals("greek")) {
								pizza = new GreekPizza();
								pizza.setName(" 希腊披萨 ");
							} else if (orderType.equals("cheese")) {
								pizza = new CheesePizza();
								pizza.setName(" 奶酪披萨 ");
							} else if (orderType.equals("pepper")) {
								pizza = new PepperPizza();
								pizza.setName("胡椒披萨");
							}							
							return pizza;
						}
					}
					//客户端，发出订购
					public class PizzaStore {
						public static void main(String[] args) {
							//传统方式
							//new OrderPizza1();							
							//使用简单工厂模式
							//new OrderPizza1(new SimpleFactory());
							//System.out.println("~~退出程序~~");							
							new OrderPizza2();
						}
					}
					结论：当出现一种新的披萨类型只需修改工厂方法，其他地方都不需要改动；
					2、工厂方法模式：
					   含义：定义创建对象的抽象方法[抽象类]，由子类决定要实例化的类，将对象的实例化推迟到了子类。
					   如：披萨订购示例[添加了地区的概念]：
					   //基础类
					   public abstract class Pizza {
							protected String name; //名字
							//准备原材料, 不同的披萨不一样，因此，我们做成抽象方法
							public abstract void prepare();							
							public void bake() {
								System.out.println(name + " baking;");
							}
							public void cut() {
								System.out.println(name + " cutting;");
							}
							//打包
							public void box() {
								System.out.println(name + " boxing;");
							}
							public void setName(String name) {
								this.name = name;
							}
						}
					   public class BJCheesePizza extends Pizza {
							@Override
							public void prepare() {
								setName("北京的奶酪pizza");
								System.out.println(" 北京的奶酪pizza 准备原材料");
							}
						}
					   public class BJPepperPizza extends Pizza {
							@Override
							public void prepare() {
								setName("北京的胡椒pizza");
								System.out.println(" 北京的胡椒pizza 准备原材料");
							}
						}
					   public class LDCheesePizza extends Pizza{
							@Override
							public void prepare() {
								setName("伦敦的奶酪pizza");
								System.out.println(" 伦敦的奶酪pizza 准备原材料");
							}
						}
					   public class LDPepperPizza extends Pizza{
							@Override
							public void prepare() {
								setName("伦敦的胡椒pizza");
								System.out.println(" 伦敦的胡椒pizza 准备原材料");
							}
						}
					   //使用者
					   public abstract class OrderPizza {
							//定义一个抽象方法，createPizza , 让各个工厂子类自己实现
							abstract Pizza createPizza(String orderType);							
							// 构造器
							public OrderPizza() {
								Pizza pizza = null;
								String orderType; // 订购披萨的类型
								do {
									orderType = getType();
									pizza = createPizza(orderType); //抽象方法，由工厂子类完成
									//输出pizza 制作过程
									pizza.prepare();
									pizza.bake();
									pizza.cut();
									pizza.box();
									
								} while (true);
							}							
							// 写一个方法，可以获取客户希望订购的披萨种类
							private String getType() {
								try {
									BufferedReader strin = new BufferedReader(new InputStreamReader(System.in));
									System.out.println("input pizza 种类:");
									String str = strin.readLine();
									return str;
								} catch (IOException e) {
									e.printStackTrace();
									return "";
								}
							}
						}
					   public class BJOrderPizza extends OrderPizza {//对象的实例化推迟到了子类来实现							
							@Override
							Pizza createPizza(String orderType) {							
								Pizza pizza = null;
								if(orderType.equals("cheese")) {
									pizza = new BJCheesePizza();
								} else if (orderType.equals("pepper")) {
									pizza = new BJPepperPizza();
								}
								return pizza;
							}
						}
					   public class LDOrderPizza extends OrderPizza {							
							@Override
							Pizza createPizza(String orderType) {							
								Pizza pizza = null;
								if(orderType.equals("cheese")) {
									pizza = new LDCheesePizza();
								} else if (orderType.equals("pepper")) {
									pizza = new LDPepperPizza();
								}
								return pizza;
							}
						}
					   //客户端使用
					   public class PizzaStore {
							public static void main(String[] args) {
								String loc = "bj";
								if (loc.equals("bj")) {
									//创建北京口味的各种Pizza
									new BJOrderPizza();
								} else {
									//创建伦敦口味的各种Pizza
									new LDOrderPizza();
								}
							}
						}					   
					3、抽象工厂模式：
					   含义：是简单工厂模式与工厂方法模式的整合，对简单工厂模式的进一步抽象，将工厂分为两层：抽象工厂[是一个接口]和实现的子类工厂[工厂族]。
					   如：披萨订购示例[添加了地区的概念]：
					   //基础类，同工厂方法的基础类
					   //使用者
					    public interface AbsFactory {//一个抽象工厂模式的抽象层(接口)
							//让下面的工厂子类来 具体实现
							public Pizza createPizza(String orderType);
						}
						public class BJFactory implements AbsFactory {//工厂子类
							@Override
							public Pizza createPizza(String orderType) {
								System.out.println("~使用的是抽象工厂模式~");
								Pizza pizza = null;
								if(orderType.equals("cheese")) {
									pizza = new BJCheesePizza();
								} else if (orderType.equals("pepper")){
									pizza = new BJPepperPizza();
								}
								return pizza;
							}
						}
						public class LDFactory implements AbsFactory {
							@Override
							public Pizza createPizza(String orderType) {
								System.out.println("~使用的是抽象工厂模式~");
								Pizza pizza = null;
								if (orderType.equals("cheese")) {
									pizza = new LDCheesePizza();
								} else if (orderType.equals("pepper")) {
									pizza = new LDPepperPizza();
								}
								return pizza;
							}
						}
						public class OrderPizza {//使用者，使用UML类图的聚合关系
							AbsFactory factory;
							// 构造器
							public OrderPizza(AbsFactory factory) {
								setFactory(factory);
							}
							private void setFactory(AbsFactory factory) {
								Pizza pizza = null;
								String orderType = ""; // 用户输入
								this.factory = factory;
								do {
									orderType = getType();
									// factory 可能是北京的工厂子类，也可能是伦敦的工厂子类
									pizza = factory.createPizza(orderType);
									if (pizza != null) { // 订购ok
										pizza.prepare();
										pizza.bake();
										pizza.cut();
										pizza.box();
									} else {
										System.out.println("订购失败");
										break;
									}
								} while (true);
							}
							// 写一个方法，可以获取客户希望订购的披萨种类
							private String getType() {
								try {
									BufferedReader strin = new BufferedReader(new InputStreamReader(System.in));
									System.out.println("input pizza 种类:");
									String str = strin.readLine();
									return str;
								} catch (IOException e) {
									e.printStackTrace();
									return "";
								}
							}
						}
					    //客户端
						public class PizzaStore {
							public static void main(String[] args) {
								//new OrderPizza(new BJFactory());
								new OrderPizza(new LDFactory());
							}
						}
					源码分析：
					JDK中Calendar类使用到了简单工厂模式
					小结：将实例化对象的代码抽取出来，放在一个类[工厂类]中统一维护与管理，以达到与主项目的解耦，增加扩展性；
						  设计模式的依赖抽象原则；创建对象实例的时候，new的动作放在工厂类的方法中；继承抽象类或实现接口；不要覆盖基类已经实现的方法；				
				原型模式：[Prototype模式]
					含义：用原型实例指定创建对象，通过拷贝原型来创建新的对象。核心：对象.clone()；
					UML类图解析：
						Prototype：原型类，声明克隆接口
						ConcretePrototype：具体的原型类，实现克隆操作
						Client：原型类，让原型对象实例克隆自己，从而创建新的对象（属性一样）
					如[克隆羊问题]：public class Sheep implements Cloneable {//实现Cloneable接口
									private String name;
									private int age;
									private String color;
									private String address = "蒙古羊";//默认属性
									public Sheep friend; //是对象, 克隆是会如何处理
									public Sheep(String name, int age, String color) {
										super();
										this.name = name;
										this.age = age;
										this.color = color;
									}
									public String getName() {
										return name;
									}
									public void setName(String name) {
										this.name = name;
									}
									public int getAge() {
										return age;
									}
									public void setAge(int age) {
										this.age = age;
									}
									public String getColor() {
										return color;
									}
									public void setColor(String color) {
										this.color = color;
									}																											
									@Override
									public String toString() {
										return "Sheep [name=" + name + ", age=" + age + ", color=" + color + ", address=" + address + "]";
									}
									//克隆该实例，使用默认的clone方法来完成
									@Override
									protected Object clone()  {										
										Sheep sheep = null;
										try {
											sheep = (Sheep)super.clone();
										} catch (Exception e) {
											System.out.println(e.getMessage());
										}
										return sheep;
									}																		
								}
							public class Client {
								public static void main(String[] args) {
									System.out.println("原型模式完成对象的创建");
									Sheep sheep1 = new Sheep("tom", 1, "白色");
									sheep1.friend = new Sheep("jack", 2, "黑色");
									Sheep sheep2 = (Sheep)sheep1.clone(); //克隆
									Sheep sheep3 = (Sheep)sheep1.clone(); //克隆
									Sheep sheep4 = (Sheep)sheep1.clone(); //克隆
									Sheep sheep5 = (Sheep)sheep1.clone(); //克隆									
									System.out.println("sheep2 =" + sheep2 + "sheep2.friend=" + sheep2.friend.hashCode());//结果hashCode值一样，是浅拷贝！
									System.out.println("sheep3 =" + sheep3 + "sheep3.friend=" + sheep3.friend.hashCode());
									System.out.println("sheep4 =" + sheep4 + "sheep4.friend=" + sheep4.friend.hashCode());
									System.out.println("sheep5 =" + sheep5 + "sheep5.friend=" + sheep5.friend.hashCode());
								}
							}
					源码分析：Spring源码中Bean对象的创建；在beans.xml中，<bean id="" class="com.**.bean.Monster" scope="prototype"/>
					浅拷贝与深拷贝[默认是浅拷贝]：
						浅拷贝：成员变量数据类型是基本数据类型，拷贝进行值传递；成员变量数据类型是引用数据类型，拷贝进行址传递[内存地址]；
						深拷贝：整个对象进行拷贝；方式：2种，一种是利用clone()方法，另一种是利用对象序列化的方式；
						如：[深拷贝]
						//基础类
						public class DeepCloneableTarget implements Serializable, Cloneable {//实现Serializable,Cloneable接口					
							private static final long serialVersionUID = 1L;
							private String cloneName;//属性名
							private String cloneClass;
							//构造器
							public DeepCloneableTarget(String cloneName, String cloneClass) {
								this.cloneName = cloneName;
								this.cloneClass = cloneClass;
							}
							//因为该类的属性，都是String，因此我们这里使用默认的clone完成即可
							@Override
							protected Object clone() throws CloneNotSupportedException {
								return super.clone();
							}
						}
						public class DeepProtoType implements Serializable, Cloneable{							
							public String name; //String 属性
							public DeepCloneableTarget deepCloneableTarget;//引用类型，对象
							public DeepProtoType() {
								super();
							}														
							//深拷贝 - 方式 1 使用clone 方法
							@Override
							protected Object clone() throws CloneNotSupportedException {								
								Object deep = null;
								//这里完成对基本数据类型(属性)和String的克隆
								deep = super.clone(); 
								//对引用类型的属性，进行单独处理
								DeepProtoType deepProtoType = (DeepProtoType)deep;
								deepProtoType.deepCloneableTarget  = (DeepCloneableTarget)deepCloneableTarget.clone();								
								return deepProtoType;
							}							
							//深拷贝 - 方式2 通过对象的序列化实现 (推荐)							
							public Object deepClone() {								
								//创建流对象
								ByteArrayOutputStream bos = null;
								ObjectOutputStream oos = null;
								ByteArrayInputStream bis = null;
								ObjectInputStream ois = null;								
								try {									
									//序列化
									bos = new ByteArrayOutputStream();
									oos = new ObjectOutputStream(bos);//将字节数组输出流转化为对象输出流
									oos.writeObject(this); //当前这个对象以对象流的方式输出									
									//反序列化，出[写]->入[读]
									bis = new ByteArrayInputStream(bos.toByteArray());
									ois = new ObjectInputStream(bis);
									DeepProtoType copyObj = (DeepProtoType)ois.readObject();									
									return copyObj;									
								} catch (Exception e1) {
									e.printStackTrace(e1.getMessage());
									return null;
								} finally {
									//关闭流
									try {
										bos.close();
										oos.close();
										bis.close();
										ois.close();
									} catch (Exception e2) {
										System.out.println(e2.getMessage());
									}
								}								
							}							
						}
						//客户端
						public class Client {
							public static void main(String[] args) throws Exception {
								DeepProtoType p1 = new DeepProtoType();
								p1.name = "宋江";
								p1.deepCloneableTarget = new DeepCloneableTarget("大牛", "小牛");							
								//方式1 完成深拷贝								
						//		DeepProtoType p2 = (DeepProtoType) p1.clone();	
						//		System.out.println("p1.name=" + p1.name + "p1.deepCloneableTarget=" + p1.deepCloneableTarget.hashCode());//结果，属性值相同，hashCode值不同
						//		System.out.println("p2.name=" + p2.name + "p2.deepCloneableTarget=" + p2.deepCloneableTarget.hashCode());							
								//方式2 完成深拷贝
								DeepProtoType p2 = (DeepProtoType) p.deepClone();								
								System.out.println("p1.name=" + p1.name + "p1.deepCloneableTarget=" + p1.deepCloneableTarget.hashCode());
								System.out.println("p2.name=" + p2.name + "p2.deepCloneableTarget=" + p2.deepCloneableTarget.hashCode());							
							}
						}
					小结：简化对象的创建过程，提高效率；动态的获取对象的运行状态；缺点:每一个类必须配备一个克隆方法；
				建造者模式[生产器模式]：
					含义：将产品与产品的建造过程解耦->建造者模式！角色：Product:产品，Builder:抽象建造者，往往是接口或抽象类，展现建造流程，组合Product；ConcreteBuilder：具体建造者，实现接口或继承抽象类，具体实现建造流程，
					      Director：指挥者，聚合Builder，隔离客户与产品对象生产流程，负责控制产品的生产过程；
					如：[盖房子案例]
					//产品->Product
					public class House {
						private String baise;//属性，地基
						private String wall;//墙面
						private String roofed;//屋顶
						public String getBaise() {
							return baise;
						}
						public void setBaise(String baise) {
							this.baise = baise;
						}
						public String getWall() {
							return wall;
						}
						public void setWall(String wall) {
							this.wall = wall;
						}
						public String getRoofed() {
							return roofed;
						}
						public void setRoofed(String roofed) {
							this.roofed = roofed;
						}						
					}
					// 抽象的建造者->Builder
					public abstract class HouseBuilder {
						protected House house = new House();//使用UML类图的组合关系					
						//将建造的流程写好, 抽象的方法，流程与产品解耦分离
						public abstract void buildBasic();
						public abstract void buildWalls();
						public abstract void roofed();						
						//建造房子好，将产品(房子) 返回
						public House buildHouse() {
							return house;
						}						
					}
					//子类继承[泛化过程]，普通房子->ConcreteBuilder
					public class CommonHouse extends HouseBuilder {
						@Override
						public void buildBasic() {
							System.out.println("普通房子打地基5米");
						}
						@Override
						public void buildWalls() {
							System.out.println("普通房子砌墙10cm");
						}
						@Override
						public void roofed() {
							System.out.println("普通房子屋顶");
						}
					}
					//子类继承[泛化过程]，高楼->ConcreteBuilder
					public class HighBuilding extends HouseBuilder {
						@Override
						public void buildBasic() {
							System.out.println("高楼的打地基100米");
						}
						@Override
						public void buildWalls() {
							System.out.println("高楼的砌墙20cm");
						}
						@Override
						public void roofed() {
							System.out.println("高楼的透明屋顶");
						}
					}
					//指挥者->Dirctor，这里去指挥制作流程，返回产品
					public class HouseDirector {						
						HouseBuilder houseBuilder = null;//采用UML类图的聚合关系
						//构造器传入houseBuilder
						public HouseDirector(HouseBuilder houseBuilder) {
							this.houseBuilder = houseBuilder;
						}
						//通过setter 传入 houseBuilder
						public void setHouseBuilder(HouseBuilder houseBuilder) {
							this.houseBuilder = houseBuilder;
						}						
						//如何处理建造房子的流程，交给指挥者
						public House constructHouse() {
							houseBuilder.buildBasic();
							houseBuilder.buildWalls();
							houseBuilder.roofed();
							return houseBuilder.buildHouse();
						}		
					}
					//客户端
					public class Client {
						public static void main(String[] args) {							
							//盖普通房子
							CommonHouse commonHouse = new CommonHouse();
							//准备创建房子的指挥者
							HouseDirector houseDirector = new HouseDirector(commonHouse);							
							//完成盖房子，返回产品(普通房子)
							House house = houseDirector.constructHouse();														
							System.out.println("--------------------------");
							//盖高楼
							HighBuilding highBuilding = new HighBuilding();
							//重置抽象建造者
							houseDirector.setHouseBuilder(highBuilding);
							//完成盖房子，返回产品(高楼)
							houseDirector.constructHouse();																					
						}
					}
					源码分析：JDK中java.lang.StringBuilder中使用到了建造者模式！
				    小结：产品与产品创建过程解耦；每一种具体的建造者相互独立；可以更加细腻的控制产品的建造过程[指挥者]；符合OCP原则；
						  与抽象工厂模式区别：前者强调的是产品组装建造流程，后者强调的是生产出产品；			
			结构型模式[软件结构]：		
				适配器模式：
				含义：将某类的接口转化成客户端期待的另一种接口表示，目的做兼容。目标[Target/dst] <-- 适配器[Adapter] <-- 被适配者[Source/src]
				分类：类适配器模式、对象适配器模式、接口适配器模式
				类适配器模式：
					如：[充电器案例]
					//被适配的类，Source
					public class Voltage220V {
						//输出220V的电压
						public int output220V() {
							int src = 220;
							System.out.println("电压=" + src + "伏");
							return src;
						}
					}
					//适配接口
					public interface IVoltage5V {
						public int output5V();
					}
					//适配器类，Adapter
					public class VoltageAdapter extends Voltage220V implements IVoltage5V {
						@Override
						public int output5V() {
							//获取到220V电压
							int srcV = output220V();
							int dstV = srcV / 44 ; //转成 5v
							return dstV;//Target
						}
					}
					public class Phone {
						//充电，依赖关系
						public void charging(IVoltage5V iVoltage5V) {
							if(iVoltage5V.output5V() == 5) {
								System.out.println("电压为5V, 可以充电~~");
							} else if (iVoltage5V.output5V() > 5) {
								System.out.println("电压大于5V, 不能充电~~");
							}
						}
					}
					//客户端
					public class Client {
						public static void main(String[] args) {
							System.out.println(" === 类适配器模式 ====");
							Phone phone = new Phone();
							phone.charging(new VoltageAdapter());
						}
					}
				优点缺点：adapter继承了src，增加了耦合，暴露了src的方法，增加成本，但同时可以根据需求重写，使灵活性增强。	
				对象配器模式[常用]：
					含义：对类适配器的改进，adapter不在继承了src，而是聚合，使用UML类图的关联关系来代替，符合"合成复用"原则，使得成本降低。
					优化部分：
					//适配器类
					public class VoltageAdapter  implements IVoltage5V {//不在使用继承关系
						private Voltage220V voltage220V; // 关联关系-聚合关系												
						//通过构造器，传入一个 Voltage220V 实例
						public VoltageAdapter(Voltage220V voltage220v) {							
							this.voltage220V = voltage220v;
						}
						@Override
						public int output5V() {							
							int dst = 0;
							if(null != voltage220V) {
								int src = this.voltage220V.output220V();//获取220V 电压
								System.out.println("使用对象适配器，进行适配~~");
								dst = src / 44;
								System.out.println("适配完成，输出的电压为=" + dst);
							}							
							return dst;						
						}
					}
					//客户端
					public class Client {
						public static void main(String[] args) {
							System.out.println(" === 对象适配器模式 ====");
							Phone phone = new Phone();
							phone.charging(new VoltageAdapter(new Voltage220V()));
						}
					}
				接口适配器：
					含义：又称适配器模式或缺省适配器模式，设计一个抽象类实现接口里面的所有方法[默认实现，空方法]，然后该抽象类子类[匿名内部类]有选择性的覆盖某些方法来实现
					如：
					//接口，被适配者->src
					public interface Interface {
						public void m1();
						public void m2();
						public void m3();
						public void m4();
					}
					//抽象类，适配器
					public abstract class AbsAdapter implements Interface {
						//默认实现
						public void m1() {
						}
						public void m2() {
						}
						public void m3() {
						}
						public void m4() {
						}
					}
					//客户端使用
					public class Client {
						public static void main(String[] args) {	
							AbsAdapter absAdapter = new AbsAdapter() {
								//只需要去覆盖需要使用接口方法
								@Override
								public void m1() {
									System.out.println("使用了m1的方法");
								}
							};							
							absAdapter.m1();
						}
					}
					源码分析：在SpringMVC框架中运用到了适配器模式，如：HandleAdapter类；
					//核心思想->src					  
					public interface Controller {//多种Controller实现
					}
					class HttpController implements Controller {
						public void doHttpHandler() {
							System.out.println("http...");
						}
					}
					class SimpleController implements Controller {
						public void doSimplerHandler() {
							System.out.println("simple...");
						}
					}
					class AnnotationController implements Controller {
						public void doAnnotationHandler() {
							System.out.println("annotation...");
						}
					}
					//适配器接口->src	
					public interface HandlerAdapter {
						public boolean supports(Object handler);
						public void handle(Object handler);
					}
					//多种适配器类
					class SimpleHandlerAdapter implements HandlerAdapter {
						public void handle(Object handler) {
							((SimpleController) handler).doSimplerHandler();
						}
						public boolean supports(Object handler) {
							return (handler instanceof SimpleController);
						}
					}
					class HttpHandlerAdapter implements HandlerAdapter {
						public void handle(Object handler) {
							((HttpController) handler).doHttpHandler();
						}
						public boolean supports(Object handler) {
							return (handler instanceof HttpController);
						}
					}
					class AnnotationHandlerAdapter implements HandlerAdapter {
						public void handle(Object handler) {
							((AnnotationController) handler).doAnnotationHandler();
						}
						public boolean supports(Object handler) {
							return (handler instanceof AnnotationController);
						}
					}
					//使用者
					public class DispatchServlet {
						public static List<HandlerAdapter> handlerAdapters = new ArrayList<HandlerAdapter>();//依赖组合关系
						public DispatchServlet() {
							handlerAdapters.add(new AnnotationHandlerAdapter());
							handlerAdapters.add(new HttpHandlerAdapter());
							handlerAdapters.add(new SimpleHandlerAdapter());
						}
						public void doDispatch() {
							// 此处模拟SpringMVC从request取handler的对象，适配器可以获取到希望的Controller
							   HttpController controller = new HttpController();
							// AnnotationController controller = new AnnotationController();
							// SimpleController controller = new SimpleController();
							// 得到对应适配器
							HandlerAdapter adapter = getHandler(controller);
							// 通过适配器执行对应的controller对应方法
							adapter.handle(controller);
						}
						public HandlerAdapter getHandler(Controller controller) {
							//遍历：根据得到的controller(handler), 返回对应适配器
							for (HandlerAdapter adapter : this.handlerAdapters) {
								if (adapter.supports(controller)) {
									return adapter;
								}
							}
							return null;
						}
						public static void main(String[] args) {
							new DispatchServlet().doDispatch(); // http...
						}
					}
					小结：三种适配器根据src以怎样的形式传给Adapter；目的是做接口的兼容；
				桥接模式：
					含义：将抽象[抽象类]与实现[接口和实现类]放在不同的层次中，它是基于类最小设计原则，防止类爆炸；
					原理：
						Client类：调用者，客户端；
						Abstraction抽象类：维护了Implementor/以及实现类；聚合了接口，是调用者与被调用者关系；
						RefinedAbstraction：是Abstraction抽象类子类；
						Implementor：实现类接口；
						ConcreteImplementorA/B：具体实现类；
					如：[手机操作案例]
					//接口
					public interface Brand {//品牌
						void open();//开机
						void close();//关机
						void call();//打电话
					}
					//实现子类
					public class Vivo implements Brand {
						@Override
						public void open() {
							System.out.println("Vivo手机开机");
						}
						@Override
						public void close() {
							System.out.println("Vivo手机关机");
						}
						@Override
						public void call() {
							System.out.println("Vivo手机打电话");
						}
					}
					public class XiaoMi implements Brand {
						@Override
						public void open() {
							System.out.println("小米手机开机");
						}
						@Override
						public void close() {
							System.out.println("小米手机关机");
						}
						@Override
						public void call() {
							System.out.println("小米手机打电话");
						}
					}
					//抽象类
					public abstract class Phone {						
						//利用UML类图聚合关系，组合品牌
						private Brand brand;
						//构造器
						public Phone(Brand brand) {
							super();
							this.brand = brand;
						}					
						protected void open() {
							this.brand.open();
						}
						protected void close() {
							brand.close();
						}
						protected void call() {
							brand.call();
						}						
					}
					//折叠式手机类，继承抽象类Phone
					public class FoldedPhone extends Phone {
						//构造器
						public FoldedPhone(Brand brand) {
							super(brand);
						}						
						public void open() {
							super.open();
							System.out.println("折叠样式手机");
						}						
						public void close() {
							super.close();
							System.out.println("折叠样式手机");
						}						
						public void call() {
							super.call();
							System.out.println("折叠样式手机");
						}
					}
					//直立式手机类，继承抽象类Phone
					public class UpRightPhone extends Phone {					
						//构造器
						public UpRightPhone(Brand brand) {
							super(brand);
						}						
						public void open() {
							super.open();
							System.out.println("直立样式手机");
						}						
						public void close() {
							super.close();
							System.out.println("直立样式手机");
						}						
						public void call() {
							super.call();
							System.out.println("直立样式手机");
						}
					}
					//客户端，依赖Phone与Brand，抽象与实现
					public class Client {
						public static void main(String[] args) {							
							//获取折叠式手机 (样式 + 品牌 )						
							Phone phone1 = new FoldedPhone(new XiaoMi());							
							phone1.open();
							phone1.call();
							phone1.close();							
							System.out.println("=======================");							
							Phone phone2 = new FoldedPhone(new Vivo());							
							phone2.open();
							phone2.call();
							phone2.close();							
							System.out.println("==============");
							//直立式手机 (样式 + 品牌 )	
							UpRightPhone phone3 = new UpRightPhone(new XiaoMi());							
							phone3.open();
							phone3.call();
							phone3.close();							
							System.out.println("==============");							
							UpRightPhone phone4 = new UpRightPhone(new Vivo());							
							phone4.open();
							phone4.call();
							phone4.close();
						}
					}
					源码分析：JDBC源码中使用到了桥接模式：
						其中DriverManger充当的是抽象类的角色，而Connection接口充当的是实现角色[子类/子接口有MysqlConnection、OracleConnection等具体实现子类]；
						客户端直接依赖DriverManger；
					小结：实现了抽象与实现的分离；替代了多层继承问题，增加系统的灵活性；替代了继承，节约成本；缺点：对系统的设计与理解[维度]难度较大；
					应用场景：JDBC驱动，银行转账系统；消息管理等				
				装饰者模式：
					含义：动态的将新功能附加到对象上，比继承更有弹性，符合开闭原则[OCP原则]，防止类爆炸，生活中的物流包裹就是一个典型的生活案列；
					原理：
					   Component ：抽象类
					   ConcreteComponent：子类，继承Component，具体的主体；中间可以适当添加缓冲层；
					   Decorator：装饰者[装饰类]，继承Component，组合Component
					如：[星巴克咖啡订单案例，单品+种类]
						//抽象类，饮料
						public abstract class Drink {
							public String des; // 描述
							private float price = 0.0f;
							public String getDes() {
								return des;
							}
							public void setDes(String des) {
								this.des = des;
							}
							public float getPrice() {
								return price;
							}
							public void setPrice(float price) {
								this.price = price;
							}							
							//计算费用的抽象方法，子类来实现
							public abstract float cost();							
						}
						//缓冲层
						public class Coffee  extends Drink {
							@Override
							public float cost() {
								return super.getPrice();
							}							
						}
						//实现子类
						public class Espresso extends Coffee {							
							public Espresso() {
								setDes("意大利咖啡");
								setPrice(6.0f);
							}
						}
						public class LongBlack extends Coffee {
							public LongBlack() {
								setDes("longblack");
								setPrice(5.0f);
							}
						}
						public class ShortBlack extends Coffee{						
							public ShortBlack() {
								setDes("shortblack");
								setPrice(4.0f);
							}
						}
						public class DeCaf extends Coffee {
							public DeCaf() {
								setDes("无因咖啡");
								setPrice(1.0f);
							}
						}
						//装饰类（种类），继承+聚合
						public class Decorator extends Drink {
							private Drink obj;							
							public Decorator(Drink obj) { //聚合
								this.obj = obj;
							}							
							@Override
							public float cost() {
								// getPrice 自己价格
								return super.getPrice() + obj.cost();
							}							
							@Override
							public String getDes() {
								// obj.getDes() 输出被装饰者的信息
								return des + " " + getPrice() + " && " + obj.getDes();
							}														
						}
						//子类
						public class Chocolate extends Decorator {
							public Chocolate(Drink obj) {
								super(obj);
								setDes("巧克力");
								setPrice(3.0f); // 调味品的价格
							}
						}
						public class Milk extends Decorator {
							public Milk(Drink obj) {
								super(obj);
								setDes("牛奶");
								setPrice(2.0f); 
							}
						}
						public class Soy extends Decorator{
							public Soy(Drink obj) {
								super(obj);
								setDes("豆浆");
								setPrice(1.5f);
							}
						}
						//客户端
						public class CoffeeBar {
							public static void main(String[] args) {
								// 装饰者模式下的订单：2份巧克力+一份牛奶的LongBlack
								// 1. 点一份 LongBlack
								Drink order1 = new LongBlack();
								System.out.println("费用=" + order1.cost());
								System.out.println("描述=" + order1.getDes());
								// 2. order 加入一份牛奶，装饰迭代
								order1 = new Milk(order1);
								System.out.println("order1 加入一份牛奶 费用 =" + order1.cost());
								System.out.println("order1 加入一份牛奶 描述 =" + order1.getDes());
								// 3. order 加入一份巧克力，装饰迭代
								order1 = new Chocolate(order1);
								System.out.println("order1 加入一份牛奶 加入一份巧克力 费用 =" + order1.cost());
								System.out.println("order1 加入一份牛奶 加入一份巧克力 描述 =" + order1.getDes());
								// 3. order 加入一份巧克力，装饰迭代
								order1 = new Chocolate(order1);
								System.out.println("order1 加入一份牛奶 加入2份巧克力 费用 =" + order1.cost());
								System.out.println("order1 加入一份牛奶 加入2份巧克力 描述 =" + order1.getDes());							
								System.out.println("===========================");								
								Drink order2 = new DeCaf();								
								System.out.println("order2 无因咖啡 费用 =" + order2.cost());
								System.out.println("order2 无因咖啡 描述 =" + order2.getDes());								
								order2 = new Milk(order2);								
								System.out.println("order2 无因咖啡 加入一份牛奶 费用 =" + order2.cost());
								System.out.println("order2 无因咖啡 加入一份牛奶 描述 =" + order2.getDes());							
							}
						}
					源码分析：
						JDK中IO结构，FilterInputStream就是一个装饰者而InputStream就是一个被装饰者[抽象类]；FileInputStream是被装饰者的一个子类，DataInputStream是装饰者的一个子类；						
				组合模式：
					含义：部分与整体模式，用树型结构来表示对象与对象组的关系
					原理：
						Component：抽象层，可是接口或抽象类，实现所有类共有的接口默认行为[添加、删除、修改等]，用于访问管理Component的子部件；
						Leaf：叶子节点，下面没有子节点；
						Composite：组合Component，非叶子节点，用于存储子部件，实现Component接口的相关操作，比如：添加、删除等；
					适用场景：组织结构[树形结构]
					如：[学校院系展示案例]
						//抽象层，抽象类
						public abstract class OrganizationComponent {
							private String name; //名字
							private String des; //说明							
							protected  void add(OrganizationComponent organizationComponent) {
								//默认实现
								throw new UnsupportedOperationException();
							}							
							protected  void remove(OrganizationComponent organizationComponent) {
								//默认实现
								throw new UnsupportedOperationException();
							}
							//构造器
							public OrganizationComponent(String name, String des) {
								super();
								this.name = name;
								this.des = des;
							}
							public String getName() {
								return name;
							}
							public void setName(String name) {
								this.name = name;
							}
							public String getDes() {
								return des;
							}
							public void setDes(String des) {
								this.des = des;
							}						
							//方法print，做成抽象的，子类都需要实现
							protected abstract void print();														
						}
						//University就是Composite，可以管理College，即大学管理学院
						public class University extends OrganizationComponent {
							List<OrganizationComponent> organizationComponents = new ArrayList<OrganizationComponent>();//组合OrganizationComponent
							// 构造器
							public University(String name, String des) {
								super(name, des);
							}
							// 重写add
							@Override
							protected void add(OrganizationComponent organizationComponent) {
								organizationComponents.add(organizationComponent);
							}
							// 重写remove
							@Override
							protected void remove(OrganizationComponent organizationComponent) {
								organizationComponents.remove(organizationComponent);
							}
							@Override
							public String getName() {
								return super.getName();
							}

							@Override
							public String getDes() {
								return super.getDes();
							}
							// print方法，就是输出University包含的学院
							@Override
							protected void print() {
								System.out.println("--------------" + getName() + "--------------");
								//遍历organizationComponents 
								for (OrganizationComponent organizationComponent : organizationComponents) {
									organizationComponent.print();
								}
							}
						}
						//学院，管理系[专业]
						public class College extends OrganizationComponent {
							//List中存放的Department
							List<OrganizationComponent> organizationComponents = new ArrayList<OrganizationComponent>();
							// 构造器
							public College(String name, String des) {
								super(name, des);
							}
							// 重写add
							@Override
							protected void add(OrganizationComponent organizationComponent) {
								//将来实际业务中，Colleage的add 和University的add不一定完全一样
								organizationComponents.add(organizationComponent);
							}
							// 重写remove
							@Override
							protected void remove(OrganizationComponent organizationComponent) {
								organizationComponents.remove(organizationComponent);
							}
							@Override
							public String getName() {
								return super.getName();
							}
							@Override
							public String getDes() {
								return super.getDes();
							}
							// print方法，就是输出College包含的系
							@Override
							protected void print() {
								System.out.println("--------------" + getName() + "--------------");
								//遍历 organizationComponents 
								for (OrganizationComponent organizationComponent : organizationComponents) {
									organizationComponent.print();
								}
							}
						}
						//系或专业，子节点->Leaf
						public class Department extends OrganizationComponent {
							//没有集合						
							public Department(String name, String des) {
								super(name, des);
							}						
							//add,remove 就不用写了，因为是叶子节点，没有子节点							
							@Override
							public String getName() {
								return super.getName();
							}							
							@Override
							public String getDes() {
								return super.getDes();
							}							
							@Override
							protected void print() {
								System.out.println(getName());
							}
						}
						//客户端
						public class Client {
							public static void main(String[] args) {								
								//从大到小创建对象，创建学校
								OrganizationComponent university = new University("清华大学", "中国顶级大学");								
								//创建学院
								OrganizationComponent computerCollege = new College("计算机学院", "计算机学院");
								OrganizationComponent infoEngineercollege = new College("信息工程学院", "信息工程学院");																
								//创建各个学院下面的系(专业)
								computerCollege.add(new Department("软件工程", "软件工程不错"));
								computerCollege.add(new Department("网络工程", "网络工程不错"));
								computerCollege.add(new Department("计算机科学与技术", "计算机科学与技术是老牌的专业"));								
								infoEngineercollege.add(new Department("通信工程", " 通信工程不好学 "));
								infoEngineercollege.add(new Department("信息工程", " 信息工程好学 "));							
								//将学院加入到学校
								university.add(computerCollege);
								university.add(infoEngineercollege);								
								//university.print();//大学下所有树形结构
								infoEngineercollege.print();//信息工程学院下树形结构
							}
						}
					源码分析：
						JDK集合类源码分析：Java的集合类-HashMap就适用了组合模式；Map：抽象层，接口[角色:Component]，定义了put/putAll方法，
							HashMap：具体的实现，非叶子节点[角色:Composite]，重写或继承了put/putAll方法，Node: 叶子节点，是HashMap静态内部类，角色Leaf;
					小结：适用于具有明确的组织结构或树形结构的场景，且叶子节点与非叶子节点属性没有明显的差异性；优点：简化客户端操作，有利于扩展；
				外观模式/过程模式：
					含义：定义一个一致性接口（界面类/高层接口），用于屏蔽内部子系统的细节，使调用端只跟这个高层接口发生调用，不需要关系子系统内部的细节；
					原理/角色：
						外观类[Facade]：为调用者提供统一的接口（方法），聚合/组合子系统集合，代理处理请求；
						调用者：外观接口的调用者；
						子系统集合：模块或子系统，处理Facade对象的任务，它是实际功能的提供者；
				    如：[家庭影院案例]
					//子系统集合之DVD播放器
					public class DVDPlayer {					
						//使用单例模式, 使用饿汉式
						private static DVDPlayer instance = new DVDPlayer();					
						public static DVDPlayer getInstanc() {
							return instance;
						}
						//开机
						public void on() {
							System.out.println(" dvd on ");
						}
						//关机
						public void off() {
							System.out.println(" dvd off ");
						}
						//正在播放
						public void play() {
							System.out.println(" dvd is playing ");
						}					
						//暂停播放
						public void pause() {
							System.out.println(" dvd pause ..");
						}
					}
					//子系统集合之爆米花机
					public class Popcorn {						
						private static Popcorn instance = new Popcorn();						
						public static Popcorn getInstance() {
							return instance;
						}
						//开机
						public void on() {
							System.out.println(" popcorn on ");
						}
						//关机
						public void off() {
							System.out.println(" popcorn ff ");
						}
						//出爆米花
						public void pop() {
							System.out.println(" popcorn is poping  ");
						}
					}
					//子系统集合之投影仪
					public class Projector {
						private static Projector instance = new Projector();						
						public static Projector getInstance() {
							return instance;
						}
						//开机
						public void on() {
							System.out.println(" Projector on ");
						}
						//关机
						public void off() {
							System.out.println(" Projector ff ");
						}
						//聚焦
						public void focus() {
							System.out.println(" Projector is Projector  ");
						}
					}
					//子系统集合之大屏
					public class Screen {
						private static Screen instance = new Screen();						
						public static Screen getInstance() {
							return instance;
						}																		
						//大屏上升
						public void up() {
							System.out.println(" Screen up ");
						}
						//大屏降下
						public void down() {
							System.out.println(" Screen down ");
						}						
					}
					//子系统集合之立体声
					public class Stereo {
						private static Stereo instance = new Stereo();						
						public static Stereo getInstance() {
							return instance;
						}
						//打开声音
						public void on() {
							System.out.println(" Stereo on ");
						}
						//关闭声音
						public void off() {
							System.out.println(" Screen off ");
						}
						//声音调高
						public void up() {
							System.out.println(" Screen up.. ");
						}
					}
					//子系统集合之灯光
					public class TheaterLight {
						private static TheaterLight instance = new TheaterLight();
						public static TheaterLight getInstance() {
							return instance;
						}
						//打开灯光
						public void on() {
							System.out.println(" TheaterLight on ");
						}
						//关闭灯光
						public void off() {
							System.out.println(" TheaterLight off ");
						}
						//调暗
						public void dim() {
							System.out.println(" TheaterLight dim.. ");
						}
						//调亮
						public void bright() {
							System.out.println(" TheaterLight bright.. ");
						}
					}
					//高层接口或界面类、外观类
					public class HomeTheaterFacade {						
						//定义各个子系统对象
						private TheaterLight theaterLight;
						private Popcorn popcorn;
						private Stereo stereo;
						private Projector projector;
						private Screen screen;
						private DVDPlayer dVDPlayer;												
						//构造器
						public HomeTheaterFacade() {
							super();
							this.theaterLight = TheaterLight.getInstance();
							this.popcorn = Popcorn.getInstance();
							this.stereo = Stereo.getInstance();
							this.projector = Projector.getInstance();
							this.screen = Screen.getInstance();
							this.dVDPlayer = DVDPlayer.getInstanc();
						}
						//操作分成4步，准备						
						public void ready() {
							popcorn.on();
							popcorn.pop();
							screen.down();
							projector.on();
							stereo.on();
							dVDPlayer.on();
							theaterLight.dim();
						}
						//开启
						public void play() {
							dVDPlayer.play();
						}
						//暂停
						public void pause() {
							dVDPlayer.pause();
						}
						//关闭
						public void end() {
							popcorn.off();
							theaterLight.bright();
							screen.up();
							projector.off();
							stereo.off();
							dVDPlayer.off();
						}
					}
					//客户端
					public class Client {
						public static void main(String[] args) {
							HomeTheaterFacade homeTheaterFacade = new HomeTheaterFacade();
							homeTheaterFacade.ready();
							homeTheaterFacade.play();														
							homeTheaterFacade.end();
						}
					}
				源码分析：
					Mybaits中的Configuration类用到了外观模式；
					大致实现思路：Configuration类外观类依赖MetaObject类[方法：newMetaObject():MetaObject]，组合/聚合了子系统集合[工厂类]，如：DefultObjectFactory，客户端只依赖Configuration外观类；
				小结：
				        屏蔽内部子系统的细节，降低客户端对子系统使用的复杂性；将客户端与子系统解耦；更好的划分访问层次；
			享元模式/蝇量模式：共享对象/数据
				含义：运用共享技术有效的支持大量细粒度的对象，常用于系统底层开发，解决系统性能问题；它可以解决内存浪费问题；经典运用场景就是池技术，如常量池、数据库连接池、缓冲池等；
				角色分析：
					FlyWeight：抽象的享元角色，是产品抽象类，它定义出了对象的外部状态[对象不可分享出来的信息]与内部状态[对象分享出来的信息]的接口或抽象类；
					ConcreteFlyWeight：具体的享元角色，具体的产品类；
					UnSharedConcreteFlyWeight：不可共享的角色，一般不会出现在享元工厂里；
					FlyWeightFactory：享元工厂类，用于构建池容器（集合），同时提供了从池中获取对象的方法；依赖FlyWeight享元角色；
				如：[网站展现案例，网站外包问题]
				//FlyWeight： 抽象类，享元角色；
				public abstract class WebSite {
					public abstract void use(User user);//抽象方法
				}
				//
				//ConcreteFlyWeight：具体的享元角色，具体网站；
				public class ConcreteWebSite extends WebSite {
					//共享的部分，内部状态
					private String type = ""; //网站发布的形式(类型，如：新闻、博客、公众号)					
					//构造器
					public ConcreteWebSite(String type) {							
						this.type = type;
					}
					@Override
					public void use(User user) {
						System.out.println("网站的发布形式为:" + type + " 在使用中 .. 使用者是" + user.getName());
					}												
				}
				// FlyWeightFactory：享元工厂类，根据需要返回一个网站，提供池技术
				public class WebSiteFactory {						
					//集合， 充当池的作用
					private HashMap<String, ConcreteWebSite> pool = new HashMap<>();						
					//根据网站的类型，返回一个网站, 如果没有就创建一个网站，并放入到池中,并返回
					public WebSite getWebSiteCategory(String type) {
						if(!pool.containsKey(type)) {
							//就创建一个网站，并放入到池中
							pool.put(type, new ConcreteWebSite(type));
						}							
						return (WebSite)pool.get(type);
					}						
					//获取网站分类的总数 (池中有多少个网站类型)
					public int getWebSiteCount() {
						return pool.size();
					}
				}
				//用户
				public class User {						
					private String name;						
					public User(String name) {
						super();
						this.name = name;
					}
					public String getName() {
						return name;
					}
					public void setName(String name) {
						this.name = name;
					}											
				}
				//客户端
				public class Client {
					public static void main(String[] args) {
						// 创建一个工厂类
						WebSiteFactory factory = new WebSiteFactory();
						// 客户要一个以新闻形式发布的网站
						WebSite webSite1 = factory.getWebSiteCategory("新闻");							
						webSite1.use(new User("tom"));
						// 客户要一个以博客形式发布的网站
						WebSite webSite2 = factory.getWebSiteCategory("博客");
						webSite2.use(new User("jack"));
						// 客户要一个以博客形式发布的网站
						WebSite webSite3 = factory.getWebSiteCategory("博客");
						webSite3.use(new User("smith"));
						// 客户要一个以博客形式发布的网站
						WebSite webSite4 = factory.getWebSiteCategory("博客");
						webSite4.use(new User("king"));							
						System.out.println("网站的分类共=" + factory.getWebSiteCount());
					}
				}
				源码分析：
					JDK中的Integer类使用到了享元模式；Integer.valueOf（），使用到了享元模式；
					观察源码发现：先判断值是否在IntegerCache缓存池中[范围-128~127]，在的话直接从池中取值，否则使用new Integer（），结论：在-128~127中使用valueOf（）的方式要比new的方式要快；
				小结：享元即共享对象，降低了对象的创建，减少了内存的消耗；缓存池技术的使用，一般使用HashMap或HashTable来存储；提高了系统的复杂度，需要区分内部状态与外部状态；				
			代理模式：
				含义：为目标对象提供一个替身，以实现对这个目标对象的访问；即代理对象访问目标对象；
					  被代理对象可以是远程对象、创建开销大的对象和需要安全控制的对象，代理的形式：静态代理、动态代理（JDK代理、接口代理）以及Cglib代理（可以在内存中动态的创建对象，不需要实现接口，属于动态代理）
				静态代理：
					含义：需要定义一个接口或父类，目标对象与代理对象一起实现接口或继承父类；
					如：[老师授课案例]
					//接口
					public interface ITeacherDao {							
						void teach(); // 授课的方法
					}
					//目标对象
					public class TeacherDao implements ITeacherDao {
						@Override
						public void teach() {
							System.out.println("老师授课中  。。。。。");
						}
					}
					//代理对象，静态代理
					public class TeacherDaoProxy implements ITeacherDao{							
						private ITeacherDao target; // 目标对象，通过接口来聚合														
						//构造器
						public TeacherDaoProxy(ITeacherDao target) {
							this.target = target;
						}
						@Override
						public void teach() {
							System.out.println("开始代理，完成某些操作。。。。。 ");//方法
							target.teach();
							System.out.println("提交。。。。。");//方法
						}
					}
					//客户端
					public class Client {
						public static void main(String[] args) {
							//创建目标对象(被代理对象)
							TeacherDao teacherDao = new TeacherDao();								
							//创建代理对象, 同时将被代理对象传递给代理对象
							TeacherDaoProxy teacherDaoProxy = new TeacherDaoProxy(teacherDao);								
							//通过代理对象，调用到被代理对象的方法，即：执行的是代理对象的方法，代理对象再去调用目标对象的方法 
							teacherDaoProxy.teach();
						}
					}
					优缺点：在不改变目标对象功能前提下，通过代理对目标功能进行了扩展；一旦接口增加了方法，目标对象与代理对象都要维护；
				动态代理：
					含义：
						
----------------------------------------------网络编程技术篇--------------------------------------------------------------------------------------------------------------	
	一、网络编程基础知识
		1、注意区分MQ与网络通讯的区别：
			MQ的目的是为了缓解服务器的压力，在消息生产者与消费者之间添加了一层，使系统解耦，接收的消息可以延迟，不要求完全实时性；
			网络通讯是服务端与客户端之间直接通讯，中间没有添加其他层，实时消息；
		2、Socket基本认识：
			含义：Socket又称“套接字”，即应用程序通过“套接字”向网络发起请求或应答网络请求，在java.net包内有Socket与ServerSocket类分别对应服务端和客户端（建立网络连接）；
				  建立连接成功后，两端都会产生一个Socket实例，操作这个实例，来完成此次会话；具体的工作，都是由子类去实现的；
								发起请求
				  Socket <------------------------>ServerSocket
								应答网络请求
			      套接字的连接过程分为4步骤（3次握手、4次挥手）：
					服务器监听：服务器端处于等待连接状态（accept）（不确定哪一个客户端连接），实时监测网络状态；
					客户端请求服务端：前提是客户端必须描述服务端的套接字，即指出地址和端口号，然后才能发出连接请求；
					服务端连接确认：服务端监听到客户端套接字的连接请求，响应客户端请求，建立一个新的线程（Thread），把自身的套接字描述信息发给客户端；
					客户端连接确认：一旦客户端确认了服务端的描述，双方建立连接，开始通讯；同时，服务端仍然属于监听状态，等待其他客户端来连接；
		3、IO（BIO）与NIO的认识：
			本质是阻塞与非阻塞的区别；
				阻塞：应用程序在获取网络数据的时候，如果网络传输慢，程序必须一直等待着，直到传输完毕为止；完全依赖于网络带宽
				非阻塞：程序直接获取已经准备好的数据，无需等待；即在网路之外添加了一个channel与buffer，客户端直接从这里面取数据；
			BIO：同步阻塞，NIO同步非阻塞，在JDK1.7以后出现了异步非阻塞模型即NIO2.0（AIO）
			同步与异步：面向操作系统的；同步指程序直接参与IO的读写操作；异步所有的IO的读写交给操作系统；同步指的是服务端执行方式，阻塞指的是具体技术；
			BIO通讯：基于TCP/IP协议，跨址传输，C/S模型，Client（多个）------------->Server acceptor（阻塞状态）---------->Thread（多个）
				案例说明：
				//服务端
				public class Server {
					final static int PROT = 8765;					
					public static void main(String[] args) {					
						ServerSocket server = null;
						try {
							server = new ServerSocket(PROT);
							System.out.println(" server start .. ");
							//进行阻塞，开启线程
							Socket socket = server.accept();
							//新建一个线程执行客户端的任务
							new Thread(new ServerHandler(socket)).start();							
						} catch (Exception e) {
							e.printStackTrace();
						} finally {
							if(server != null){
								try {
									server.close();
								} catch (IOException e) {
									e.printStackTrace();
								}
							}
							server = null;
						}																		
					}
				}
				//客户端
				public class Client {
					final static String ADDRESS = "127.0.0.1";
					final static int PORT = 8765;					
					public static void main(String[] args) {						
						Socket socket = null;
						//输入流-读数据，输出流-写数据
						BufferedReader in = null;
						PrintWriter out = null;						
						try {
							socket = new Socket(ADDRESS, PORT);//描述服务端套接字的信息
							in = new BufferedReader(new InputStreamReader(socket.getInputStream()));
							out = new PrintWriter(socket.getOutputStream(), true);							
							//向服务器端发送数据
							out.println("接收到客户端的请求数据...");
							String response = in.readLine();
							System.out.println("Client: " + response);//结果：Client: 服务器端回送响的应数据.							
						} catch (Exception e) {
							e.printStackTrace();
						} finally {
							if(in != null){
								try {
									in.close();
								} catch (IOException e) {
									e.printStackTrace();
								}
							}
							if(out != null){
								try {
									out.close();
								} catch (Exception e) {
									e.printStackTrace();
								}
							}
							if(socket != null){
								try {
									socket.close();
								} catch (IOException e) {
									e.printStackTrace();
								}
							}
							socket = null;
						}
					}
				}
				//Handler
				public class ServerHandler implements Runnable{
					private Socket socket;					
					public ServerHandler(Socket socket){
						this.socket = socket;
					}					
					@Override
					public void run() {
						BufferedReader in = null;
						PrintWriter out = null;
						try {
							in = new BufferedReader(new InputStreamReader(this.socket.getInputStream()));
							out = new PrintWriter(this.socket.getOutputStream(), true);
							String body = null;
							while(true){
								body = in.readLine();
								if(body == null) break;
								System.out.println("Server :" + body);//结果：Server : 接收到客户端的请求数据...
								out.println("服务器端回送响的应数据.");
							}							
						} catch (Exception e) {
							e.printStackTrace();
						} finally {
							if(in != null){
								try {
									in.close();
								} catch (IOException e) {
									e.printStackTrace();
								}
							}
							if(out != null){
								try {
									out.close();
								} catch (Exception e) {
									e.printStackTrace();
								}
							}
							if(socket != null){
								try {
									socket.close();
								} catch (IOException e) {
									e.printStackTrace();
								}
							}
							socket = null;
						}												
					}
				}
			伪异步IO：利用线程池技术来缓解创建过多线程带来的服务器的压力；
				原理：Client（多个）------------->Server acceptor（阻塞状态）---------->ThreadPool，实现Runable接口；
				//案例分析：
				//服务端
				public class Server {
					final static int PORT = 8765;
					public static void main(String[] args) {
						ServerSocket server = null;
						BufferedReader in = null;
						PrintWriter out = null;
						try {
							server = new ServerSocket(PORT);
							System.out.println("server start...");
							Socket socket = null;
							//利用池技术
							HandlerExecutorPool executorPool = new HandlerExecutorPool(50, 1000);
							while(true){
								socket = server.accept();
								executorPool.execute(new ServerHandler(socket));
							}						
						} catch (Exception e) {
							e.printStackTrace();
						} finally {
							if(in != null){
								try {
									in.close();
								} catch (Exception e1) {
									e1.printStackTrace();
								}
							}
							if(out != null){
								try {
									out.close();
								} catch (Exception e2) {
									e2.printStackTrace();
								}
							}
							if(server != null){
								try {
									server.close();
								} catch (Exception e3) {
									e3.printStackTrace();
								}
							}
							server = null;				
						}																
					}										
				}
				//线程池，JDK1.5以后JUC包下
				public class HandlerExecutorPool {
					private ExecutorService executor;
					public HandlerExecutorPool(int maxPoolSize, int queueSize){
						this.executor = new ThreadPoolExecutor(
								Runtime.getRuntime().availableProcessors(),
								maxPoolSize, 
								120L, 
								TimeUnit.SECONDS,
								new ArrayBlockingQueue<Runnable>(queueSize));
					}					
					public void execute(Runnable task){
						this.executor.execute(task);
					}														
				}
				//客户端、Handler类同上；
			NIO：（JDK1.5）非阻塞IO（同步），核心概念：Buffer（缓冲区）、Channel（通道）、Selector（多路复用器、选择器），目的就是减少TCP的3次握手4次挥手操作，减少连接开销；
				原理：Client端（核心类：SocketChannel类，对Socket类的进一步抽象）注册到服务端选择器上
					  Server端（核心类：ServerSocketChannel类，对ServerSocket类的进一步抽象），这里有多路复用器，采用轮询（Key）所有注册通道，查看通道状态（Connect、Accept、Read、Write），执行相关操作；
				基本概念解释：	  
					  Buffer：缓冲区，包含读写数据的对象，实质是一个对象，通常是一个字节数组（ByteBuffer），也可以对应Java的其他基本类型（Boolean除外）；
					  Channel：网络数据通过Channel读写，方向是双向的，与多路复用器结合，有多种状态位；有2种分类：网路读写（SelectableChannel）、文件操作（FileChannel）;
					  Selector：多路复用器、选择器，是NIO基础，轮询注册其上的Channel，查看通道状态；理论上channel是无上限的，底层利用JDK的epoll机制，获取连接句柄；
								类似一个管理者角色，管理channel，在客户端通道注册到选择器后，Selector会分配每一个channel一个key，轮询的是key；当管道准备就绪（accept）状态时，通知cpu进行读写操作；
					  Buffer：API说明示例；
					  public class TestBuffer {						
						public static void main(String[] args) {							
							// 1 基本操作
							//创建指定长度的缓冲区
							IntBuffer buf = IntBuffer.allocate(10);//声明容量
							buf.put(13);// position位置：0 - > 1
							buf.put(21);// position位置：1 - > 2
							buf.put(35);// position位置：2 - > 3
							//把位置复位为0，也就是position位置：3 - > 0
							buf.flip();
							System.out.println("使用flip复位：" + buf);//使用flip复位：java.nio.HeapIntBuffer[pos=0 lim=3 cap=10]
							System.out.println("容量为: " + buf.capacity());	//容量一旦初始化后不允许改变（warp方法包裹数组除外）
							System.out.println("限制为: " + buf.limit());		//由于只装载了三个元素,所以可读取或者操作的元素为3 则limit=3														
							System.out.println("获取下标为1的元素：" + buf.get(1));//读数据
							System.out.println("get(index)方法，position位置不改变：" + buf);//get(index)方法，position位置不改变：java.nio.HeapIntBuffer[pos=0 lim=3 cap=10]
							buf.put(1, 4);//写数据
							System.out.println("put(index, change)方法，position位置不变：" + buf);//java.nio.HeapIntBuffer[pos=0 lim=3 cap=10]						
							for (int i = 0; i < buf.limit(); i++) {
								//调用get方法会使其缓冲区位置（position）向后递增一位
								System.out.print(buf.get() + "\t");
							}
							System.out.println("buf对象遍历之后为: " + buf);	//buf对象遍历之后为: java.nio.HeapIntBuffer[pos=3 lim=3 cap=10]						
							// 2 wrap方法使用
							//  wrap方法会包裹一个数组: 一般这种用法不会先初始化缓存对象的长度，因为没有意义，最后还会被wrap所包裹的数组覆盖掉。 
							//  并且wrap方法修改缓冲区对象的时候，数组本身也会跟着发生变化。                     
							int[] arr = new int[]{1,2,5};
							IntBuffer buf1 = IntBuffer.wrap(arr);
							System.out.println(buf1);//java.nio.HeapIntBuffer[pos=0 lim=3 cap=3]						
							IntBuffer buf2 = IntBuffer.wrap(arr, 0 , 2);
							//这样使用表示容量为数组arr的长度，但是可操作的元素只有实际进入缓存区的元素长度
							System.out.println(buf2);//java.nio.HeapIntBuffer[pos=0 lim=2 cap=3]														
							// 3 其他方法
							IntBuffer buf1 = IntBuffer.allocate(10);
							int[] arr = new int[]{1,2,5};
							buf1.put(arr);
							System.out.println(buf1);//java.nio.HeapIntBuffer[pos=3 lim=10 cap=10]	
							//一种复制方法
							IntBuffer buf3 = buf1.duplicate();
							System.out.println(buf3);//java.nio.HeapIntBuffer[pos=3 lim=10 cap=10]	
							//设置buf1的位置属性
							//buf1.position(0);
							buf1.flip();
							System.out.println(buf1);//java.nio.HeapIntBuffer[pos=0 lim=3 cap=10]							
							System.out.println("可读数据为：" + buf1.remaining());//可读数据为：3						
							int[] arr2 = new int[buf1.remaining()];
							//将缓冲区数据放入arr2数组中去
							buf1.get(arr2);
							for(int i : arr2){
								System.out.print(Integer.toString(i) + ",");//1,2,5,
							}							
						}
					}
				  NIO案例说明（了解）：
					//服务端（读-操作）
					public class Server implements Runnable{
						//1 多路复用器（管理所有的通道）
						private Selector seletor;
						//2 建立缓冲区
						private ByteBuffer readBuf = ByteBuffer.allocate(1024);
						//private ByteBuffer writeBuf = ByteBuffer.allocate(1024);
						public Server(int port){
							try {
								//1 打开路复用器
								this.seletor = Selector.open();
								//2 打开服务器通道
								ServerSocketChannel ssc = ServerSocketChannel.open();
								//3 设置服务器通道为非阻塞模式
								ssc.configureBlocking(false);
								//4 绑定地址
								ssc.bind(new InetSocketAddress(port));
								//5 把服务器通道注册到多路复用器上，并且监听阻塞事件，标识位
								ssc.register(this.seletor, SelectionKey.OP_ACCEPT);								
								System.out.println("Server start, port :" + port);								
							} catch (IOException e) {
								e.printStackTrace();
							}
						}
						@Override
						public void run() {
							while(true){
								try {
									//1 必须要让多路复用器开始监听
									this.seletor.select();
									//2 返回多路复用器已经选择的结果集
									Iterator<SelectionKey> keys = this.seletor.selectedKeys().iterator();
									//3 进行遍历
									while(keys.hasNext()){
										//4 获取一个选择的元素
										SelectionKey key = keys.next();
										//5 直接从容器中移除就可以了
										keys.remove();
										//6 如果是有效的
										if(key.isValid()){
											//7 如果为阻塞状态
											if(key.isAcceptable()){
												this.accept(key);
											}
											//8 如果为可读状态
											if(key.isReadable()){
												this.read(key);
											}
											//9 写数据
											if(key.isWritable()){
												//this.write(key); //ssc
											}
										}										
									}
								} catch (IOException e) {
									e.printStackTrace();
								}
							}
						}						
						private void write(SelectionKey key){
							//ServerSocketChannel ssc =  (ServerSocketChannel) key.channel();
							//ssc.register(this.seletor, SelectionKey.OP_WRITE);
						}
						private void read(SelectionKey key) {
							try {
								//1 清空缓冲区旧的数据
								this.readBuf.clear();
								//2 获取之前注册的socket通道对象
								SocketChannel sc = (SocketChannel) key.channel();
								//3 读取数据
								int count = sc.read(this.readBuf);
								//4 如果没有数据
								if(count == -1){
									key.channel().close();
									key.cancel();
									return;
								}
								//5 有数据则进行读取 读取之前需要进行复位方法(把position 和limit进行复位)
								this.readBuf.flip();
								//6 根据缓冲区的数据长度创建相应大小的byte数组，接收缓冲区的数据
								byte[] bytes = new byte[this.readBuf.remaining()];
								//7 接收缓冲区数据
								this.readBuf.get(bytes);
								//8 打印结果
								String body = new String(bytes).trim();
								System.out.println("Server : " + body);								
								// 9..可以写回给客户端数据 								
							} catch (IOException e) {
								e.printStackTrace();
							}							
						}
						private void accept(SelectionKey key) {
							try {
								//1 获取服务通道
								ServerSocketChannel ssc =  (ServerSocketChannel) key.channel();
								//2 执行阻塞方法
								SocketChannel sc = ssc.accept();
								//3 设置阻塞模式
								sc.configureBlocking(false);
								//4 注册到多路复用器上，并设置读取标识，即sc通道可读
								sc.register(this.seletor, SelectionKey.OP_READ);
							} catch (IOException e) {
								e.printStackTrace();
							}
						}						
						public static void main(String[] args) {							
							new Thread(new Server(8765)).start();
						}											
					}
					//客户端
					public class Client {
						//需要一个Selector 
						public static void main(String[] args) {							
							//创建连接的地址
							InetSocketAddress address = new InetSocketAddress("127.0.0.1", 8765);							
							//声明连接通道
							SocketChannel sc = null;							
							//建立缓冲区
							ByteBuffer buf = ByteBuffer.allocate(1024);							
							try {
								//打开通道
								sc = SocketChannel.open();
								//进行连接
								sc.connect(address);								
								while(true){
									//定义一个字节数组，然后使用系统录入功能：
									byte[] bytes = new byte[1024];
									System.in.read(bytes);									
									//把数据放到缓冲区中
									buf.put(bytes);
									//对缓冲区进行复位
									buf.flip();
									//写出数据
									sc.write(buf);
									//清空缓冲区数据
									buf.clear();
								}
							} catch (IOException e) {
								e.printStackTrace();
							} finally {
								if(sc != null){
									try {
										sc.close();
									} catch (IOException e) {
										e.printStackTrace();
									}
								}
							}							
						}						
					}
				优缺点：优点减少连接数量，采用抽象的通道技术（取代了TCP/IP的通讯技术）以及多路复用等技术；缺点：书写繁琐，所有的细节都要自己去实现；
			AIO：（JDK1.7）	异步非阻塞，引入异步通道概念；在多路复用器轮询通道是异步的，两个核心类：AsynchronousSocketChannel与AsynchronousServerSocketChannel；
				案例说明：
				//服务端
				public class Server {
					//线程池
					private ExecutorService executorService;
					//线程组
					private AsynchronousChannelGroup threadGroup;
					//服务器通道
					public AsynchronousServerSocketChannel assc;					
					public Server(int port){
						try {
							//创建一个缓存池
							executorService = Executors.newCachedThreadPool();
							//创建线程组
							threadGroup = AsynchronousChannelGroup.withCachedThreadPool(executorService, 1);
							//创建服务器通道
							assc = AsynchronousServerSocketChannel.open(threadGroup);
							//进行绑定，便于寻址
							assc.bind(new InetSocketAddress(port));							
							System.out.println("server start , port : " + port);
							//进行阻塞
							assc.accept(this, new ServerCompletionHandler());
							//一直阻塞不让服务器停止，模拟服务器一直处于运行状态，因为非阻塞
							Thread.sleep(Integer.MAX_VALUE);							
						} catch (Exception e) {
							e.printStackTrace();
						}
					}					
					public static void main(String[] args) {
						Server server = new Server(8765);
					}					
				}
				//Handler
				public class ServerCompletionHandler implements CompletionHandler<AsynchronousSocketChannel, Server> {
					@Override
					public void completed(AsynchronousSocketChannel asc, Server attachment) {
						//当有下一个客户端接入的时候直接调用Server的accept方法，这样反复执行下去，保证多个客户端都可以阻塞
						attachment.assc.accept(attachment, this);
						read(asc);
					}
					private void read(final AsynchronousSocketChannel asc) {
						//读取数据，异步读数据
						ByteBuffer buf = ByteBuffer.allocate(1024);
						asc.read(buf, buf, new CompletionHandler<Integer, ByteBuffer>() {
							@Override
							public void completed(Integer resultSize, ByteBuffer attachment) {//数据读完以后
								//进行读取之后,重置标识位
								attachment.flip();
								//获得读取的字节数
								System.out.println("Server -> " + "收到客户端的数据长度为:" + resultSize);
								//获取读取的数据
								String resultData = new String(attachment.array()).trim();
								System.out.println("Server -> " + "收到客户端的数据信息为:" + resultData);
								String response = "服务器响应, 收到了客户端发来的数据: " + resultData;
								write(asc, response);
							}
							@Override
							public void failed(Throwable exc, ByteBuffer attachment) {
								exc.printStackTrace();
							}
						});
					}					
					private void write(AsynchronousSocketChannel asc, String response) {
						try {
							ByteBuffer buf = ByteBuffer.allocate(1024);
							buf.put(response.getBytes());
							buf.flip();
							asc.write(buf).get();//开启一个新的线程，不影响主线程执行，不断的写数据
						} catch (InterruptedException e) {
							e.printStackTrace();
						} catch (ExecutionException e) {
							e.printStackTrace();
						}
					}					
					@Override
					public void failed(Throwable exc, Server attachment) {
						exc.printStackTrace();
					}
				}
				//客户端
				public class Client implements Runnable{
					private AsynchronousSocketChannel asc ;					
					public Client() throws Exception {
						asc = AsynchronousSocketChannel.open();
					}					
					public void connect(){
						asc.connect(new InetSocketAddress("127.0.0.1", 8765));//寻址
					}					
					public void write(String request){
						try {
							asc.write(ByteBuffer.wrap(request.getBytes())).get();
							read();
						} catch (Exception e) {
							e.printStackTrace();
						}
					}
					private void read() {
						ByteBuffer buf = ByteBuffer.allocate(1024);
						try {
							asc.read(buf).get();//不断的读数据
							buf.flip();
							byte[] respByte = new byte[buf.remaining()];
							buf.get(respByte);
							System.out.println(new String(respByte,"utf-8").trim());
						} catch (InterruptedException e) {
							e.printStackTrace();
						} catch (ExecutionException e) {
							e.printStackTrace();
						} catch (UnsupportedEncodingException e) {
							e.printStackTrace();
						}
					}					
					@Override
					public void run() {//模拟客户端服务一直开启状态
						while(true){							
						}
					}					
					public static void main(String[] args) throws Exception {
						Client c1 = new Client();
						c1.connect();						
						Client c2 = new Client();
						c2.connect();					
						Client c3 = new Client();
						c3.connect();						
						new Thread(c1, "c1").start();
						new Thread(c2, "c2").start();
						new Thread(c3, "c3").start();						
						Thread.sleep(1000);						
						c1.write("c1 aaa");
						c2.write("c2 bbbb");
						c3.write("c3 ccccc");
					}					
				}
	二、Netty通讯技术（联想Apache mina通讯框架）
		1、初步认识：
			Netty简单易用，健壮可扩展，当下主流框架技术底层都有用到，如：JMS中的RocketMQ、分布式通信框架Dubbox、Hadoop的RPC框架Avro等等
			Netty是基于Java的NIO（客户端-服务端）网络应用框架，它提供了简易的API使得与业务逻辑解耦，是异步通讯的（非阻塞）；
			Netty支持的传输协议有：Socket、Http，它支持服务有WebSocket、SSL（安全认证、Secure Sockets Layer 安全套接层）以及大文件传输等
			Netty特性：易于使用、高吞吐量低的延迟性能好、安全性高、社区活跃度高
		2、Netty通讯步骤：
			//服务端
			a、创建2个线程组，一个专门用于网络事件处理（接收客户端的连接，客户端可能有多个），另一个进行网络通讯读写；
			b、创建ServerBootstrap对象，配置Netty参数；
			c、创建类ChannelInitalizer，配置初始化工作；
			d、配置端口，启动Netty服务端；
			//客户端
			a、创建1个线程组，进行网络通讯读写；
			b、创建Bootstrap对象，配置Netty参数；
			c、创建类ChannelInitalizer，配置初始化工作；
			d、寻址，连接Netty服务端；
		3、简单示例，入门级HelloWorld：
		   //服务端，调用netty API接口
		   public class Server {
				public static void main(String[] args) throws Exception {
					//1 创建线两个程组，一个是用于处理服务器端接收客户端连接的，一个是进行网络通信的（网络读写）
					EventLoopGroup pGroup = new NioEventLoopGroup();
					EventLoopGroup cGroup = new NioEventLoopGroup();					
					//2 创建辅助工具类，用于服务器通道的一系列配置
					ServerBootstrap b = new ServerBootstrap();
					b.group(pGroup, cGroup)		//绑定俩个线程组
					.channel(NioServerSocketChannel.class)		//指定NIO的模式
					.option(ChannelOption.SO_BACKLOG, 1024)		//设置tcp缓冲区
					.option(ChannelOption.SO_SNDBUF, 32*1024)	//设置发送缓冲大小
					.option(ChannelOption.SO_RCVBUF, 32*1024)	//接收缓冲大小
					.option(ChannelOption.SO_KEEPALIVE, true)	//保持连接
					.childHandler(new ChannelInitializer<SocketChannel>() {
						@Override
						protected void initChannel(SocketChannel sc) throws Exception {
							//3 在这里配置具体数据接收方法的处理
							sc.pipeline().addLast(new ServerHandler());
						}
					});					
					//4 进行绑定，即服务端可以开放多个端口 
					ChannelFuture cf1 = b.bind(8765).sync();
					//ChannelFuture cf2 = b.bind(8764).sync();
					//5 等待关闭，同步优雅关闭
					cf1.channel().closeFuture().sync();
					//cf2.channel().closeFuture().sync();
					pGroup.shutdownGracefully();
					cGroup.shutdownGracefully();
				}
			}
			//ServerHandler，处理服务端业务逻辑
			public class ServerHandler extends ChannelHandlerAdapter {
				@Override
				public void channelActive(ChannelHandlerContext ctx) throws Exception {
					System.out.println("server channel active... ");
				}
				@Override
				public void channelRead(ChannelHandlerContext ctx, Object msg)
						throws Exception {
						ByteBuf buf = (ByteBuf) msg;
						byte[] req = new byte[buf.readableBytes()];
						buf.readBytes(req);
						String body = new String(req, "utf-8");
						System.out.println("Server :" + body );//服务端接收到的shuju
						String response = "进行返回给客户端的响应：" + body ;
						ctx.writeAndFlush(Unpooled.copiedBuffer(response.getBytes()));
						//.addListener(ChannelFutureListener.CLOSE);//将Netty长连接转成短连接
				}
				@Override
				public void channelReadComplete(ChannelHandlerContext ctx)
						throws Exception {
					System.out.println("读完了");
					ctx.flush();
				}
				@Override
				public void exceptionCaught(ChannelHandlerContext ctx, Throwable t)
						throws Exception {
					ctx.close();
				}
			}
			//客户端，调用netty API接口
			public class Client {
				public static void main(String[] args) throws Exception{					
					EventLoopGroup group = new NioEventLoopGroup();
					Bootstrap b = new Bootstrap();
					b.group(group)
					.channel(NioSocketChannel.class)
					.handler(new ChannelInitializer<SocketChannel>() {
						@Override
						protected void initChannel(SocketChannel sc) throws Exception {
							sc.pipeline().addLast(new ClientHandler());
						}
					});					
					ChannelFuture cf1 = b.connect("127.0.0.1", 8765).sync();//寻址，模拟多个客户端连接
					//ChannelFuture cf2 = b.connect("127.0.0.1", 8764).sync();
					//发送消息
					Thread.sleep(1000);
					cf1.channel().writeAndFlush(Unpooled.copiedBuffer("777".getBytes()));
					cf1.channel().writeAndFlush(Unpooled.copiedBuffer("666".getBytes()));
					//cf2.channel().writeAndFlush(Unpooled.copiedBuffer("888".getBytes()));
					Thread.sleep(2000);
					cf1.channel().writeAndFlush(Unpooled.copiedBuffer("888".getBytes()));
					//cf2.channel().writeAndFlush(Unpooled.copiedBuffer("666".getBytes()));					
					cf1.channel().closeFuture().sync();
					//cf2.channel().closeFuture().sync();
					group.shutdownGracefully();															
				}
			}
			// ClientHandler，处理客户端业务逻辑
			public class ClientHandler extends ChannelHandlerAdapter{
				@Override
				public void channelActive(ChannelHandlerContext ctx) throws Exception {
				}
				@Override
				public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
					try {
						ByteBuf buf = (ByteBuf) msg;						
						byte[] req = new byte[buf.readableBytes()];
						buf.readBytes(req);					
						String body = new String(req, "utf-8");
						System.out.println("Client :" + body );//客户端接收到的服务端的响应数据
						String response = "收到服务器端的返回信息：" + body;
					} finally {
						ReferenceCountUtil.release(msg);//释放信息
					}
				}
				@Override
				public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
				}
				@Override
				public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause)
						throws Exception {
					ctx.close();
				}
			}
		4、Netty拆包、粘包：
			问题产生：TCP是一个“流”的协议，即没有界限的遗传数据，会产生拆包、粘包问题，对应的解决方案：
				1、消息定长（固定报文的长度）；2、在包尾部添加特殊的字符进行分割；3、将消息分为消息头（消息长度）与消息体；
			Netty提供：DelimiterBasedFrameDecoder（自定义分割符类）、FixedLengthFrameDecoder（定长）来处理这一问题；
			案例分析一：
			//服务端
			public class Server {
				public static void main(String[] args) throws Exception{
					//1 创建2个线程，一个是负责接收客户端的连接。一个是负责进行数据传输的
					EventLoopGroup pGroup = new NioEventLoopGroup();
					EventLoopGroup cGroup = new NioEventLoopGroup();					
					//2 创建服务器辅助类
					ServerBootstrap b = new ServerBootstrap();
					b.group(pGroup, cGroup)
					 .channel(NioServerSocketChannel.class)
					 .option(ChannelOption.SO_BACKLOG, 1024)
					 .option(ChannelOption.SO_SNDBUF, 32*1024)
					 .option(ChannelOption.SO_RCVBUF, 32*1024)
					 .childHandler(new ChannelInitializer<SocketChannel>() {
						@Override
						protected void initChannel(SocketChannel sc) throws Exception {
							//设置特殊分隔符$_
							ByteBuf buf = Unpooled.copiedBuffer("$_".getBytes());
							sc.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, buf));
							//设置字符串形式的解码
							sc.pipeline().addLast(new StringDecoder());
							sc.pipeline().addLast(new ServerHandler());
						}
					});					
					//4 绑定连接
					ChannelFuture cf = b.bind(8765).sync();					
					//等待服务器监听端口关闭
					cf.channel().closeFuture().sync();
					pGroup.shutdownGracefully();
					cGroup.shutdownGracefully();					
				}				
			}
			//ServerHandler
			public class ServerHandler extends ChannelHandlerAdapter {
				@Override
				public void channelActive(ChannelHandlerContext ctx) throws Exception {
					System.out.println(" server channel active... ");
				}
				@Override
				public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
					String request = (String)msg;//接收客户端数据是解码后的字符串数据
					System.out.println("Server :" + msg);
					String response = "服务器响应：" + msg + "$_";
					ctx.writeAndFlush(Unpooled.copiedBuffer(response.getBytes()));
				}
				@Override
				public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {					
				}
				@Override
				public void exceptionCaught(ChannelHandlerContext ctx, Throwable t) throws Exception {
					ctx.close();
				}
			}
			//客户端
			public class Client {
				public static void main(String[] args) throws Exception {					
					EventLoopGroup group = new NioEventLoopGroup();					
					Bootstrap b = new Bootstrap();
					b.group(group)
					 .channel(NioSocketChannel.class)
					 .handler(new ChannelInitializer<SocketChannel>() {
						@Override
						protected void initChannel(SocketChannel sc) throws Exception {
							//同服务端
							ByteBuf buf = Unpooled.copiedBuffer("$_".getBytes());
							sc.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, buf));
							sc.pipeline().addLast(new StringDecoder());
							sc.pipeline().addLast(new ClientHandler());
						}
					});					
					ChannelFuture cf = b.connect("127.0.0.1", 8765).sync();					
					cf.channel().writeAndFlush(Unpooled.wrappedBuffer("bbbb$_".getBytes()));
					cf.channel().writeAndFlush(Unpooled.wrappedBuffer("cccc$_".getBytes()));										
					//等待客户端端口关闭
					cf.channel().closeFuture().sync();
					group.shutdownGracefully();				
				}
			}
			//ClientHandler
			public class ClientHandler extends ChannelHandlerAdapter{
				@Override
				public void channelActive(ChannelHandlerContext ctx) throws Exception {
					System.out.println("client channel active... ");
				}
				@Override
				public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
					try {
						String response = (String)msg;
						System.out.println("Client: " + response);
					} finally {
						ReferenceCountUtil.release(msg);
					}
				}
				@Override
				public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
				}
				@Override
				public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
					ctx.close();
				}
			}
			//案例分析二：
			//服务端
			public class Server {
				public static void main(String[] args) throws Exception{
					//1 创建2个线程，一个是负责接收客户端的连接。一个是负责进行数据传输的
					EventLoopGroup pGroup = new NioEventLoopGroup();
					EventLoopGroup cGroup = new NioEventLoopGroup();					
					//2 创建服务器辅助类
					ServerBootstrap b = new ServerBootstrap();
					b.group(pGroup, cGroup)
					 .channel(NioServerSocketChannel.class)
					 .option(ChannelOption.SO_BACKLOG, 1024)
					 .option(ChannelOption.SO_SNDBUF, 32*1024)
					 .option(ChannelOption.SO_RCVBUF, 32*1024)
					 .childHandler(new ChannelInitializer<SocketChannel>() {
						@Override
						protected void initChannel(SocketChannel sc) throws Exception {
							//设置定长字符串接收
							sc.pipeline().addLast(new FixedLengthFrameDecoder(5));
							//设置字符串形式的解码
							sc.pipeline().addLast(new StringDecoder());
							sc.pipeline().addLast(new ServerHandler());
						}
					});					
					//4 绑定连接
					ChannelFuture cf = b.bind(8765).sync();					
					//等待服务器监听端口关闭
					cf.channel().closeFuture().sync();
					pGroup.shutdownGracefully();
					cGroup.shutdownGracefully();					
				}				
			}
			//ServerHandler
			public class ServerHandler extends ChannelHandlerAdapter {
				@Override
				public void channelActive(ChannelHandlerContext ctx) throws Exception {
					System.out.println(" server channel active... ");
				}
				@Override
				public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
					String request = (String)msg;
					System.out.println("Server :" + msg);
					String response =  request ;
					ctx.writeAndFlush(Unpooled.copiedBuffer(response.getBytes()));
				}
				@Override
				public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {					
				}
				@Override
				public void exceptionCaught(ChannelHandlerContext ctx, Throwable t) throws Exception {
				}
			}
			//客户端
			public class Client {
				public static void main(String[] args) throws Exception {					
					EventLoopGroup group = new NioEventLoopGroup();					
					Bootstrap b = new Bootstrap();
					b.group(group)
					 .channel(NioSocketChannel.class)
					 .handler(new ChannelInitializer<SocketChannel>() {
						@Override
						protected void initChannel(SocketChannel sc) throws Exception {
							sc.pipeline().addLast(new FixedLengthFrameDecoder(5));
							sc.pipeline().addLast(new StringDecoder());
							sc.pipeline().addLast(new ClientHandler());
						}
					});					
					ChannelFuture cf = b.connect("127.0.0.1", 8765).sync();					
					cf.channel().writeAndFlush(Unpooled.wrappedBuffer("aaaaabbbbb".getBytes()));
					cf.channel().writeAndFlush(Unpooled.copiedBuffer("ccccccc".getBytes()));					
					//等待客户端端口关闭
					cf.channel().closeFuture().sync();
					group.shutdownGracefully();					
				}
			}
			//ClientHandler
			public class ClientHandler extends ChannelHandlerAdapter{
				@Override
				public void channelActive(ChannelHandlerContext ctx) throws Exception {
					System.out.println("client channel active... ");
				}
				@Override
				public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
					String response = (String)msg;
					System.out.println("Client: " + response);
				}
				@Override
				public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
				}
				@Override
				public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
				}
			}
		5、Netty编解码问题：
			含义：实质是Java序列化问题，目的：进行网络传输；对象持久化；
				可以使用对象序列化，但性能太低，一般使用编解码框架：Jboss的Marshalling包、google的Protobuf；
			案例分析：
			//服务端
			public class Server {
				public static void main(String[] args) throws Exception{
					//开启2个线程组
					EventLoopGroup pGroup = new NioEventLoopGroup();
					EventLoopGroup cGroup = new NioEventLoopGroup();
					//辅助工具类
					ServerBootstrap b = new ServerBootstrap();
					b.group(pGroup, cGroup)
					 .channel(NioServerSocketChannel.class)
					 .option(ChannelOption.SO_BACKLOG, 1024)
					 //设置日志级别
					 .handler(new LoggingHandler(LogLevel.INFO))
					 //初始化工作
					 .childHandler(new ChannelInitializer<SocketChannel>() {
						protected void initChannel(SocketChannel sc) throws Exception {
							//管道处理
							sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());//解码
							sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());//编码
							sc.pipeline().addLast(new ServerHandler());//处理业务逻辑
						}
					});					
					ChannelFuture cf = b.bind(8765).sync();
					//关闭资源
					cf.channel().closeFuture().sync();
					pGroup.shutdownGracefully();
					cGroup.shutdownGracefully();					
				}
			}
			//编解码工具类
			public final class MarshallingCodeCFactory {
				/**
				 * 创建Jboss Marshalling解码器MarshallingDecoder
				 * @return MarshallingDecoder
				 */
				public static MarshallingDecoder buildMarshallingDecoder() {
					//首先通过Marshalling工具类的精通方法获取Marshalling实例对象 参数serial标识创建的是java序列化工厂对象。
					final MarshallerFactory marshallerFactory = Marshalling.getProvidedMarshallerFactory("serial");
					//创建了MarshallingConfiguration对象，配置了版本号为5 
					final MarshallingConfiguration configuration = new MarshallingConfiguration();
					configuration.setVersion(5);
					//根据marshallerFactory和configuration创建provider
					UnmarshallerProvider provider = new DefaultUnmarshallerProvider(marshallerFactory, configuration);
					//构建Netty的MarshallingDecoder对象，俩个参数分别为provider和单个消息序列化后的最大长度
					MarshallingDecoder decoder = new MarshallingDecoder(provider, 1024 * 1024 * 1);
					return decoder;
				}
				/**
				 * 创建Jboss Marshalling编码器MarshallingEncoder
				 * @return MarshallingEncoder
				 */
				public static MarshallingEncoder buildMarshallingEncoder() {
					final MarshallerFactory marshallerFactory = Marshalling.getProvidedMarshallerFactory("serial");
					final MarshallingConfiguration configuration = new MarshallingConfiguration();
					configuration.setVersion(5);
					MarshallerProvider provider = new DefaultMarshallerProvider(marshallerFactory, configuration);
					//构建Netty的MarshallingEncoder对象，MarshallingEncoder用于实现序列化接口的POJO对象序列化为二进制数组
					MarshallingEncoder encoder = new MarshallingEncoder(provider);
					return encoder;
				}
			}
			//服务端业务逻辑处理，ServerHandler类
			public class ServerHandler extends ChannelHandlerAdapter{
				@Override
				public void channelActive(ChannelHandlerContext ctx) throws Exception {
				}
				@Override
				public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
					Req req = (Req)msg;
					System.out.println("Server : " + req.getId() + ", " + req.getName() + ", " + req.getRequestMessage());
					byte[] attachment = GzipUtils.ungzip(req.getAttachment());
					//程序所在的目录下的文件
					String path = System.getProperty("user.dir") + File.separatorChar + "receive" +  File.separatorChar + "001.jpg";
					FileOutputStream fos = new FileOutputStream(path);
					fos.write(attachment);
					fos.close();
					//服务端响应
					Resp resp = new Resp();
					resp.setId(req.getId());
					resp.setName("resp" + req.getId());
					resp.setResponseMessage("响应内容" + req.getId());
					ctx.writeAndFlush(resp);//.addListener(ChannelFutureListener.CLOSE);
				}
				@Override
				public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {					
				}
				@Override
				public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
					ctx.close();
				}								
			}
			//基础对象类：Req与Resp
			public class Req implements Serializable{
				private static final long  SerialVersionUID = 1L;				
				private String id;
				private String name;
				private String requestMessage;
				private byte[] attachment;				
				public String getId() {
					return id;
				}
				public void setId(String id) {
					this.id = id;
				}
				public String getName() {
					return name;
				}
				public void setName(String name) {
					this.name = name;
				}
				public String getRequestMessage() {
					return requestMessage;
				}
				public void setRequestMessage(String requestMessage) {
					this.requestMessage = requestMessage;
				}
				public byte[] getAttachment() {
					return attachment;
				}
				public void setAttachment(byte[] attachment) {
					this.attachment = attachment;
				}								
			}
			public class Resp implements Serializable{				
				private static final long serialVersionUID = 1L;				
				private String id;
				private String name;
				private String responseMessage;				
				public String getId() {
					return id;
				}
				public void setId(String id) {
					this.id = id;
				}
				public String getName() {
					return name;
				}
				public void setName(String name) {
					this.name = name;
				}
				public String getResponseMessage() {
					return responseMessage;
				}
				public void setResponseMessage(String responseMessage) {
					this.responseMessage = responseMessage;
				}				
			}
			//压缩/解压工具包
			public class GzipUtils {
				public static byte[] gzip(byte[] data) throws Exception{
					ByteArrayOutputStream bos = new ByteArrayOutputStream();
					GZIPOutputStream gzip = new GZIPOutputStream(bos);
					gzip.write(data);
					gzip.finish();
					gzip.close();
					byte[] ret = bos.toByteArray();
					bos.close();
					return ret;
				}				
				public static byte[] ungzip(byte[] data) throws Exception{
					ByteArrayInputStream bis = new ByteArrayInputStream(data);
					GZIPInputStream gzip = new GZIPInputStream(bis);
					byte[] buf = new byte[1024];
					int num = -1;
					ByteArrayOutputStream bos = new ByteArrayOutputStream();
					while((num = gzip.read(buf, 0 , buf.length)) != -1 ){
						bos.write(buf, 0, num);
					}
					gzip.close();
					bis.close();
					byte[] ret = bos.toByteArray();
					bos.flush();
					bos.close();
					return ret;
				}				
				public static void main(String[] args) throws Exception{					
					//读取文件
					String readPath = System.getProperty("user.dir") + File.separatorChar + "sources" +  File.separatorChar + "006.jpg";
					File file = new File(readPath);  
					FileInputStream in = new FileInputStream(file);  
					byte[] data = new byte[in.available()];  
					in.read(data);  
					in.close();  					
					System.out.println("文件原始大小:" + data.length);
					//测试压缩					
					byte[] ret1 = GzipUtils.gzip(data);
					System.out.println("压缩之后大小:" + ret1.length);					
					byte[] ret2 = GzipUtils.ungzip(ret1);
					System.out.println("还原之后大小:" + ret2.length);					
					//写出文件
					String writePath = System.getProperty("user.dir") + File.separatorChar + "receive" +  File.separatorChar + "006.jpg";
					FileOutputStream fos = new FileOutputStream(writePath);
					fos.write(ret2);
					fos.close();    											
				}												
			}
			//客户端
			public class Client {				
				public static void main(String[] args) throws Exception{					
					EventLoopGroup group = new NioEventLoopGroup();
					Bootstrap b = new Bootstrap();
					b.group(group)
					 .channel(NioSocketChannel.class)
					 .handler(new ChannelInitializer<SocketChannel>() {
						@Override
						protected void initChannel(SocketChannel sc) throws Exception {
							sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());
							sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());
							sc.pipeline().addLast(new ClientHandler());
						}
					});					
					ChannelFuture cf = b.connect("127.0.0.1", 8765).sync();					
					for(int i = 0; i < 5; i++ ){
						Req req = new Req();
						req.setId("" + i);
						req.setName("pro" + i);
						req.setRequestMessage("数据信息" + i);	
						String path = System.getProperty("user.dir") + File.separatorChar + "sources" +  File.separatorChar + "001.jpg";
						File file = new File(path);
						FileInputStream in = new FileInputStream(file);  
						byte[] data = new byte[in.available()];  
						in.read(data);  
						in.close(); 
						req.setAttachment(GzipUtils.gzip(data));
						cf.channel().writeAndFlush(req);
					}
					cf.channel().closeFuture().sync();
					group.shutdownGracefully();
				}
			}
			//ClientHandler
			public class ClientHandler extends ChannelHandlerAdapter{				
				@Override
				public void channelActive(ChannelHandlerContext ctx) throws Exception {					
				}
				@Override
				public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
					try {
						Resp resp = (Resp)msg;
						System.out.println("Client : " + resp.getId() + ", " + resp.getName() + ", " + resp.getResponseMessage());			
					} finally {
						ReferenceCountUtil.release(msg);
					}
				}
				@Override
				public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {					
				}
				@Override
				public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
					ctx.close();
				}				
			}
		6、数据通讯
		   含义：在实际工作中，多台机器可以通过netty通讯，对于参数的设置取决于服务器性能，具体通讯方式可以分为三类：
				a、使用长连接，客户端与服务端一直处于开启连接转态，对服务器的性能要求比较高，而且适用于客户端数量较少的情况，业务场景：滴滴打车
				b、使用短链接，客户端一次批量的提交数据，客户端会把数据临时存储在缓存区或临时表中，当条件满足阈值时，才与服务端连接，提交数据，弊端：不能实时的提交数据
				c、特殊的长连接，规定在一定时间内两者没有通讯，则断开连接，下次连接客户端向服务端发起连接请求，建立连接；但需要注意2个因素：
					超时如何关闭通讯，以及后续如何建立连接；服务端宕机，客户端如何与服务端进行连接（方案：客户端使用job任务，定时检测）；
			案例分析：
				//服务端
			public class Server {
				public static void main(String[] args) throws Exception{
					//开启2个线程组
					EventLoopGroup pGroup = new NioEventLoopGroup();
					EventLoopGroup cGroup = new NioEventLoopGroup();
					//辅助类
					ServerBootstrap b = new ServerBootstrap();
					b.group(pGroup, cGroup)
					 .channel(NioServerSocketChannel.class)
					 .option(ChannelOption.SO_BACKLOG, 1024)
					 //设置日志
					 .handler(new LoggingHandler(LogLevel.INFO))
					 .childHandler(new ChannelInitializer<SocketChannel>() {
						protected void initChannel(SocketChannel sc) throws Exception {
							//管道链
							sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());
							sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());
							//设置服务端与客户端超时断开连接时间：5s
							sc.pipeline().addLast(new ReadTimeoutHandler(5)); 
							sc.pipeline().addLast(new ServerHandler());
						}
					});					
					ChannelFuture cf = b.bind(8765).sync();
					//关闭通道 
					cf.channel().closeFuture().sync();
					pGroup.shutdownGracefully();
					cGroup.shutdownGracefully();					
				}
			}
			//JavaBean类
			public class Request implements Serializable{
				private static final long  SerialVersionUID = 1L;				
				private String id;
				private String name;
				private String requestMessage;				
				public String getId() {
					return id;
				}
				public void setId(String id) {
					this.id = id;
				}
				public String getName() {
					return name;
				}
				public void setName(String name) {
					this.name = name;
				}
				public String getRequestMessage() {
					return requestMessage;
				}
				public void setRequestMessage(String requestMessage) {
					this.requestMessage = requestMessage;
				}
			}
			public class Response implements Serializable{				
				private static final long serialVersionUID = 1L;				
				private String id;
				private String name;
				private String responseMessage;				
				public String getId() {
					return id;
				}
				public void setId(String id) {
					this.id = id;
				}
				public String getName() {
					return name;
				}
				public void setName(String name) {
					this.name = name;
				}
				public String getResponseMessage() {
					return responseMessage;
				}
				public void setResponseMessage(String responseMessage) {
					this.responseMessage = responseMessage;
				}				
			}
			//MarshallingCodeCFactory类同上
			//ServerHandler
			public class ServerHandler extends ChannelHandlerAdapter{
				@Override
				public void channelActive(ChannelHandlerContext ctx) throws Exception {
				}
				@Override
				public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
					Request request = (Request)msg;
					System.out.println("Server : " + request.getId() + ", " + request.getName() + ", " + request.getRequestMessage());
					Response response = new Response();
					response.setId(request.getId());
					response.setName("response" + request.getId());
					response.setResponseMessage("响应内容" + request.getId());
					ctx.writeAndFlush(response);//.addListener(ChannelFutureListener.CLOSE);
				}
				@Override
				public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {					
				}
				@Override
				public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
					ctx.close();
				}								
			}
			//客户端
			public class Client {
				//单例获取实例对象
				private static class SingletonHolder {
					static final Client instance = new Client();
				}				
				public static Client getInstance(){
					return SingletonHolder.instance;
				}
				//建立辅助类
				private EventLoopGroup group;
				private Bootstrap b;
				private ChannelFuture cf;				
				private Client(){
						group = new NioEventLoopGroup();
						b = new Bootstrap();
						b.group(group)
						 .channel(NioSocketChannel.class)
						 .handler(new LoggingHandler(LogLevel.INFO))
						 .handler(new ChannelInitializer<SocketChannel>() {
								@Override
								protected void initChannel(SocketChannel sc) throws Exception {
									sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());
									sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());
									//超时handler（当服务器端与客户端在指定时间以上没有任何进行通信，则会关闭响应的通道，主要为减小服务端资源占用）
									sc.pipeline().addLast(new ReadTimeoutHandler(5)); 
									sc.pipeline().addLast(new ClientHandler());
								}
						});
				}				
				public void connect(){
					try {
						this.cf = b.connect("127.0.0.1", 8765).sync();//寻址连接
						System.out.println("远程服务器已经连接, 可以进行数据交换..");				
					} catch (Exception e) {
						e.printStackTrace();
					}
				}
				//获取ChannelFuture对象
				public ChannelFuture getChannelFuture(){					
					if(this.cf == null){
						this.connect();
					}
					if(!this.cf.channel().isActive()){
						this.connect();
					}					
					return this.cf;
				}				
				public static void main(String[] args) throws Exception{
					final Client c = Client.getInstance();
					//c.connect();					
					ChannelFuture cf = c.getChannelFuture();
					for(int i = 1; i <= 3; i++ ){
						Request request = new Request();
						request.setId("" + i);
						request.setName("pro" + i);
						request.setRequestMessage("数据信息" + i);
						cf.channel().writeAndFlush(request);
						//间隔4S写入数据
						TimeUnit.SECONDS.sleep(4);
					}
					cf.channel().closeFuture().sync();					
					//模拟客户端连接服务器
					new Thread(new Runnable() {
						@Override
						public void run() {
							try {
								System.out.println("进入子线程...");
								ChannelFuture cf = c.getChannelFuture();
								System.out.println(cf.channel().isActive());
								System.out.println(cf.channel().isOpen());								
								//再次发送数据
								Request request = new Request();
								request.setId("" + 4);
								request.setName("pro" + 4);
								request.setRequestMessage("数据信息" + 4);
								cf.channel().writeAndFlush(request);					
								cf.channel().closeFuture().sync();
								System.out.println("子线程结束.");
							} catch (InterruptedException e) {
								e.printStackTrace();
							}
						}
					}).start();					
					System.out.println("断开连接,主线程结束..");					
				}											
			}
			//ClientHandler
			public class ClientHandler extends ChannelHandlerAdapter{				
				@Override
				public void channelActive(ChannelHandlerContext ctx) throws Exception {
				}
				@Override
				public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
					try {
						Response resp = (Response)msg;
						System.out.println("Client : " + resp.getId() + ", " + resp.getName() + ", " + resp.getResponseMessage());			
					} finally {
						//只做读取操作，没有写数据需要释放消息
						ReferenceCountUtil.release(msg);
					}
				}
				@Override
				public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {					
				}
				@Override
				public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
					ctx.close();
				}				
			}
		7、心跳检测
			含义：在服务器集群之间需要进行心跳检测，基于Master-Slaver模式，监控各个服务器节点的各个方面情况（CPU、磁盘、网络），把这样的过程叫心跳检测；
			案例分析（利用netty与sigar相关技术实现心跳检测）：
			//服务端
			public class Server {
				public static void main(String[] args) throws Exception{					
					EventLoopGroup pGroup = new NioEventLoopGroup();
					EventLoopGroup cGroup = new NioEventLoopGroup();					
					ServerBootstrap b = new ServerBootstrap();
					b.group(pGroup, cGroup)
					 .channel(NioServerSocketChannel.class)
					 .option(ChannelOption.SO_BACKLOG, 1024)
					 //设置日志
					 .handler(new LoggingHandler(LogLevel.INFO))
					 .childHandler(new ChannelInitializer<SocketChannel>() {
						protected void initChannel(SocketChannel sc) throws Exception {
							sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());
							sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());
							//心跳检测类
							sc.pipeline().addLast(new ServerHeartBeatHandler());
						}
					});					
					ChannelFuture cf = b.bind(8765).sync();					
					cf.channel().closeFuture().sync();
					pGroup.shutdownGracefully();
					cGroup.shutdownGracefully();					
				}
			}
			//ServerHeartBeatHandler类
			public class ServerHeartBeatHandler extends ChannelHandlerAdapter {				
				private static HashMap<String, String> AUTH_IP_MAP = new HashMap<String, String>();
				private static final String SUCCESS_KEY = "auth_success_key";				
				static {
					AUTH_IP_MAP.put("192.168.1.200", "1234");
				}				
				private boolean auth(ChannelHandlerContext ctx, Object msg){
						//System.out.println(msg);
						//从客户端取到的信息
						String [] ret = ((String) msg).split(",");
						String auth = AUTH_IP_MAP.get(ret[0]);
						if(auth != null && auth.equals(ret[1])){
							ctx.writeAndFlush(SUCCESS_KEY);//认证通过
							return true;
						} else {
							ctx.writeAndFlush("auth failure !").addListener(ChannelFutureListener.CLOSE);
							return false;
						}
				}				
				@Override
				public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
					if(msg instanceof String){
						//首次认证
						auth(ctx, msg);
					} else if (msg instanceof RequestInfo) {						
						RequestInfo info = (RequestInfo) msg;
						System.out.println("--------------------------------------------");
						System.out.println("当前主机ip为: " + info.getIp());
						System.out.println("当前主机cpu情况: ");
						HashMap<String, Object> cpu = info.getCpuPercMap();
						System.out.println("总使用率: " + cpu.get("combined"));
						System.out.println("用户使用率: " + cpu.get("user"));
						System.out.println("系统使用率: " + cpu.get("sys"));
						System.out.println("等待率: " + cpu.get("wait"));
						System.out.println("空闲率: " + cpu.get("idle"));
						
						System.out.println("当前主机memory情况: ");
						HashMap<String, Object> memory = info.getMemoryMap();
						System.out.println("内存总量: " + memory.get("total"));
						System.out.println("当前内存使用量: " + memory.get("used"));
						System.out.println("当前内存剩余量: " + memory.get("free"));
						System.out.println("--------------------------------------------");
						//响应数据
						ctx.writeAndFlush("info received!");
					} else {
						ctx.writeAndFlush("connect failure!").addListener(ChannelFutureListener.CLOSE);
					}
				}
			}
			//客户端
			public class Client {				
				public static void main(String[] args) throws Exception{					
					EventLoopGroup group = new NioEventLoopGroup();
					Bootstrap b = new Bootstrap();
					b.group(group)
					 .channel(NioSocketChannel.class)
					 .handler(new ChannelInitializer<SocketChannel>() {
						@Override
						protected void initChannel(SocketChannel sc) throws Exception {
							sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());
							sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());
							//心跳检测类
							sc.pipeline().addLast(new ClienHeartBeattHandler());
						}
					});
					//寻址连接
					ChannelFuture cf = b.connect("127.0.0.1", 8765).sync();
					cf.channel().closeFuture().sync();
					group.shutdownGracefully();
				}
			}
			//ClienHeartBeattHandler
			public class ClienHeartBeattHandler extends ChannelHandlerAdapter {
				//池化技术，特点是可以定时执行任务
				private ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);				
				private ScheduledFuture<?> heartBeat;
				//主动向服务器发送认证信息
				private InetAddress addr;				
				private static final String SUCCESS_KEY = "auth_success_key";
				@Override
				public void channelActive(ChannelHandlerContext ctx) throws Exception {
					addr = InetAddress.getLocalHost();
					String ip = addr.getHostAddress();
					String key = "1234";
					//证书，由两部分构成：IP与KEY
					String auth = ip + "," + key;
					//写出
					ctx.writeAndFlush(auth);
				}				
				@Override
				public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
					try {
						if(msg instanceof String){
							String ret = (String)msg;
							if(SUCCESS_KEY.equals(ret)){
								// 握手成功，主动发送心跳消息，每2S执行一次任务
								this.heartBeat = this.scheduler.scheduleWithFixedDelay(new HeartBeatTask(ctx), 0, 2, TimeUnit.SECONDS);
								System.out.println(msg);    			
							}
							else {
								System.out.println(msg);
							}
						}
					} finally {
						ReferenceCountUtil.release(msg);
					}
				}
				//线程任务
				private class HeartBeatTask implements Runnable {
					private final ChannelHandlerContext ctx;
					public HeartBeatTask(final ChannelHandlerContext ctx) {
						this.ctx = ctx;
					}				
					@Override
					public void run() {
						try {
							RequestInfo info = new RequestInfo();
							//ip
							info.setIp(addr.getHostAddress());
							Sigar sigar = new Sigar();
							//cpu prec
							CpuPerc cpuPerc = sigar.getCpuPerc();
							HashMap<String, Object> cpuPercMap = new HashMap<String, Object>();
							cpuPercMap.put("combined", cpuPerc.getCombined());
							cpuPercMap.put("user", cpuPerc.getUser());
							cpuPercMap.put("sys", cpuPerc.getSys());
							cpuPercMap.put("wait", cpuPerc.getWait());
							cpuPercMap.put("idle", cpuPerc.getIdle());
							// memory
							Mem mem = sigar.getMem();
							HashMap<String, Object> memoryMap = new HashMap<String, Object>();
							memoryMap.put("total", mem.getTotal() / 1024L);
							memoryMap.put("used", mem.getUsed() / 1024L);
							memoryMap.put("free", mem.getFree() / 1024L);
							info.setCpuPercMap(cpuPercMap);
							info.setMemoryMap(memoryMap);
							ctx.writeAndFlush(info);
							
						} catch (Exception e) {
							e.printStackTrace();
						}
					}
					public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
						cause.printStackTrace();
						if (heartBeat != null) {
							heartBeat.cancel(true);
							heartBeat = null;
						}
						ctx.fireExceptionCaught(cause);
					}					
				}
			}
			//JavaBean类
			public class RequestInfo implements Serializable {
				private String ip ;
				private HashMap<String, Object> cpuPercMap ;
				private HashMap<String, Object> memoryMap;				
				public String getIp() {
					return ip;
				}
				public void setIp(String ip) {
					this.ip = ip;
				}
				public HashMap<String, Object> getCpuPercMap() {
					return cpuPercMap;
				}
				public void setCpuPercMap(HashMap<String, Object> cpuPercMap) {
					this.cpuPercMap = cpuPercMap;
				}
				public HashMap<String, Object> getMemoryMap() {
					return memoryMap;
				}
				public void setMemoryMap(HashMap<String, Object> memoryMap) {
					this.memoryMap = memoryMap;
				}								
			}
		8、基于Http协议实现上传/下载（了解即可，实现文件的上传与下载可以使用专业的框架：如FastDfs、HDFs）
			Http协议的认识：超文本传输协议，是基于TCP协议之上的运用层协议，主要用于WEB开发；Netty下的Http也是异步非阻塞的，Http协议特点：简单（使用简单、在URL中携带必要参数即可）、
			灵活（支持任意类型的数据对象）、无状态（对事务处理没有记忆能力、即想获取之前的信息必须重新请求）；构成：请求行、请求头、请求体组成；
			请求方式：GET、POST、HEAD、PUT、DELETE、TRACE、CONNECT、OPTINS
			响应码：
				1XX：提示信息；2XX：成功；3XX：重定向；4XX:客户端错误；5XX:服务端错误；
				常见状态码：200 OK、400 Bad Request（语法不对）、401 Unauthorized（未授权）、403 Forbidden（服务器拒绝）、404 Not Fund（找不到）、405 Method Not Allowed（请求方式不被允许）
							500 Inernal Server Error（服务器内部错误）、503 Server Unavailable （服务当前不可用）；
			案例分析：（Netty实现文件上传核心利用的是chuck分片断点续传技术）		
			#与Http的整合例子
			public final class HttpHelloWorldServer {
				  //安全验证
				  static final boolean SSL = System.getProperty("ssl") != null;
				  static final int PORT = Integer.parseInt(System.getProperty("port", SSL? "8443" : "8080"));			  
				  public static void main(String[] args) throws Exception {
					  //配置SSL
					  final SslContext sslCtx;
					  if (SSL) {
						  SelfSignedCertificate ssc = new SelfSignedCertificate();
						  sslCtx = SslContext.newServerContext(ssc.certificate(), ssc.privateKey());
					  } else {
						  sslCtx = null;
					  }			  
					  //配置服务端
					  EventLoopGroup bossGroup = new NioEventLoopGroup(1);
					  EventLoopGroup workerGroup = new NioEventLoopGroup();
					  try {
						  ServerBootstrap b = new ServerBootstrap();
						  b.option(ChannelOption.SO_BACKLOG, 1024);
						  b.group(bossGroup, workerGroup)
						   .channel(NioServerSocketChannel.class)
						   .handler(new LoggingHandler(LogLevel.INFO))
						   .childHandler(new HttpHelloWorldServerInitializer(sslCtx));			  
						  Channel ch = b.bind(PORT).sync().channel();			  
						  System.err.println("Open your web browser and navigate to " +
								  (SSL? "https" : "http") + "://127.0.0.1:" + PORT + '/');			  
						  ch.closeFuture().sync();
					  } finally {
						  bossGroup.shutdownGracefully();
						  workerGroup.shutdownGracefully();
					  }
				  }				  				  
			}
			#HttpHelloWorldServerInitializer
			public class HttpHelloWorldServerInitializer extends ChannelInitializer<SocketChannel> {			  
				  private final SslContext sslCtx;			  
				  public HttpHelloWorldServerInitializer(SslContext sslCtx) {
					 this.sslCtx = sslCtx;
				  }			  
				  @Override
				  public void initChannel(SocketChannel ch) {
					  ChannelPipeline p = ch.pipeline();
					  if (sslCtx != null) {
						  p.addLast(sslCtx.newHandler(ch.alloc()));
					  }
					  //管道链
					  p.addLast(new HttpServerCodec());
					  p.addLast(new HttpHelloWorldServerHandler());
				  }
			  }
			  public class HttpHelloWorldServerHandler extends ChannelHandlerAdapter {
				  //连接OK，响应标识
				  private static final byte[] CONTENT = { 'H', 'e', 'l', 'l', 'o', ' ', 'W', 'o', 'r', 'l', 'd' };			  
				  @Override
				  public void channelReadComplete(ChannelHandlerContext ctx) {
					  ctx.flush();
				  }			  
				  @Override
				  public void channelRead(ChannelHandlerContext ctx, Object msg) {
					  if (msg instanceof HttpRequest) {
						  HttpRequest req = (HttpRequest) msg;			  
						  if (HttpHeaderUtil.is100ContinueExpected(req)) {
							  ctx.write(new DefaultFullHttpResponse(HTTP_1_1, CONTINUE));
						  }
						  boolean keepAlive = HttpHeaderUtil.isKeepAlive(req);
						  FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, OK, Unpooled.wrappedBuffer(CONTENT));
						  response.headers().set(CONTENT_TYPE, "text/plain");
						  response.headers().setInt(CONTENT_LENGTH, response.content().readableBytes());			  
						  if (!keepAlive) {
							  ctx.write(response).addListener(ChannelFutureListener.CLOSE);
						  } else {
							  response.headers().set(CONNECTION, HttpHeaderValues.KEEP_ALIVE);
							  ctx.write(response);
						  }
					  }
				  }			  
				  @Override
				  public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) {
					  cause.printStackTrace();
					  ctx.close();
				  }
			  }
			  #注：浏览器访问:127.0.0.1:8080，页面出现Hello Word，说明netty与http配置成功！
			  #FileList列表
			  public class HttpFileServer {
				private static final String DEFAULT_URL = "/sources/";
				public void run(final int port, final String url) throws Exception {
					EventLoopGroup bossGroup = new NioEventLoopGroup();
					EventLoopGroup workerGroup = new NioEventLoopGroup();
					try {
						ServerBootstrap b = new ServerBootstrap();
						b.group(bossGroup, workerGroup)
							.channel(NioServerSocketChannel.class)
							.childHandler(new ChannelInitializer<SocketChannel>() {
							@Override
							protected void initChannel(SocketChannel ch)
								throws Exception {
								// 加入http的解码器
								ch.pipeline().addLast("http-decoder", new HttpRequestDecoder());
								// 加入ObjectAggregator解码器，作用是他会把多个消息转换为单一的FullHttpRequest或者FullHttpResponse
								ch.pipeline().addLast("http-aggregator", new HttpObjectAggregator(65536));
								// 加入http的编码器
								ch.pipeline().addLast("http-encoder", new HttpResponseEncoder());
								// 加入chunked 主要作用是支持异步发送的码流（大文件传输），但不专用过多的内存，防止java内存溢出
								ch.pipeline().addLast("http-chunked", new ChunkedWriteHandler());
								// 加入自定义处理文件服务器的业务逻辑handler
								ch.pipeline().addLast("fileServerHandler",new HttpFileServerHandler(url));									
							}
							});
						ChannelFuture future = b.bind("192.168.1.200", port).sync();
						System.out.println("HTTP文件目录服务器启动，网址是 : " + "http://192.168.1.200:"  + port + url);
						future.channel().closeFuture().sync();
					} finally {
						bossGroup.shutdownGracefully();
						workerGroup.shutdownGracefully();
					}
				}
				public static void main(String[] args) throws Exception {
					int port = 8765;
					String url = DEFAULT_URL;
					new HttpFileServer().run(port, url);
				}
			}
			public class HttpFileServerHandler extends SimpleChannelInboundHandler<FullHttpRequest> {				
				private final String url;
				public HttpFileServerHandler(String url) {
					this.url = url;
				}
				@Override
				public void messageReceived(ChannelHandlerContext ctx, FullHttpRequest request) throws Exception {
					//对请求的解码结果进行判断：
					if (!request.decoderResult().isSuccess()) {
						// 400
						sendError(ctx, BAD_REQUEST);
						return;
					}
					//对请求方式进行判断：如果不是get方式（如post方式）则返回异常
					if (request.method() != GET) {
						// 405
						sendError(ctx, METHOD_NOT_ALLOWED);
						return;
					}
					//获取请求uri路径
					final String uri = request.uri();
					//对url进行分析，返回本地系统
					final String path = sanitizeUri(uri);
					//如果 路径构造不合法，则path为null
					if (path == null) {
						//403
						sendError(ctx, FORBIDDEN);
						return;
					}
					// 创建file对象
					File file = new File(path);
					// 判断文件是否为隐藏或者不存在
					if (file.isHidden() || !file.exists()) {
						// 404 
						sendError(ctx, NOT_FOUND);
						return;
					}
					// 如果为文件夹
					if (file.isDirectory()) {
						if (uri.endsWith("/")) {
							//如果以正常"/"结束 说明是访问的一个文件目录：则进行展示文件列表（web服务端则可以跳转一个Controller，遍历文件并跳转到一个页面）
							sendListing(ctx, file);
						} else {
							//如果非"/"结束 则重定向，补全"/" 再次请求
							sendRedirect(ctx, uri + '/');
						}
						return;
					}
					// 如果所创建的file对象不是文件类型
					if (!file.isFile()) {
						// 403
						sendError(ctx, FORBIDDEN);
						return;
					}					
					//随机文件读写类
					RandomAccessFile randomAccessFile = null;
					try {
						randomAccessFile = new RandomAccessFile(file, "r");// 以只读的方式打开文件
					} catch (FileNotFoundException fnfe) {
						// 404
						sendError(ctx, NOT_FOUND);
						return;
					}					
					//获取文件长度
					long fileLength = randomAccessFile.length();
					//建立响应对象
					HttpResponse response = new DefaultHttpResponse(HTTP_1_1, OK);
					//设置响应信息
					HttpHeaderUtil.setContentLength(response, fileLength);
					//设置响应头
					setContentTypeHeader(response, file);
					//如果一直保持连接则设置响应头信息为：HttpHeaders.Values.KEEP_ALIVE
					if (HttpHeaderUtil.isKeepAlive(request)) {
						response.headers().set(CONNECTION, HttpHeaderValues.KEEP_ALIVE);
					}
					//进行写出
					ctx.write(response);					
					//构造发送文件线程，将文件写入到Chunked缓冲区中
					ChannelFuture sendFileFuture;
					//写出ChunkedFile
					sendFileFuture = ctx.write(new ChunkedFile(randomAccessFile, 0, fileLength, 8192), ctx.newProgressivePromise());
					//添加传输监听，文件上传进度监听
					sendFileFuture.addListener(new ChannelProgressiveFutureListener() {
						@Override
						public void operationProgressed(ChannelProgressiveFuture future, long progress, long total) {
							if (total < 0) { // total unknown
								System.err.println("Transfer progress: " + progress);
							} else {
								System.err.println("Transfer progress: " + progress + " / " + total);
							}
						}
						@Override
						public void operationComplete(ChannelProgressiveFuture future) throws Exception {
							System.out.println("Transfer complete.");
						}
					});					
					//如果使用Chunked编码，最后则需要发送一个编码结束的看空消息体，进行标记，表示所有消息体已经成功发送完成。
					ChannelFuture lastContentFuture = ctx.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT);
					//如果当前连接请求非Keep-Alive ，最后一包消息发送完成后 服务器主动关闭连接
					if (!HttpHeaderUtil.isKeepAlive(request)) {
						lastContentFuture.addListener(ChannelFutureListener.CLOSE);
					}
				}
				@Override
				public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
					if (ctx.channel().isActive()) {
						sendError(ctx, INTERNAL_SERVER_ERROR);
						ctx.close();
					}
				}
				//非法URI正则
				private static final Pattern INSECURE_URI = Pattern.compile(".*[<>&\"].*");
				/**
				 * <B>方法名称：</B>解析URI<BR>
				 * <B>概要说明：</B>对URI进行分析<BR>
				 * @param uri netty包装后的字符串对象
				 * @return path 解析结果
				 */
				private String sanitizeUri(String uri) {
					try {
						//使用UTF-8字符集
						uri = URLDecoder.decode(uri, "UTF-8");
					} catch (UnsupportedEncodingException e) {
						try {
							//尝试ISO-8859-1
							uri = URLDecoder.decode(uri, "ISO-8859-1");
						} catch (UnsupportedEncodingException e1) {
							//抛出预想外异常信息
							throw new Error();
						}
					}
					// 对uri进行细粒度判断：4步验证操作
					// step 1 基础验证
					if (!uri.startsWith(url)) {
						return null;
					}
					// step 2 基础验证
					if (!uri.startsWith("/")) {
						return null;
					}
					// step 3 将文件分隔符替换为本地操作系统的文件路径分隔符
					uri = uri.replace('/', File.separatorChar);
					// step 4 二次验证合法性
					if (uri.contains(File.separator + '.')
						|| uri.contains('.' + File.separator) || uri.startsWith(".")
						|| uri.endsWith(".") || INSECURE_URI.matcher(uri).matches()) {
						return null;
					}
					//当前工程所在目录 + URI构造绝对路径进行返回 
					return System.getProperty("user.dir") + File.separator + uri;
				}				
				//文件是否被允许访问下载验证
				private static final Pattern ALLOWED_FILE_NAME = Pattern.compile("[A-Za-z0-9][-_A-Za-z0-9\\.]*");
				private static void sendListing(ChannelHandlerContext ctx, File dir) {
					// 设置响应对象
					FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, OK);
					// 响应头
					response.headers().set(CONTENT_TYPE, "text/html; charset=UTF-8");
					// 追加文本内容
					StringBuilder ret = new StringBuilder();
					String dirPath = dir.getPath();
					ret.append("<!DOCTYPE html>\r\n");
					ret.append("<html><head><title>");
					ret.append(dirPath);
					ret.append(" 目录：");
					ret.append("</title></head><body>\r\n");
					ret.append("<h3>");
					ret.append(dirPath).append(" 目录：");
					ret.append("</h3>\r\n");
					ret.append("<ul>");
					ret.append("<li>链接：<a href=\"../\">..</a></li>\r\n");					
					// 遍历文件 添加超链接
					for (File f : dir.listFiles()) {
						//step 1: 跳过隐藏或不可读文件 
						if (f.isHidden() || !f.canRead()) {
							continue;
						}
						String name = f.getName();
						//step 2: 如果不被允许，则跳过此文件
						if (!ALLOWED_FILE_NAME.matcher(name).matches()) {
							continue;
						}
						//拼接超链接即可
						ret.append("<li>链接：<a href=\"");
						ret.append(name);
						ret.append("\">");
						ret.append(name);
						ret.append("</a></li>\r\n");
					}
					ret.append("</ul></body></html>\r\n");
					//构造结构，写入缓冲区
					ByteBuf buffer = Unpooled.copiedBuffer(ret, CharsetUtil.UTF_8);
					//进行写出操作
					response.content().writeBytes(buffer);
					//重置写出区域
					buffer.release();
					//使用ctx对象写出并且刷新到SocketChannel中去 并主动关闭连接(这里是指关闭处理发送数据的线程连接)
					ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
				}
				//重定向操作
				private static void sendRedirect(ChannelHandlerContext ctx, String newUri) {
					//建立响应对象
					FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, FOUND);
					//设置新的请求地址放入响应对象中去
					response.headers().set(LOCATION, newUri);
					//使用ctx对象写出并且刷新到SocketChannel中去 并主动关闭连接(这里是指关闭处理发送数据的线程连接)
					ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
				}
				//错误信息
				private static void sendError(ChannelHandlerContext ctx, HttpResponseStatus status) {
					//建立响应对象
					FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, status, Unpooled.copiedBuffer("Failure: " + status.toString()+ "\r\n", CharsetUtil.UTF_8));
					//设置响应头信息
					response.headers().set(CONTENT_TYPE, "text/plain; charset=UTF-8");
					//使用ctx对象写出并且刷新到SocketChannel中去 并主动关闭连接(这里是指关闭处理发送数据的线程连接)
					ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
				}
				private static void setContentTypeHeader(HttpResponse response, File file) {
					//使用mime对象获取文件类型
					MimetypesFileTypeMap mimeTypesMap = new MimetypesFileTypeMap();
					response.headers().set(CONTENT_TYPE, mimeTypesMap.getContentType(file.getPath()));
				}
			}			  
----------------------------------------------Java数据结构与算法---------------------------------------------------------------------------------------------------------
		一、	
			
----------------------------------------------JVM虚拟机优化篇----------------------------------------------------------------------------------------------------------		
	一、VM含义：
		虚拟机：虚拟的机器，是一款软件，用于执行虚拟计算机指令，可以分为系统虚拟机与程序虚拟机。
				系统虚拟机有：Visual Box、VMare，使用时注意三种网络适配器的模式（主机模式（JVM不能访问外网）、NAT网络地址转化模式（宿主机与主机在不同的网段）、桥接模式（同一网段））
				程序虚拟机有：典型的Java虚拟机（JVM）		
	二、JVM：
		基本结构：
			类加载子系统（加载.class的编译文件）、方法区（类、静态常量以及方法、池的概念，线程共享的，永久区）、Java堆（存储对象实例，线程共享的）、直接内存（epoll机制处理、NIO 2.0（异步）读写）、Java栈（存储变量、对象引用，独享一块线程）、本地方法栈、垃圾回收系统（GC机制、核心）、
			PC寄存器（指针计数作用）、执行引擎（执行Java代码）
		需要掌握的地方：
			1、堆、栈、方法区的概念与联系
				堆：存储对象实例，解决数据存储问题，数据怎么放、怎么存；主要是对象实例；
				栈：解决程序运行问题，即程序如何运行，如何处理数据；主要存变量、对象引用
				方法区：一块永久区，是先决条件；存储类信息、静态方法以及常量，池的概念；
			2、底层情况：
				堆：几乎所有对象实例都存放在堆里面，而且堆是完全自动化管理的，即通过垃圾回收机制（GC），垃圾对象自动清理；根据GC机制不同，堆的结构也不同，分为新生代与老年代。
					新生代指的是新生的对象或年龄不大的对象，而老年代指的是老年的对象。
					新生代细分可以分为eden区、s0区（from区）与s1区（to区），而且s0区与s1区是大小相同可以相互转换角色的区域。
					新创建的对象先进入eden区，经过一次的GC清理后会进入s0区或s1区（涉及到复制算法概念），经过多轮的GC之后（默认15次），绝大多数对象会被清洗掉，剩下来的最终会进入老年区。
				栈：是一块线程私有的内存空间，一般由三部分组成：
					局部变量表：存放的是局部变量
					操作数栈：保存的是计算的中间过程（Temp）
					帧数据区：保存访问常量池的指针，异常处理表也是一部分
				方法区：一块线程共享的区域，存储类的信息，包括：类的字段、方法、常量池等
		虚拟机参数：
			主要围绕堆、栈、方法区进行配置
			1、堆的参数设置：
				基本概念：
					-XX：属于系统级别（JVM）的配置，可以配置日志信息、以及JVM使用什么样的垃圾回收器
					非-XX：属于应用级别的配置；
					+：启用
					-：禁用
				常见参数解析：
					-XX:+PrintGC：虚拟机启动后，会打印GC的日志信息
					-XX:+UseSerialGC：使用串行回收器
					-XX:+PrintGCDetails：打印详细的信息，包括各区情况（新生代、老年代）
					-Xms：设置Java程序初始化堆大小
					-Xmx：设置Java程序最大堆大小
					-Xmx20m -Xms5m -XX:+PrintCommandLineFlags：将显示或隐式的传给虚拟机的参数打印输出
					总结：实际工作中，将初始堆大小与最大的堆大小设置相同，可以减少程序运行时垃圾回收GC次数，从而提高系统性能
					案例说明：
					public class Test01 {
						public static void main(String[] args) {
							//-Xms5m -Xmx20m -XX:+PrintGCDetails -XX:+UseSerialGC -XX:+PrintCommandLineFlags							
							//查看GC信息
							System.out.println("max memory:" + Runtime.getRuntime().maxMemory());
							System.out.println("free memory:" + Runtime.getRuntime().freeMemory());
							System.out.println("total memory:" + Runtime.getRuntime().totalMemory());							
							byte[] b1 = new byte[1*1024*1024];
							System.out.println("分配了1M");
							System.out.println("max memory:" + Runtime.getRuntime().maxMemory());
							System.out.println("free memory:" + Runtime.getRuntime().freeMemory());
							System.out.println("total memory:" + Runtime.getRuntime().totalMemory());							
							byte[] b2 = new byte[4*1024*1024];
							System.out.println("分配了4M");
							System.out.println("max memory:" + Runtime.getRuntime().maxMemory());
							System.out.println("free memory:" + Runtime.getRuntime().freeMemory());
							System.out.println("total memory:" + Runtime.getRuntime().totalMemory());							
						}						
					}
					#新生代的配置
					-Xmn：设置新生代的大小，这个参数对GC的行为有很大影响（GC主要回收这块内存），一般设置为整个堆内存的1/3到1/4左右
					-XX:SurvivorRatio：设置新生代中的eden空间和from/to空间的比例，含义：-XX:SurvivorRatio=eden/to=eden/from
					-XX:NewRatio：设置新生代与老年代的比例，即：-XX:NewRatio=老年代/新生代
					总结：尽可能的将对象预留在新生代，减少老年代GC的次数
					案例说明：
					public class Test02 {
						public static void main(String[] args) {							
							//第一次配置
							//-Xms20m -Xmx20m -Xmn1m -XX:SurvivorRatio=2 -XX:+PrintGCDetails -XX:+UseSerialGC							
							//第二次配置
							//-Xms20m -Xmx20m -Xmn7m -XX:SurvivorRatio=2 -XX:+PrintGCDetails -XX:+UseSerialGC							
							//第三次配置
							//-XX:NewRatio=老年代/新生代
							//-Xms20m -Xmx20m -XX:NewRatio=2 -XX:+PrintGCDetails -XX:+UseSerialGC							
							byte[] b = null;
							//连续向系统申请10MB空间
							for(int i = 0 ; i <10; i ++){
								b = new byte[1*1024*1024];
							}
						}
					}
				堆内存溢出处理：
					含义：Java程序在运行的时候，如果堆空间不足，则会抛出堆内存溢出的错误（Out Of Memory）OOM，在生产环境下，严重影响业务中断；JVM提供了-XX:+HeapDumpOnOutOfMemoryError参数，
						  可以导出整个堆信息，配合-XX:+HeapDumpPath来设置存储路径；配合使用插件：Memory Analyzer 1.5.0进行分析；
					案例分析：
					public class Test03 {
						public static void main(String[] args) {							
							//-Xms1m -Xmx1m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=d:/Test03.dump
							//堆内存溢出
							Vector v = new Vector();
							for(int i=0; i < 5; i ++){
								v.add(new Byte[1*1024*1024]);
							}							
						}
					}
			2、栈的参数设置：
				-Xss：指定线程的最大栈空间，决定了函数调用的最大深度；
				案例分析：
				public class Test04 {
					//-Xss1m  
					//-Xss5m					
					//栈调用深度
					private static int count;					
					public static void recursion(){
						count++;
						recursion();
					}
					public static void main(String[] args){
						try {
							recursion();
						} catch (Throwable t) {
							System.out.println("调用最大深入：" + count);
							t.printStackTrace();
						}
					}
				}
			3、方法区的参数设置：
				-XX:MaxPermSize=64MB
				-XX:PermSize=64MB，默认设置就是64MB
			4、直接内存的参数设置（了解）：		
				-XX:MaxDirectMemorySize：利用这一参数设置，可以忽略；广泛用于NIO中；
			5、对象如何进入老年代？参数设置：
				-XX:MaxTenuringThreshold=15，默认值15，即GC次数15次
				案例分析：
				public class Test05 {
					public static void main(String[] args) {
						//初始的对象在eden区
						//参数：-Xmx64M -Xms64M -XX:+PrintGCDetails
				//		for(int i=0; i< 5; i++){//5M
				//			byte[] b = new byte[1024*1024];
				//		}																		
						//测试进入老年代的对象
						//参数：-Xmx1024M -Xms1024M -XX:+UseSerialGC -XX:MaxTenuringThreshold=15 -XX:+PrintGCDetails -XX:+PrintHeapAtGC
				//		Map<Integer, byte[]> m = new HashMap<Integer, byte[]>();
				//		for(int i =0; i <5 ; i++) {
				//			byte[] b = new byte[1024*1024];
				//			m.put(i, b);
				//		}	
				//		for(int k = 0; k<20; k++) {
				//			for(int j = 0; j<300; j++){
				//				byte[] b = new byte[1024*1024]; 
				//			}
				//		}											
					}
				}
			6、当对象过大，eden区装不了直接进入老年代，可以设置参数来确定，但要注意TLAB区域：
				-XX:PretenureSizeThreshold
				TLAB区：全程为Thread Local Allocation Buffer，即线程本地分配缓存，线程专用的，目的是为了加速对象分配而产生的，避免多线程冲突的问题；一般不会太大，但TLAB装不下，会直接分配到堆上；
						相关参数设置：
							-XX:+UseTLAB：使用TLAB
							-XX:+TLABSize：设置TLAB的大小
							-XX:TLABRefillWasteFraction：设置进入TLAB区单个对象的大小，是一个比值，默认64，即但单个对象大于整个区的1/64，则在堆内存中创建对象
							-XX:+PrintTLAB：打印信息
							-XX:ResizeTLAB：自动调整TLABRefillWasteFraction的阈值
				案例分析：
				public class Test06 {
					public static void main(String[] args) {						
						//参数：-Xmx30M -Xms30M -XX:+UseSerialGC -XX:+PrintGCDetails -XX:PretenureSizeThreshold=1000
						//出现这种现象原因为：JVM虚拟机对于体积不大的对象会优先把数据分配到TLAB区域中，因此就失去了在老年代分配的机会
						//参数：-Xmx30M -Xms30M -XX:+UseSerialGC -XX:+PrintGCDetails -XX:PretenureSizeThreshold=1000 -XX:-UseTLAB
						Map<Integer, byte[]> m = new HashMap<Integer, byte[]>();
						for(int i=0; i< 5*1024; i++){
							byte[] b = new byte[1024];
							m.put(i, b);
						}
					}
				}
				public class Test07 {
					public static void alloc(){
						byte[] b = new byte[2];
					}
					public static void main(String[] args) {						
						//TLAB分配
						//参数：-XX:+UseTLAB -XX:+PrintTLAB -XX:+PrintGC -XX:TLABSize=102400 -XX:-ResizeTLAB -XX:TLABRefillWasteFraction=100 -XX:-DoEscapeAnalysis -server
						for(int i=0; i<10000000;i++){
							alloc();
						}																																																
					}
				}
			7、对象创建流程图：
				new 关键字创建对象 --------->尝试栈上分配（临时变量、对象）----N---->尝试TLAB分配（逻辑概念）----N---->是否满足进入老年代-----N---->eden区分配---->END
													|Y										|Y									|Y
													栈										TLAB								老年代								
		虚拟机工作模式：
			JVM支持Client和Server两种工作模式，使用相应的参数：-client或-server调用相应的模式，区别：Client模式启动快，用于测试环境；Server模式启动慢，用于生产环境，JDK1.7以后都是Server模式
		垃圾回收和算法：
			垃圾回收：
				概念：Garbage Collection，简称GC，在GC机制内存中不再使用的对象，需要回收。垃圾回收涉及多种算法，如：引用计数法，标记压缩法，复制算法，分代、分区思想
					引用计数法：古老的方法，核心思想是：对象被引用时计数加1，对象失去引用时计数减1，缺点：在循环迭代时易出错，频繁的加减操作影响系统性能
					标记清除法：分为标记和清除2个阶段，缺点存在空间碎片问题，GC以后内存空间是不连续的
					复制算法：Jvm新生代中的S0区或S1区使用这种算法
					标记压缩法：Jvm老年代使用这种算法，在标记清除基础之上，对标记对象进行压缩放置到一端而进行的垃圾清理
					分代算法：将内存分成多块，每块使用不同的算法
					分区算法：分区概念类似于磁盘分区，将整个内存空间分成独立的N块小空间，每个空间都可以独立使用，GC时只需对某一块内存空间进行GC，提高性能，减少GC停顿时间
			垃圾回收停顿想象：
				在GC的时候，会要求系统进入一个停顿的状态，此时程序会终止所有的线程，此刻程序是不会产生新的垃圾，也有利于更好的标记垃圾对象
		
				
			
			
					
			
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	